#!/usr/bin/env bash
# scripts/training-data/01.download
#
# STEP 1 ‚Äî DOWNLOAD (single entrypoint)
#
# Downloads:
#   1) Best audio (original format: webm/opus/m4a/etc)  -> keeps it  ‚úÖ (SOURCE OF TRUTH)
#   2) WAV audio extracted from that best audio         -> for Whisper/pipeline ‚úÖ (raw + clean)
#   3) MP4 video (best video+audio merged into mp4)
#   4) Info JSON metadata files
#
# Output:
#   data/01.download/<source_name>/<video_name>/*
#
# Use:
#   A) One source (video / playlist / channel):
#      ./scripts/training-data/01.download "daily_evolution" "https://www.youtube.com/watch?v=utuuVOXJunM"
#
#   B) Batch from sources file:
#      ./scripts/training-data/01.download --sources
#      ./scripts/training-data/01.download --sources docs/sources.txt
#
# Cookies:
#   - Put cookie export file at:
#       docs/data_docs/www.youtube.com_cookies.txt
#     OR set:
#       YOUTUBE_COOKIES_FILE=/path/to/cookies.txt
#   - Script COPIES cookies into the output folder and uses the copy.
#
# NOTE (2026 reality check):
#   YouTube increasingly requires JS-based signature extraction for yt-dlp.
#   This script enforces a JS runtime for reliability (node/deno/etc).
#
# BEST-PRACTICE AUDIO STRATEGY (core correctness):
#   1) ALWAYS keep the original best audio file downloaded from YouTube.
#   2) Create ASR WAVs yourself with ffmpeg:
#        - *.asr.raw16k.wav    (format normalized only)
#        - *.asr.clean16k.wav  (mild cleanup for fewer hallucinations)
#   3) Optionally create *.listen.mp3 for fast playback / QA.
#
# IMPORTANT: ffmpeg can break loops if it reads from stdin.
#   -> We force -nostdin so it cannot steal input from while-read loops.

set -euo pipefail

usage() {
  cat <<'EOF'
Usage:

  Download one source (video/playlist/channel):
    ./scripts/training-data/01.download "<source_name>" "<youtube_url>"

  Download all sources from config:
    ./scripts/training-data/01.download --sources [path/to/sources.txt]

Examples:
  ./scripts/training-data/01.download "daily_evolution" "https://www.youtube.com/watch?v=utuuVOXJunM"
  ./scripts/training-data/01.download --sources
EOF
}

safe_name() {
  printf '%s' "$1" | tr -cs 'A-Za-z0-9._-' '_' | sed -E 's/^_+//;s/_+$//'
}

have_cmd() { command -v "$1" >/dev/null 2>&1; }

# Pick downloader
DOWNLOADER="yt-dlp"
if ! have_cmd yt-dlp; then
  if have_cmd youtube-dl; then
    DOWNLOADER="youtube-dl"
  else
    echo "‚ùå Error: yt-dlp not found. Install it with:"
    echo "   pip install -U yt-dlp yt-dlp-ejs"
    exit 1
  fi
fi

# Need ffmpeg for merging mp4 + extracting wav
if ! have_cmd ffmpeg; then
  echo "‚ùå Error: ffmpeg not found. Install it first."
  echo "   macOS:   brew install ffmpeg"
  echo "   Ubuntu:  sudo apt-get install -y ffmpeg"
  exit 1
fi

# ffprobe helps us validate that clean/raw durations match
FFPROBE_OK=0
if have_cmd ffprobe; then
  FFPROBE_OK=1
fi

# Script lives at: scripts/training-data/01.download
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
ROOT_DIR="$(cd "$SCRIPT_DIR/../.." && pwd)"

# Where downloads must go
OUTPUT_ROOT="${OUTPUT_ROOT:-"$ROOT_DIR/data/01.download"}"

COOKIES_FILE="${YOUTUBE_COOKIES_FILE:-"$ROOT_DIR/docs/data_docs/www.youtube.com_cookies.txt"}"

# --------------------------
# Reliability + audio settings (business-critical)
# --------------------------

# 1) YouTube download reliability knobs
#    Lower concurrent fragments reduces 403s on many networks/regions.
CONCURRENT_FRAGMENTS="${CONCURRENT_FRAGMENTS:-1}"
RETRIES="${RETRIES:-10}"
FRAGMENT_RETRIES="${FRAGMENT_RETRIES:-10}"
RETRY_SLEEP="${RETRY_SLEEP:-2}"

# 2) ASR audio standardization
#    16k mono PCM = safest common denominator for Whisper pipelines.
ASR_SAMPLE_RATE="${ASR_SAMPLE_RATE:-16000}"

# 3) Clean audio filters (conservative & robust)
#    IMPORTANT: dynaudnorm is intentionally removed here because it can hang or truncate in batch pipelines.
#    These are stable and typically helpful:
#      - highpass: remove rumble
#      - lowpass: reduce hiss
#      - afftdn: mild noise reduction (optional)
#      - alimiter: prevent clipping
ASR_CLEAN_FILTERS="${ASR_CLEAN_FILTERS:-highpass=f=80,lowpass=f=8000,afftdn=nf=-25,alimiter=limit=0.97}"

# 3b) Timestamp safety (prevents weird duration truncation on some sources)
#     async=1 helps align/repair broken timestamps without aggressive stretching.
ASR_RESYNC_FILTER="${ASR_RESYNC_FILTER:-aresample=async=1:first_pts=0}"

# 4) Optional playable preview file for QA
MAKE_PREVIEW_MP3="${MAKE_PREVIEW_MP3:-1}"
PREVIEW_MP3_BITRATE="${PREVIEW_MP3_BITRATE:-128k}"

# 5) ffmpeg hang protection (never let one file brick the batch)
FFMPEG_TIMEOUT_SEC="${FFMPEG_TIMEOUT_SEC:-600}"  # 10 minutes
USE_TIMEOUT=0
if have_cmd timeout; then
  USE_TIMEOUT=1
fi

# --------------------------
# JS runtime detection (yt-dlp best practice)
# --------------------------
js_runtime_args=()
extractor_args=()

if [[ "$DOWNLOADER" == "yt-dlp" ]]; then
  # yt-dlp increasingly needs JS runtime for reliable extraction.
  if have_cmd deno; then
    js_runtime_args=(--js-runtimes deno)
  elif have_cmd node; then
    js_runtime_args=(--js-runtimes node)
  elif have_cmd qjs; then
    js_runtime_args=(--js-runtimes quickjs)
  elif have_cmd bun; then
    js_runtime_args=(--js-runtimes bun)
  else
    echo "‚ùå Error: No JS runtime found (required for reliable YouTube extraction now)."
    echo "   Install one (recommended: deno OR node):"
    echo "     Ubuntu/WSL: sudo apt update && sudo apt install -y nodejs npm"
    echo "     or install deno from official docs"
    exit 1
  fi

  # DO NOT force android client by default.
  # It frequently triggers PO Token requirements and skipped formats.
  extractor_args=()
fi

# --------------------------
# Common yt-dlp args (reliability)
# --------------------------
common_dl_args=()
if [[ "$DOWNLOADER" == "yt-dlp" ]]; then
  common_dl_args=(
    --retries "$RETRIES"
    --fragment-retries "$FRAGMENT_RETRIES"
    --file-access-retries "$FRAGMENT_RETRIES"
    --retry-sleep "$RETRY_SLEEP"
    --sleep-interval 1
    --max-sleep-interval 3
    --concurrent-fragments "$CONCURRENT_FRAGMENTS"
    --continue
    --no-post-overwrites
    --ignore-errors
    --progress
    --newline
  )
else
  # youtube-dl fallback: keep it simple (some yt-dlp flags may not exist)
  common_dl_args=(
    --continue
    --ignore-errors
  )
fi

# --------------------------
# Helpers: durations + safe ffmpeg runner
# --------------------------
ffprobe_duration_sec() {
  local f="$1"
  if [[ "$FFPROBE_OK" -ne 1 || ! -f "$f" ]]; then
    echo "0"
    return 0
  fi
  ffprobe -v error -show_entries format=duration -of default=nokey=1:noprint_wrappers=1 "$f" 2>/dev/null | awk '{printf "%.3f\n", $1}'
}

run_ffmpeg() {
  # Usage: run_ffmpeg <log_file> <ffmpeg args...>
  local log_file="$1"
  shift

  if [[ "$USE_TIMEOUT" -eq 1 ]]; then
    timeout "$FFMPEG_TIMEOUT_SEC" ffmpeg -nostdin "$@" 2>>"$log_file"
  else
    ffmpeg -nostdin "$@" 2>>"$log_file"
  fi
}

# --------------------------
# ASR file creation
# --------------------------
make_asr_outputs_for_input() {
  local in_audio="$1"
  local log_file="$2"

  local stem="${in_audio%.*}"              # remove extension
  local raw_out="${stem}.asr.raw16k.wav"
  local clean_out="${stem}.asr.clean16k.wav"
  local mp3_out="${stem}.listen.mp3"

  # RAW WAV (format normalization only)
  if [[ ! -f "$raw_out" ]]; then
    echo "üéõÔ∏è  RAW ASR WAV:"
    echo "   IN : $in_audio"
    echo "   OUT: $raw_out"

    run_ffmpeg "$log_file" -hide_banner -loglevel warning -y \
      -i "$in_audio" \
      -map 0:a:0? -vn -sn -dn \
      -ac 1 -ar "$ASR_SAMPLE_RATE" -c:a pcm_s16le \
      -af "$ASR_RESYNC_FILTER" \
      "$raw_out" || {
        echo "‚ö†Ô∏è Failed to build RAW WAV: $raw_out" >>"$log_file"
      }
  fi

  # CLEAN WAV (mild cleanup)
  if [[ ! -f "$clean_out" ]]; then
    echo "üßº CLEAN ASR WAV:"
    echo "   IN : $in_audio"
    echo "   OUT: $clean_out"

    run_ffmpeg "$log_file" -hide_banner -loglevel warning -y \
      -i "$in_audio" \
      -map 0:a:0? -vn -sn -dn \
      -ac 1 -ar "$ASR_SAMPLE_RATE" -c:a pcm_s16le \
      -af "$ASR_CLEAN_FILTERS,$ASR_RESYNC_FILTER" \
      "$clean_out" || {
        echo "‚ö†Ô∏è Failed to build CLEAN WAV: $clean_out" >>"$log_file"
      }
  fi

  # Duration verification: clean must not be shorter than raw (this is your 1:46 bug)
  if [[ -f "$raw_out" && -f "$clean_out" && "$FFPROBE_OK" -eq 1 ]]; then
    local d_raw d_clean
    d_raw="$(ffprobe_duration_sec "$raw_out")"
    d_clean="$(ffprobe_duration_sec "$clean_out")"

    # If clean is suspiciously shorter, rebuild clean with ultra-safe filters
    # (no afftdn, no risky stuff; just bandlimit + limiter)
    local min_ok
    min_ok="$(awk -v r="$d_raw" 'BEGIN{printf "%.3f", (r - 0.500)}')" # allow 0.5s tolerance

    if awk -v c="$d_clean" -v m="$min_ok" 'BEGIN{exit !(c < m)}'; then
      echo "‚ö†Ô∏è CLEAN WAV seems truncated:"
      echo "   raw  : ${d_raw}s"
      echo "   clean: ${d_clean}s"
      echo "   -> rebuilding clean with safer filters (no afftdn)..."

      local safer_filters="highpass=f=80,lowpass=f=8000,alimiter=limit=0.97"
      rm -f "$clean_out" 2>/dev/null || true

      run_ffmpeg "$log_file" -hide_banner -loglevel warning -y \
        -i "$in_audio" \
        -map 0:a:0? -vn -sn -dn \
        -ac 1 -ar "$ASR_SAMPLE_RATE" -c:a pcm_s16le \
        -af "$safer_filters,$ASR_RESYNC_FILTER" \
        "$clean_out" || true

      # If still bad, fallback: clean = raw (never block the pipeline)
      d_clean="$(ffprobe_duration_sec "$clean_out")"
      min_ok="$(awk -v r="$d_raw" 'BEGIN{printf "%.3f", (r - 0.500)}')"
      if awk -v c="$d_clean" -v m="$min_ok" 'BEGIN{exit !(c < m)}'; then
        echo "‚ö†Ô∏è CLEAN still truncated after rebuild -> using RAW as CLEAN fallback."
        cp -f "$raw_out" "$clean_out"
      fi
    fi
  fi

  # Optional preview MP3 (fast QA listening)
  if [[ "$MAKE_PREVIEW_MP3" == "1" && ! -f "$mp3_out" ]]; then
    echo "üéß PREVIEW MP3:"
    echo "   IN : $in_audio"
    echo "   OUT: $mp3_out"

    run_ffmpeg "$log_file" -hide_banner -loglevel warning -y \
      -i "$in_audio" \
      -map 0:a:0? -vn -sn -dn \
      -c:a libmp3lame -b:a "$PREVIEW_MP3_BITRATE" \
      "$mp3_out" || {
        echo "‚ö†Ô∏è Failed to build preview MP3: $mp3_out" >>"$log_file"
      }
  fi
}

make_asr_files() {
  local output_dir="$1"
  local log_file="$output_dir/audio-asr-build.log"
  : > "$log_file"

  echo ""
  echo "üß™ Building ASR audio outputs under: $output_dir"
  echo "   - *.asr.raw16k.wav    (normalized only)"
  echo "   - *.asr.clean16k.wav  (mild cleanup)"
  if [[ "$MAKE_PREVIEW_MP3" == "1" ]]; then
    echo "   - *.listen.mp3        (playable QA preview)"
  fi
  echo "   Log: $log_file"
  echo ""

  local found_any=0

  # Primary path: use original downloaded best audio:
  #   <title> [id].audio.<ext>
  while IFS= read -r -d '' in_audio; do
    found_any=1
    make_asr_outputs_for_input "$in_audio" "$log_file"
  done < <(
    find "$output_dir" -type f \
      -name "*.audio.*" \
      ! -name "*.wav" \
      ! -name "*.asr.raw16k.wav" \
      ! -name "*.asr.clean16k.wav" \
      -print0
  )

  # Fallback path: if audio download failed, extract from the MP4 instead.
  if [[ "$found_any" -eq 0 ]]; then
    echo "‚ö†Ô∏è  No original audio files found. Falling back to extracting audio from MP4..." | tee -a "$log_file"
    while IFS= read -r -d '' mp4; do
      make_asr_outputs_for_input "$mp4" "$log_file"
    done < <(
      find "$output_dir" -type f \
        -name "*.mp4" \
        -print0
    )
  fi

  echo ""
  echo "‚úÖ ASR outputs step completed."
}

download_one() {
  local source_name="$1"
  local youtube_url="$2"

  local safe_source
  safe_source="$(safe_name "$source_name")"

  # ‚úÖ REQUIRED output: data/01.download/<source>/<video_name>/*
  local output_dir="$OUTPUT_ROOT/$safe_source"

  # Keep logs/archives inside the same output folder (self-contained)
  local archive_audio="$output_dir/.youtube-dl-archive.audio.txt"
  local archive_video="$output_dir/.youtube-dl-archive.video.txt"

  local log_audio="$output_dir/download-audio.log"
  local log_video="$output_dir/download-video.log"

  mkdir -p "$output_dir"

  # Cookies: runtime copy so the export is never overwritten
  local -a cookies_args=()
  if [[ -f "$COOKIES_FILE" ]]; then
    local runtime_cookie="$output_dir/.yt-dlp-cookies.runtime.txt"
    cp "$COOKIES_FILE" "$runtime_cookie"
    chmod 600 "$runtime_cookie" 2>/dev/null || true
    cookies_args=(--cookies "$runtime_cookie")
    echo "üç™ Cookies: using $COOKIES_FILE (copied -> $runtime_cookie)"
  else
    echo "‚ö†Ô∏è  Cookies: NOT FOUND at $COOKIES_FILE"
    echo "    (public videos still work, age/private may fail)"
  fi

  echo "================================"
  echo "üì• Download source: $source_name"
  echo "   URL: $youtube_url"
  echo "   Output: $output_dir"
  echo "   Using: $DOWNLOADER"
  echo "================================"

  # Base naming:
  # - original audio file: <title> [id].audio.<ext>
  # - extracted wav:       <title> [id].audio.asr.raw16k.wav (created by ffmpeg)
  # - cleaned wav:         <title> [id].audio.asr.clean16k.wav (created by ffmpeg)
  # - preview mp3:         <title> [id].audio.listen.mp3 (created by ffmpeg)
  # - mp4 video:           <title> [id].mp4
  local base="$output_dir/%(title)s [%(id)s]/%(title)s [%(id)s]"

  # --------------------------
  # 1) Download best audio (original) ‚Äî DO NOT let yt-dlp convert to WAV
  # --------------------------
  echo ""
  echo "üéß AUDIO: bestaudio (original format retained as source-of-truth)"
  set +e
  "$DOWNLOADER" \
    --format "bestaudio/best" \
    --output "${base}.audio.%(ext)s" \
    --write-info-json \
    --download-archive "$archive_audio" \
    --no-post-overwrites \
    "${common_dl_args[@]}" \
    "${js_runtime_args[@]}" \
    "${extractor_args[@]}" \
    "${cookies_args[@]}" \
    "$youtube_url" 2>&1 | tee "$log_audio"
  local audio_status=${PIPESTATUS[0]}
  set -e

  if [[ "$audio_status" -ne 0 ]]; then
    echo "‚ö†Ô∏è  Audio download finished with errors (exit code $audio_status). Check: $log_audio"
  else
    echo "‚úÖ Audio download finished OK. Log: $log_audio"
  fi

  # --------------------------
  # 1b) Create ASR-safe WAVs (raw + clean) + preview mp3
  # --------------------------
  make_asr_files "$output_dir"

  # --------------------------
  # 2) Download MP4 video (best effort)
  # --------------------------
  echo ""
  echo "üé• VIDEO: MP4 download"

  # Reliability-first default:
  #   - progressive MP4 avoids many 403s caused by separate BV+BA fragment fetching
  VIDEO_FORMAT="${VIDEO_FORMAT:-best[ext=mp4]/best}"

  # If you *really* want bestvideo+audio merging, enable:
  #   HIGH_QUALITY_VIDEO=1 ./scripts/training-data/01.download ...
  if [[ "${HIGH_QUALITY_VIDEO:-0}" == "1" ]]; then
    VIDEO_FORMAT="bv*[ext=mp4]+ba[ext=m4a]/b[ext=mp4]/bv*+ba/b"
    echo "    (HQ MODE enabled: bestvideo+audio merge)"
  else
    echo "    (SAFE MODE: progressive mp4 preferred)"
  fi

  set +e
  "$DOWNLOADER" \
    --format "$VIDEO_FORMAT" \
    --merge-output-format mp4 \
    --output "${base}.%(ext)s" \
    --write-info-json \
    --download-archive "$archive_video" \
    --no-post-overwrites \
    "${common_dl_args[@]}" \
    "${js_runtime_args[@]}" \
    "${extractor_args[@]}" \
    "${cookies_args[@]}" \
    "$youtube_url" 2>&1 | tee "$log_video"
  local video_status=${PIPESTATUS[0]}
  set -e

  if [[ "$video_status" -ne 0 ]]; then
    echo "‚ö†Ô∏è  Video download finished with errors (exit code $video_status). Check: $log_video"
  else
    echo "‚úÖ Video download finished OK. Log: $log_video"
  fi

  echo ""
  echo "‚úÖ Done: $source_name"
  echo "   Folder: $output_dir"
  echo ""
}

download_from_sources() {
  local sources_file="${1:-$ROOT_DIR/docs/sources.txt}"

  if [[ ! -f "$sources_file" ]]; then
    echo "‚ùå Sources file not found: $sources_file"
    exit 1
  fi

  echo "üì• Downloading from sources file: $sources_file"
  echo "üìÅ Output root: $OUTPUT_ROOT"
  echo ""

  while IFS= read -r line; do
    [[ -z "${line//[[:space:]]/}" ]] && continue
    [[ "$line" =~ ^[[:space:]]*# ]] && continue

    local source_name=""
    local youtube_url=""
    if [[ "$line" == *"|"* ]]; then
      source_name="${line%%|*}"
      youtube_url="${line#*|}"
    else
      # best-effort: whitespace split (first token = name, rest = url)
      source_name="${line%%[[:space:]]*}"
      youtube_url="${line#"$source_name"}"
      youtube_url="${youtube_url#"${youtube_url%%[![:space:]]*}"}"
    fi

    [[ -z "$source_name" || -z "$youtube_url" ]] && continue
    download_one "$source_name" "$youtube_url"
  done < "$sources_file"

  echo "‚úÖ All sources processed."
}

# CLI
case "${1:-}" in
  -h|--help)
    usage
    exit 0
    ;;
  --sources)
    download_from_sources "${2:-}"
    ;;
  "")
    usage
    exit 1
    ;;
  *)
    if [[ $# -lt 2 ]]; then
      echo "‚ùå Error: Need both <source_name> and <youtube_url>"
      echo ""
      usage
      exit 1
    fi
    download_one "$1" "$2"
    ;;
esac
