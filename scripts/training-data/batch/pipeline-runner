#!/usr/bin/env python3
"""
pipeline-runner — Conveyor-belt pipeline orchestrator.

Each video progresses through stages 06→09 sequentially, but multiple videos
are in-flight simultaneously. A shared semaphore caps concurrent LLM calls.

Usage:
    ./pipeline-runner P001.1                     # default: 10 parallel LLM calls
    ./pipeline-runner P001.1 --parallel 5        # limit concurrent LLM calls
    ./pipeline-runner P001.1 --from 06e          # resume from a stage
    ./pipeline-runner P001.1 --dry-run           # show what would run
"""

import argparse
import asyncio
import json
import os
import re
import sys
import tempfile
import time
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, List, Optional, Set

from quarantine_updater import extract_from_cross_stage_or_chunks

SCRIPT_DIR = Path(__file__).resolve().parent
REPO_ROOT = SCRIPT_DIR.parent.parent.parent
BATCHES_DIR = REPO_ROOT / "docs" / "pipeline" / "batches"
DATA_DIR = REPO_ROOT / "data"
QUARANTINE_DIR = DATA_DIR / "validation" / "quarantine"
VENV_PYTHON = str(REPO_ROOT / ".venv" / "bin" / "python")
TSX_LOADER = REPO_ROOT / "node_modules" / "tsx" / "dist" / "loader.mjs"
VALIDATION_DIR = REPO_ROOT / "scripts" / "training-data" / "validation"

VIDEO_ID_RE = re.compile(r"\[([A-Za-z0-9_-]{11})\]")

DEFAULT_PARALLEL = 10


# ── Stage registry ──────────────────────────────────────────────────────────

@dataclass
class Stage:
    key: str
    script: str
    needs_llm: bool

STAGES = [
    Stage("06",  "06.LLM.video-type",              needs_llm=True),
    Stage("06b", "06b.LLM.verify",                  needs_llm=True),
    Stage("06c", "06c.DET.patch",                    needs_llm=False),
    Stage("06d", "06d.DET.sanitize",                 needs_llm=False),
    Stage("06e", "06e.LLM.quality-check",            needs_llm=True),
    Stage("06f", "06f.DET.damage-map",               needs_llm=False),
    Stage("06g", "06g.LLM.damage-adjudicator",       needs_llm=True),
    Stage("06h", "06h.DET.confidence-propagation",    needs_llm=False),
    Stage("07",  "07.LLM.content",                   needs_llm=True),
    Stage("08",  "08.DET.taxonomy-validation",        needs_llm=False),
    Stage("09",  "09.EXT.chunk-embed.ts",            needs_llm=False),
]

STAGE_KEYS = [s.key for s in STAGES]
STAGES_SUPPORTING_QUARANTINE = {"06c", "06d", "06e", "06f", "06g", "06h", "07", "08", "09"}
STAGES_SUPPORTING_OVERWRITE = {"06", "06b", "06c", "06d", "06e", "06f", "06g", "06h", "07"}


# ── Video state tracking ────────────────────────────────────────────────────

@dataclass
class VideoState:
    video_id: str
    source: str
    folder: str
    current_stage: str = ""
    status: str = "pending"   # pending | running | done | failed | quarantined
    error_stage: str = ""
    error_msg: str = ""
    quarantine_checks: Set[str] = field(default_factory=set)
    quarantine_reasons: List[dict] = field(default_factory=list)


# ── Manifest parsing ────────────────────────────────────────────────────────

def load_manifest_videos(manifest_path: Path) -> List[VideoState]:
    """Parse manifest into list of VideoState entries."""
    videos = []
    for line in manifest_path.read_text(encoding="utf-8").splitlines():
        line = line.strip()
        if not line or line.startswith("#"):
            continue
        parts = line.split("|", 1)
        if len(parts) != 2:
            continue
        source = parts[0].strip()
        folder = parts[1].strip()
        match = VIDEO_ID_RE.search(folder)
        if not match:
            continue
        videos.append(VideoState(
            video_id=match.group(1),
            source=source,
            folder=folder,
        ))
    return videos


# ── Subprocess execution ────────────────────────────────────────────────────

def build_stage_command(
    stage: Stage,
    manifest_path: str,
    quarantine_file: Optional[Path] = None,
    confidence_band_high_threshold: Optional[float] = None,
    confidence_band_medium_threshold: Optional[float] = None,
    min_chunk_confidence: Optional[float] = None,
) -> List[str]:
    """Build the command list to execute a stage script."""
    script_path = str(REPO_ROOT / "scripts" / "training-data" / stage.script)

    if stage.script.endswith(".ts"):
        cmd = ["node", "--import", str(TSX_LOADER), script_path]
    else:
        cmd = [VENV_PYTHON, "-u", script_path]

    cmd.extend(["--manifest", manifest_path])
    if stage.key in STAGES_SUPPORTING_OVERWRITE:
        # Single-path strictness: always recompute stage outputs so downstream
        # artifacts cannot drift from updated upstream inputs.
        cmd.append("--overwrite")

    # In runner mode, Stage 07 executes per-video manifests. Its built-in
    # Claude preflight runs before pending-work detection, so running preflight
    # per video causes avoidable failures/churn when no LLM calls are needed.
    if stage.key == "07":
        cmd.append("--skip-llm-preflight")
    # Stage 08 per-video runs are only used for immediate gating progression.
    # Canonical manifest-level Stage 08 reporting is emitted in end-of-run
    # validation, so skip per-video report files to avoid temp-manifest clutter.
    if stage.key == "08":
        cmd.append("--no-report")

    if stage.key == "06h":
        if confidence_band_high_threshold is not None:
            cmd.extend(["--confidence-band-high-threshold", str(confidence_band_high_threshold)])
        if confidence_band_medium_threshold is not None:
            cmd.extend(["--confidence-band-medium-threshold", str(confidence_band_medium_threshold)])
    if stage.key == "09" and min_chunk_confidence is not None:
        cmd.extend(["--min-chunk-confidence", str(min_chunk_confidence)])

    if stage.key in STAGES_SUPPORTING_QUARANTINE and quarantine_file and quarantine_file.exists():
        cmd.extend(["--quarantine-file", str(quarantine_file)])

    return cmd


async def run_subprocess(
    cmd: List[str],
    stage: Stage,
    video_id: str,
    log_prefix: str,
) -> int:
    """Run a stage subprocess and stream its output."""
    proc = await asyncio.create_subprocess_exec(
        *cmd,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.STDOUT,
    )
    assert proc.stdout is not None
    while True:
        line = await proc.stdout.readline()
        if not line:
            break
        text = line.decode("utf-8", errors="replace").rstrip()
        print(f"{log_prefix} [{stage.key}] {text}")
    await proc.wait()
    return proc.returncode or 0


# ── Quarantine check ────────────────────────────────────────────────────────

def load_quarantine_video_ids(quarantine_file: Optional[Path]) -> Set[str]:
    if not quarantine_file or not quarantine_file.exists():
        return set()
    try:
        payload = json.loads(quarantine_file.read_text(encoding="utf-8"))
    except (json.JSONDecodeError, OSError):
        return set()
    if not isinstance(payload, dict):
        return set()
    ids = payload.get("quarantined_video_ids")
    if not isinstance(ids, list):
        return set()
    return {str(v).strip() for v in ids if isinstance(v, str) and re.fullmatch(r"[A-Za-z0-9_-]{11}", v.strip())}


def add_quarantine_reason(vs: VideoState, check: str, message: str) -> None:
    if check not in vs.quarantine_checks:
        vs.quarantine_checks.add(check)
        vs.quarantine_reasons.append(
            {
                "severity": "error",
                "check": check,
                "message": message[:300],
            }
        )


async def run_contract_preflight(
    stage: Stage,
    manifest_path: str,
    quarantine_file: Optional[Path],
    log_prefix: str,
) -> int:
    cmd = [
        VENV_PYTHON,
        "-u",
        str(VALIDATION_DIR / "validate_stage_contract.py"),
        "--manifest",
        manifest_path,
        "--stage",
        stage.key,
    ]
    if quarantine_file and quarantine_file.exists():
        cmd.extend(["--quarantine-file", str(quarantine_file)])

    proc = await asyncio.create_subprocess_exec(
        *cmd,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.STDOUT,
    )
    assert proc.stdout is not None
    while True:
        line = await proc.stdout.readline()
        if not line:
            break
        text = line.decode("utf-8", errors="replace").rstrip()
        print(f"{log_prefix} [preflight:{stage.key}] {text}")
    await proc.wait()
    return proc.returncode or 0


async def run_stage_validator_errors(
    stage: Stage,
    manifest_path: str,
    log_prefix: str,
) -> Set[str]:
    if stage.key == "07":
        cmd = [
            VENV_PYTHON,
            "-u",
            str(VALIDATION_DIR / "validate_cross_stage.py"),
            "--manifest",
            manifest_path,
            "--json",
        ]
    elif stage.key == "09":
        cmd = [
            VENV_PYTHON,
            "-u",
            str(VALIDATION_DIR / "validate_chunks.py"),
            "--manifest",
            manifest_path,
            "--json",
        ]
    else:
        return set()

    proc = await asyncio.create_subprocess_exec(
        *cmd,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.DEVNULL,
    )
    stdout, _ = await proc.communicate()
    text = stdout.decode("utf-8", errors="replace").strip()
    if not text:
        return set()
    try:
        payload = json.loads(text)
    except json.JSONDecodeError:
        print(f"{log_prefix} [validate:{stage.key}] WARNING: non-JSON validator output")
        return set()
    if not isinstance(payload, dict):
        return set()
    quarantined_ids, _ = extract_from_cross_stage_or_chunks(payload, stage_label=stage.key)
    return quarantined_ids


def check_06b_verdict(video_id: str, source: str) -> bool:
    """Check if a video was REJECTED by stage 06b. Returns True if REJECT."""
    verify_dir = DATA_DIR / "06b.LLM.verify" / source
    if not verify_dir.exists():
        return False
    candidates = list(verify_dir.rglob(f"*{video_id}*.verification.json"))
    for cpath in candidates:
        try:
            payload = json.loads(cpath.read_text(encoding="utf-8"))
        except (json.JSONDecodeError, OSError):
            continue
        verdict = str(
            payload.get("verdict") or payload.get("overall_verdict") or ""
        ).strip().upper()
        if verdict == "REJECT":
            return True
    return False


def write_quarantine_file(
    quarantine_path: Path,
    quarantined: List[VideoState],
) -> None:
    """Write quarantine file in the standard format."""
    if not quarantined:
        return
    quarantine_path.parent.mkdir(parents=True, exist_ok=True)

    # Load existing quarantine to merge
    existing_ids: Set[str] = set()
    existing_videos: List[dict] = []
    if quarantine_path.exists():
        try:
            data = json.loads(quarantine_path.read_text(encoding="utf-8"))
            existing_videos = data.get("videos", [])
            existing_ids = set(data.get("quarantined_video_ids", []))
        except (json.JSONDecodeError, OSError):
            pass

    for vs in quarantined:
        if vs.video_id not in existing_ids:
            existing_ids.add(vs.video_id)
            checks = sorted(vs.quarantine_checks) if vs.quarantine_checks else ["stage06b_reject"]
            reasons = (
                vs.quarantine_reasons
                if vs.quarantine_reasons
                else [
                    {
                        "severity": "error",
                        "check": "stage06b_reject",
                        "message": "Stage 06b verdict: REJECT",
                    }
                ]
            )
            existing_videos.append({
                "video_id": vs.video_id,
                "checks": checks,
                "reasons": reasons,
            })

    out = {
        "version": 1,
        "generated_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        "quarantine_level": "error",
        "quarantined_video_count": len(existing_ids),
        "quarantined_video_ids": sorted(existing_ids),
        "videos": existing_videos,
    }
    quarantine_path.write_text(
        json.dumps(out, indent=2, ensure_ascii=False) + "\n",
        encoding="utf-8",
    )


# ── Per-video pipeline ──────────────────────────────────────────────────────

async def run_video(
    vs: VideoState,
    stages: List[Stage],
    semaphore: asyncio.Semaphore,
    quarantine_file: Optional[Path],
    full_manifest_path: Path,
    confidence_band_high_threshold: Optional[float],
    confidence_band_medium_threshold: Optional[float],
    min_chunk_confidence: Optional[float],
    dry_run: bool,
    progress: Dict[str, str],
) -> None:
    """Run one video through all stages sequentially."""
    log_prefix = f"[{vs.video_id}]"
    if vs.video_id in load_quarantine_video_ids(quarantine_file):
        vs.status = "quarantined"
        add_quarantine_reason(vs, "preexisting_quarantine", "Video was already quarantined before this run.")
        progress[vs.video_id] = "QUARANTINED"
        print(f"{log_prefix} SKIP: already quarantined before run")
        return

    for stage in stages:
        vs.current_stage = stage.key
        vs.status = "running"
        progress[vs.video_id] = stage.key

        # Create temp 1-video manifest
        fd, tmp_manifest = tempfile.mkstemp(suffix=".txt", prefix=f"manifest_{vs.video_id}_")
        try:
            with os.fdopen(fd, "w") as f:
                f.write(f"{vs.source} | {vs.folder}\n")

            cmd = build_stage_command(
                stage,
                tmp_manifest,
                quarantine_file,
                confidence_band_high_threshold=confidence_band_high_threshold,
                confidence_band_medium_threshold=confidence_band_medium_threshold,
                min_chunk_confidence=min_chunk_confidence,
            )

            if dry_run:
                label = "LLM" if stage.needs_llm else "DET"
                print(f"{log_prefix} [{label}] {stage.key}: {' '.join(cmd)}")
                continue

            preflight_rc = await run_contract_preflight(stage, tmp_manifest, quarantine_file, log_prefix)
            if preflight_rc != 0:
                vs.status = "failed"
                vs.error_stage = stage.key
                vs.error_msg = f"Contract preflight failed (exit {preflight_rc})"
                print(f"{log_prefix} FAILED at stage {stage.key} (contract preflight exit {preflight_rc})")
                progress[vs.video_id] = f"{stage.key}(PREFAIL)"
                return

            if stage.needs_llm:
                progress[vs.video_id] = f"{stage.key}(wait)"
                async with semaphore:
                    progress[vs.video_id] = f"{stage.key}(llm)"
                    rc = await run_subprocess(cmd, stage, vs.video_id, log_prefix)
            else:
                rc = await run_subprocess(cmd, stage, vs.video_id, log_prefix)

            if rc != 0:
                vs.status = "failed"
                vs.error_stage = stage.key
                vs.error_msg = f"Exit code {rc}"
                print(f"{log_prefix} FAILED at stage {stage.key} (exit code {rc})")
                progress[vs.video_id] = f"{stage.key}(FAIL)"
                return

            # Post-06b: check for REJECT verdict
            if stage.key == "06b":
                if check_06b_verdict(vs.video_id, vs.source):
                    vs.status = "quarantined"
                    add_quarantine_reason(vs, "stage06b_reject", "Stage 06b verdict: REJECT")
                    print(f"{log_prefix} QUARANTINED: REJECT verdict from 06b")
                    progress[vs.video_id] = "QUARANTINED"
                    return

            if stage.key in ("07", "09"):
                error_ids = await run_stage_validator_errors(stage, str(full_manifest_path), log_prefix)
                if vs.video_id in error_ids:
                    vs.status = "quarantined"
                    if stage.key == "07":
                        add_quarantine_reason(
                            vs,
                            "stage07_cross_stage_error",
                            "Stage 07 cross-stage validation reported error severity issues.",
                        )
                    else:
                        add_quarantine_reason(
                            vs,
                            "stage09_chunk_validation_error",
                            "Stage 09 chunk validation reported error severity issues.",
                        )
                    print(f"{log_prefix} QUARANTINED: stage {stage.key} validation errors")
                    progress[vs.video_id] = "QUARANTINED"
                    return

        finally:
            try:
                os.unlink(tmp_manifest)
            except OSError:
                pass

    vs.status = "done"
    progress[vs.video_id] = "done"
    print(f"[{vs.video_id}] COMPLETE")


# ── Progress display ────────────────────────────────────────────────────────

async def progress_reporter(
    videos: List[VideoState],
    progress: Dict[str, str],
    interval: float = 5.0,
) -> None:
    """Periodically print a status summary line."""
    total = len(videos)
    while True:
        await asyncio.sleep(interval)
        done = sum(1 for v in videos if v.status in ("done", "failed", "quarantined"))
        active = []
        for vid, stage in sorted(progress.items()):
            if stage not in ("done", "QUARANTINED") and "FAIL" not in stage:
                active.append(f"{vid[:7]}:{stage}")
        summary = " ".join(active[:8])
        if len(active) > 8:
            summary += f" +{len(active) - 8}"
        print(f"\n--- [{done}/{total} done] {summary} ---\n")
        if done >= total:
            break


# ── End-of-run validation ───────────────────────────────────────────────────

async def run_end_of_run_validation(
    sub_id: str,
    quarantine_file: Optional[Path],
) -> int:
    """Run end-of-run validation through the same code path as sequential mode."""
    cmd = ["bash", str(SCRIPT_DIR / "sub-batch-pipeline"), sub_id, "--validate"]
    if quarantine_file and quarantine_file.exists():
        cmd.extend(["--quarantine-file", str(quarantine_file)])

    print("\n=== End-of-run validation (delegated) ===\n")
    proc = await asyncio.create_subprocess_exec(*cmd)
    await proc.wait()
    return proc.returncode or 0


# ── Main orchestrator ────────────────────────────────────────────────────────

async def run_pipeline(args: argparse.Namespace) -> int:
    sub_id = args.sub_batch
    manifest_path = BATCHES_DIR / f"{sub_id}.txt"
    if not manifest_path.exists():
        print(f"ERROR: Manifest not found: {manifest_path}", file=sys.stderr)
        return 1

    videos = load_manifest_videos(manifest_path)
    if not videos:
        print(f"ERROR: No videos found in manifest: {manifest_path}", file=sys.stderr)
        return 1

    # Determine stage range
    start_key = args.start_from
    if start_key not in STAGE_KEYS:
        print(f"ERROR: Unknown stage: {start_key} (valid: {', '.join(STAGE_KEYS)})", file=sys.stderr)
        return 1
    start_idx = STAGE_KEYS.index(start_key)
    stages = STAGES[start_idx:]

    parallel = args.parallel
    semaphore = asyncio.Semaphore(parallel)
    if args.quarantine_file:
        quarantine_file = Path(args.quarantine_file)
        if not quarantine_file.is_absolute():
            quarantine_file = REPO_ROOT / quarantine_file
    else:
        quarantine_file = QUARANTINE_DIR / f"{sub_id}.json"

    print()
    print("=" * 56)
    print(f"  Pipeline Runner: {sub_id}")
    print(f"  Videos: {len(videos)}")
    print(f"  Stages: {' → '.join(s.key for s in stages)}")
    print(f"  Parallel LLM calls: {parallel}")
    if args.dry_run:
        print("  Mode: DRY RUN")
    print("=" * 56)
    print()

    # Shared progress tracker
    progress: Dict[str, str] = {v.video_id: "pending" for v in videos}

    # Launch all video pipelines + progress reporter
    tasks = [
        asyncio.create_task(
            run_video(
                vs,
                stages,
                semaphore,
                quarantine_file,
                manifest_path,
                args.confidence_band_high_threshold,
                args.confidence_band_medium_threshold,
                args.min_chunk_confidence,
                args.dry_run,
                progress,
            )
        )
        for vs in videos
    ]
    if not args.dry_run:
        reporter = asyncio.create_task(progress_reporter(videos, progress))
    else:
        reporter = None

    await asyncio.gather(*tasks)
    if reporter:
        reporter.cancel()
        try:
            await reporter
        except asyncio.CancelledError:
            pass

    # Write quarantine file for any rejected videos
    quarantined = [v for v in videos if v.status == "quarantined"]
    if quarantined:
        write_quarantine_file(quarantine_file, quarantined)

    # Summary
    done_count = sum(1 for v in videos if v.status == "done")
    fail_count = sum(1 for v in videos if v.status == "failed")
    q_count = sum(1 for v in videos if v.status == "quarantined")

    print()
    print("=" * 56)
    print(f"  Pipeline Summary: {sub_id}")
    print("=" * 56)
    print(f"  Passed:      {done_count}/{len(videos)}")
    if q_count:
        print(f"  Quarantined: {q_count}")
        for v in quarantined:
            print(f"    {v.video_id}")
    if fail_count:
        print(f"  Failed:      {fail_count}")
        for v in videos:
            if v.status == "failed":
                print(f"    {v.video_id} at stage {v.error_stage}: {v.error_msg}")
    print("=" * 56)
    print()

    validation_rc = 0
    # End-of-run validation (skip if dry run or all failed)
    if not args.dry_run and done_count > 0:
        validation_rc = await run_end_of_run_validation(sub_id, quarantine_file)
        if validation_rc != 0:
            print(f"[pipeline-runner] End-of-run validation failed (exit {validation_rc})", file=sys.stderr)

    return 1 if fail_count > 0 or validation_rc != 0 else 0


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Conveyor-belt pipeline runner — process videos in parallel across stages.",
    )
    parser.add_argument(
        "sub_batch",
        help="Sub-batch ID (e.g., P001.1)",
    )
    parser.add_argument(
        "--parallel", "-j",
        type=int,
        default=DEFAULT_PARALLEL,
        help=f"Max concurrent LLM calls (default: {DEFAULT_PARALLEL})",
    )
    parser.add_argument(
        "--from",
        dest="start_from",
        default="06",
        help="Stage to start from (default: 06)",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Show commands without executing",
    )
    parser.add_argument(
        "--quarantine-file",
        help="Optional quarantine JSON path (default: data/validation/quarantine/<sub-batch>.json)",
    )
    parser.add_argument(
        "--confidence-band-high-threshold",
        type=float,
        help="Optional Stage 06h high confidence band threshold override (0..1)",
    )
    parser.add_argument(
        "--confidence-band-medium-threshold",
        type=float,
        help="Optional Stage 06h medium confidence band threshold override (0..1)",
    )
    parser.add_argument(
        "--min-chunk-confidence",
        type=float,
        help="Optional Stage 09 chunk confidence floor override (0..1)",
    )
    args = parser.parse_args()
    for name in ("confidence_band_high_threshold", "confidence_band_medium_threshold", "min_chunk_confidence"):
        value = getattr(args, name)
        if value is not None and not (0.0 <= float(value) <= 1.0):
            parser.error(f"--{name.replace('_', '-')} must be within [0,1]")
    if (
        args.confidence_band_high_threshold is not None
        and args.confidence_band_medium_threshold is not None
        and args.confidence_band_medium_threshold > args.confidence_band_high_threshold
    ):
        parser.error("--confidence-band-medium-threshold cannot exceed --confidence-band-high-threshold")
    rc = asyncio.run(run_pipeline(args))
    sys.exit(rc)


if __name__ == "__main__":
    main()
