#!/usr/bin/env python3
"""
scripts/training-data/08b.content

Content Enrichment using Ollama LLM (renamed from 09.enrich in pipeline consolidation)

Reads:
  - Interaction JSONL files:
      data/08a.structure/<source>/<video>/*.interactions.jsonl

Writes:
  - Enriched ground truth JSON:
      data/08b.content/<source>/<video>/*.enriched.json

The enrichment adds:
  - Refined phase boundaries (opener/hook/vibe/close) with turn indices
  - Detailed technique detection with explanations
  - Topic extraction from conversation content
  - Interaction quality assessment
  - Commentary section identification

Use:

  A) One source (video / playlist / channel):
     ./scripts/training-data/08b.content "daily_evolution" "https://www.youtube.com/watch?v=utuuVOXJunM"

  B) Batch from sources file:
     ./scripts/training-data/08b.content --sources
     ./scripts/training-data/08b.content --sources docs/sources.txt

Environment:
  OLLAMA_API_URL=http://localhost:11434
  OLLAMA_MODEL=llama3.1
"""

from __future__ import annotations

import argparse
import json
import os
import re
import shlex
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import requests


# ---------------------------
# Ollama configuration
# ---------------------------

OLLAMA_BASE_URL = os.environ.get("OLLAMA_API_URL", "http://localhost:11434")
OLLAMA_MODEL = os.environ.get("OLLAMA_MODEL", "llama3.1")


# ---------------------------
# Technique and Topic Taxonomies
# ---------------------------

# Comprehensive daygame technique list with descriptions for prompting
TECHNIQUE_TAXONOMY = {
    # Openers
    "direct_opener": "Explicitly stating attraction/interest upfront ('I think you're attractive')",
    "indirect_opener": "Starting conversation without revealing intent (asking for directions, opinion)",
    "situational_opener": "Opening based on something happening in the environment",
    "observation_opener": "Commenting on something specific about her (outfit, book, behavior)",

    # Attraction techniques
    "push_pull": "Giving a compliment then taking it away, or vice versa ('You seem cool... for a tourist')",
    "tease": "Playful mocking or joking at her expense in a fun way",
    "cold_read": "Making an assumption about her personality/life ('You look like a yoga teacher')",
    "role_play": "Creating imaginary scenarios together ('We'd make terrible dance partners')",
    "disqualification": "Playfully suggesting you two wouldn't work out",
    "neg": "Backhanded compliment or subtle challenge to her value",
    "DHV": "Demonstration of higher value through stories or behavior",
    "preselection": "Implying other women are interested in you",

    # Connection techniques
    "qualification": "Asking what makes her special beyond looks ('What's your passion?')",
    "statement_of_intent": "Clearly expressing romantic/sexual interest",
    "grounding": "Sharing personal details to build trust and rapport",
    "storytelling": "Using engaging stories to convey personality",
    "vulnerability": "Sharing something genuine/personal to create connection",
    "callback_humor": "Referencing something mentioned earlier in conversation",

    # Physical/Logistics
    "kino": "Physical touch escalation (handshake, high-five, arm touch)",
    "proximity": "Moving closer or positioning strategically",
    "false_time_constraint": "Saying you need to leave soon to reduce pressure",
    "compliance_test": "Small requests to gauge her interest level",

    # Closing techniques
    "number_close": "Asking for her phone number",
    "instagram_close": "Asking for her Instagram handle",
    "soft_close": "Suggesting future meeting without immediate commitment",
    "assumptive_close": "Acting as if she's already agreed ('So when are you free?')",
    "instant_date": "Suggesting to continue hanging out right now",
    "bounce": "Moving to a different location together",

    # Approach mechanics
    "front_stop": "Stopping her from the front, facing her directly",
    "side_stop": "Approaching from the side, walking alongside",
    "seated_approach": "Approaching someone who is sitting down",
}

TOPIC_TAXONOMY = {
    # Personal info
    "origin": "Where she's from, nationality, hometown",
    "career": "Job, profession, what she does for work",
    "education": "Studies, university, school",
    "hobby": "Interests, activities, passions",
    "travel": "Trips, places visited, travel plans",
    "living_situation": "Where she lives, roommates, neighborhood",

    # Appearance-related
    "appearance": "General looks, attractiveness comments",
    "style": "Fashion, clothing choices, aesthetic",
    "hair": "Hair color, style, length",
    "eyes": "Eye color, eye contact",
    "height": "How tall she is",
    "tattoos": "Body art, piercings",
    "fitness": "Gym, exercise, sports",

    # Personality/Vibe
    "personality": "Character traits, demeanor",
    "energy": "Vibe, aura, presence",
    "age": "How old she is, age-related topics",

    # Logistics
    "plans": "What she's doing today, schedule",
    "contact": "Exchanging numbers, social media",
    "logistics": "Meeting up, availability, dating",
    "relationship": "Boyfriend, dating status",

    # Context
    "food_drinks": "Coffee, restaurants, bars",
    "location": "The current place, area, city",
    "weather": "Weather-related conversation",
    "events": "Concerts, festivals, activities happening",
}


@dataclass
class EnrichedInteraction:
    id: int
    interaction_type: str  # "approach" or "commentary"
    description: str
    start_time: float
    end_time: float
    phases: Dict[str, Optional[Dict[str, int]]]  # phase -> {start_turn, end_turn}
    outcome: str
    outcome_confidence: float
    topics_discussed: List[str]
    techniques_used: List[Dict[str, str]]  # [{technique, example, turn_index}]
    interaction_quality: Dict[str, Any]  # quality metrics
    original_turns: List[Dict]


def call_ollama(prompt: str, retries: int = 3, timeout: int = 120) -> Optional[str]:
    """Call Ollama API with retry logic."""
    for attempt in range(retries):
        try:
            response = requests.post(
                f"{OLLAMA_BASE_URL}/api/generate",
                json={
                    "model": OLLAMA_MODEL,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.2,
                        "num_predict": 3000,
                    }
                },
                timeout=timeout
            )
            if response.ok:
                return response.json().get("response", "")
        except requests.exceptions.RequestException as e:
            if attempt < retries - 1:
                time.sleep(2 ** attempt)  # Exponential backoff
                continue
            print(f"[08b.content] Ollama error: {e}")
    return None


def build_enrichment_prompt(interaction: Dict, interaction_idx: int) -> str:
    """Build a detailed prompt for Ollama to enrich the interaction."""

    turns = interaction.get("turns", [])

    # Format conversation for the prompt
    conversation_lines = []
    for i, turn in enumerate(turns):
        speaker = turn.get("speaker", "unknown")
        text = turn.get("text", "").strip()
        phase = turn.get("phase", "unknown")

        # Map speaker labels
        speaker_label = "COACH" if speaker in ("coach", "spk_0") else "GIRL" if speaker in ("target", "girl") else speaker.upper()
        conversation_lines.append(f"[Turn {i}] {speaker_label}: {text}")

    conversation_text = "\n".join(conversation_lines)

    # Build technique list for prompt
    technique_list = "\n".join([f"  - {k}: {v}" for k, v in list(TECHNIQUE_TAXONOMY.items())[:25]])

    # Build topic list for prompt
    topic_list = ", ".join(list(TOPIC_TAXONOMY.keys()))

    prompt = f"""You are an expert daygame analyst. Analyze this street approach interaction and extract detailed metadata.

INTERACTION #{interaction_idx}
Duration: {interaction.get('start_time', 0):.1f}s - {interaction.get('end_time', 0):.1f}s
Current outcome: {interaction.get('outcome', 'unknown')}

CONVERSATION:
{conversation_text}

ANALYSIS TASKS:

1. INTERACTION TYPE: Is this an "approach" (coach talking to a woman) or "commentary" (coach talking to camera/explaining)?

2. DESCRIPTION: Write a concise 10-20 word description of what happens in this interaction.

3. PHASES: Identify which turns belong to each phase. Daygame phases are:
   - opener: The initial approach and opening lines (usually turns 0-2)
   - hook: When she shows initial positive response/engagement (she responds warmly, asks questions back)
   - vibe: Extended conversation, banter, building connection, sharing stories
   - close: Attempting to get contact info or set up a date

   Return start_turn and end_turn indices (0-indexed) for each phase, or null if not present.

4. TECHNIQUES USED: Identify specific daygame techniques demonstrated. Common techniques:
{technique_list}

   For each technique found, note which turn it appears in and quote a brief example.

5. TOPICS DISCUSSED: Which topics came up in conversation?
   Available topics: {topic_list}
   Only include topics that were actually discussed, not just mentioned in passing.

6. INTERACTION QUALITY: Assess the interaction:
   - hook_point_reached: Did she become genuinely engaged? (true/false)
   - investment_level: How much did she invest? (low/medium/high)
   - vibe_quality: How was the conversational energy? (awkward/neutral/good/great)
   - close_attempted: Did he try to close? (true/false)
   - close_success: Was the close successful? (true/false/partial/unknown)

Return your analysis as valid JSON only. No explanation text before or after.

EXAMPLE OUTPUT FORMAT:
{{
  "interaction_type": "approach",
  "description": "Direct opener on blonde girl, good vibe, number close successful",
  "phases": {{
    "opener": {{"start_turn": 0, "end_turn": 2}},
    "hook": {{"start_turn": 3, "end_turn": 5}},
    "vibe": {{"start_turn": 6, "end_turn": 15}},
    "close": {{"start_turn": 16, "end_turn": 18}}
  }},
  "techniques_used": [
    {{"technique": "direct_opener", "turn_index": 0, "example": "I saw you and had to say hi"}},
    {{"technique": "cold_read", "turn_index": 4, "example": "You look like you do yoga"}},
    {{"technique": "push_pull", "turn_index": 8, "example": "You seem cool... for a tourist"}}
  ],
  "topics_discussed": ["origin", "career", "travel", "contact"],
  "interaction_quality": {{
    "hook_point_reached": true,
    "investment_level": "medium",
    "vibe_quality": "good",
    "close_attempted": true,
    "close_success": true
  }},
  "refined_outcome": "number"
}}

YOUR JSON RESPONSE:"""

    return prompt


def parse_llm_response(response: str) -> Optional[Dict]:
    """Parse JSON from LLM response, handling various formats."""
    if not response:
        return None

    try:
        # Try to find JSON in code block
        code_block_match = re.search(r"```(?:json)?\s*(\{[\s\S]*?\})\s*```", response)
        if code_block_match:
            return json.loads(code_block_match.group(1))

        # Try to find raw JSON object
        start = response.find("{")
        if start != -1:
            bracket_count = 0
            for i, char in enumerate(response[start:], start):
                if char == "{":
                    bracket_count += 1
                elif char == "}":
                    bracket_count -= 1
                    if bracket_count == 0:
                        json_str = response[start:i + 1]
                        return json.loads(json_str)
    except (json.JSONDecodeError, ValueError) as e:
        print(f"[08b.content] JSON parse error: {e}")
        print(f"[08b.content] Response preview: {response[:500]}...")

    return None


def enrich_interaction(interaction: Dict, interaction_idx: int) -> Dict:
    """Use Ollama to enrich a single interaction with detailed metadata."""

    prompt = build_enrichment_prompt(interaction, interaction_idx)
    response = call_ollama(prompt)

    # Default enrichment if LLM fails
    default_enrichment = {
        "interaction_type": "approach",
        "description": f"Interaction {interaction_idx}",
        "phases": {
            "opener": None,
            "hook": None,
            "vibe": None,
            "close": None
        },
        "techniques_used": [],
        "topics_discussed": [],
        "interaction_quality": {
            "hook_point_reached": False,
            "investment_level": "unknown",
            "vibe_quality": "unknown",
            "close_attempted": False,
            "close_success": "unknown"
        },
        "refined_outcome": interaction.get("outcome", "unknown")
    }

    if not response:
        return default_enrichment

    parsed = parse_llm_response(response)
    if not parsed:
        return default_enrichment

    # Merge parsed data with defaults
    for key in default_enrichment:
        if key not in parsed:
            parsed[key] = default_enrichment[key]

    return parsed


def process_interaction_file(input_path: Path, output_path: Path) -> Dict:
    """Process a single interactions JSONL file and create enriched output."""

    print(f"[08b.content] Processing: {input_path.name}")

    # Load interactions from JSONL
    interactions = []
    with input_path.open("r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if line:
                try:
                    interactions.append(json.loads(line))
                except json.JSONDecodeError:
                    continue

    if not interactions:
        print(f"[08b.content] No interactions found in {input_path}")
        return {}

    print(f"[08b.content] Found {len(interactions)} interactions to enrich")

    # Derive metadata from path
    video_name = input_path.stem.replace(".interactions", "")
    source_name = input_path.parent.parent.name if input_path.parent.parent else "unknown"

    # Enrich each interaction
    enriched_interactions = []

    for idx, interaction in enumerate(interactions, start=1):
        print(f"[08b.content]   [{idx}/{len(interactions)}] Enriching interaction {interaction.get('id', idx)}...")

        # Get LLM enrichment
        enrichment = enrich_interaction(interaction, idx)

        # Build enriched interaction object
        enriched = {
            "id": idx,
            "original_id": interaction.get("id", f"interaction_{idx}"),
            "conversation_id": interaction.get("conversation_id", idx),
            "type": enrichment.get("interaction_type", "approach"),
            "description": enrichment.get("description", f"Interaction {idx}"),
            "start_time": interaction.get("start_time", 0.0),
            "end_time": interaction.get("end_time", 0.0),
            "duration_sec": interaction.get("end_time", 0.0) - interaction.get("start_time", 0.0),
            "phases": enrichment.get("phases", {}),
            "outcome": enrichment.get("refined_outcome", interaction.get("outcome", "unknown")),
            "outcome_confidence": interaction.get("outcome_confidence", 0.5),
            "topics_discussed": enrichment.get("topics_discussed", []),
            "techniques_used": enrichment.get("techniques_used", []),
            "interaction_quality": enrichment.get("interaction_quality", {}),
            "turn_count": len(interaction.get("turns", [])),
            "turns": interaction.get("turns", []),
        }

        enriched_interactions.append(enriched)

        desc_preview = enrichment.get("description", "")[:50]
        print(f"[08b.content]       -> {enrichment.get('interaction_type', 'approach')}: {desc_preview}")

    # Build summary statistics
    approach_count = sum(1 for i in enriched_interactions if i.get("type") == "approach")
    commentary_count = sum(1 for i in enriched_interactions if i.get("type") == "commentary")

    outcomes = {}
    all_techniques = set()
    all_topics = set()

    for i in enriched_interactions:
        if i.get("type") == "approach":
            outcome = i.get("outcome", "unknown")
            outcomes[outcome] = outcomes.get(outcome, 0) + 1
            for tech in i.get("techniques_used", []):
                if isinstance(tech, dict):
                    all_techniques.add(tech.get("technique", ""))
                else:
                    all_techniques.add(str(tech))
            all_topics.update(i.get("topics_discussed", []))

    # Build final output
    output = {
        "video_title": video_name,
        "source": source_name,
        "source_file": str(input_path),
        "content_type": "mixed" if commentary_count > 0 else "infield",
        "interactions": enriched_interactions,
        "summary": {
            "total_interactions": approach_count,
            "total_commentary_sections": commentary_count,
            "outcomes": outcomes,
            "techniques_demonstrated": sorted([t for t in all_techniques if t]),
            "topics_covered": sorted([t for t in all_topics if t]),
        },
        "enrichment_metadata": {
            "model": OLLAMA_MODEL,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        }
    }

    # Write output
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with output_path.open("w", encoding="utf-8") as f:
        json.dump(output, f, indent=2, ensure_ascii=False)

    print(f"[08b.content] Saved: {output_path}")
    print(f"[08b.content]   {approach_count} approaches, {commentary_count} commentary sections")

    return output


# ---------------------------
# Path helpers
# ---------------------------

def repo_root() -> Path:
    # scripts/training-data/<thisfile> -> repo root = parents[2]
    return Path(__file__).resolve().parents[2]


def structure_root() -> Path:
    return repo_root() / "data" / "08a.structure"


def output_root() -> Path:
    return repo_root() / "data" / "08b.content"


def infer_name_from_input(input_path: Path) -> Optional[str]:
    try:
        parts = input_path.resolve().parts
    except OSError:
        return None

    if "data" not in parts:
        return None
    i = parts.index("data")
    if i + 2 >= len(parts):
        return None
    stage = parts[i + 1]
    name = parts[i + 2]
    if stage in {"07.conversations", "08a.structure", "08b.content"}:
        return name
    return None


def extract_video_id_from_url(url: str) -> Optional[str]:
    url = (url or "").strip()
    if not url:
        return None
    m = re.search(r"[?&]v=([^&]+)", url)
    if m:
        return m.group(1)
    m = re.search(r"youtu\.be/([^?&/]+)", url)
    if m:
        return m.group(1)
    return None


def parse_sources_file(path: Path) -> List[Tuple[str, str]]:
    sources: List[Tuple[str, str]] = []
    for raw in path.read_text(encoding="utf-8").splitlines():
        line = raw.strip()
        if not line or line.startswith("#"):
            continue
        if "|" in line:
            name, url = line.split("|", 1)
            name = name.strip()
            url = url.strip()
            if name and url:
                sources.append((name, url))
            continue
        parts = shlex.split(line)
        if len(parts) >= 2:
            sources.append((parts[0], parts[1]))
    return sources


def resolve_existing_path(p: Path) -> Optional[Path]:
    if p.exists():
        return p.resolve()
    p2 = repo_root() / p
    if p2.exists():
        return p2.resolve()
    return None


def compute_output_file_for_input_file(input_file: Path, out_dir: Path) -> Path:
    stem = input_file.stem
    for suffix in [".interactions", ".conversations", ".features", ".tonality"]:
        if stem.endswith(suffix):
            stem = stem[:-len(suffix)]
    return out_dir / f"{stem}.enriched.json"


def find_input_files(in_dir: Path, video_filter: Optional[str]) -> List[Path]:
    files = sorted(in_dir.rglob("*.interactions.jsonl"))
    if not video_filter:
        return files
    needle = video_filter.strip()
    return [f for f in files if needle in f.name or needle in f.as_posix()]


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Enrich interactions with LLM analysis (techniques, phases, topics)"
    )
    parser.add_argument(
        "name",
        nargs="?",
        help="Source name (folder under data/08.interactions)."
    )
    parser.add_argument(
        "youtube_url",
        nargs="?",
        help="YouTube URL. Video URLs filter by ID unless --video is set."
    )
    parser.add_argument(
        "--channel",
        help="Alias for the positional name argument."
    )
    parser.add_argument(
        "--sources",
        nargs="?",
        const="docs/sources.txt",
        help="Process all sources from a sources.txt file (default: docs/sources.txt)."
    )
    parser.add_argument(
        "--input",
        help="Input JSONL file or directory (defaults to data/08.interactions/<name>)."
    )
    parser.add_argument(
        "--output",
        help="Output JSON file or directory (defaults to data/09.enrich/<name>)."
    )
    parser.add_argument(
        "--video",
        help="Optional filename substring filter when --input is a directory."
    )
    parser.add_argument(
        "--overwrite",
        action="store_true",
        help="Overwrite already-written outputs."
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Print what would happen, don't write files."
    )

    args = parser.parse_args()

    if args.name and args.channel:
        raise SystemExit("Provide either positional <name> OR --channel, not both.")
    name = (args.channel or args.name or "").strip() or None

    # Test Ollama connection
    try:
        response = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=5)
        if not response.ok:
            print(f"[08b.content] Warning: Ollama not responding properly")
    except requests.exceptions.RequestException:
        print(f"[08b.content] Error: Cannot connect to Ollama at {OLLAMA_BASE_URL}")
        print(f"[08b.content] Make sure Ollama is running: ollama serve")
        return

    def run_one(input_path: Path, output_path: Path, video_filter: Optional[str]) -> None:
        if input_path.is_dir():
            files = find_input_files(input_path, video_filter=video_filter)
            if not files:
                print(f"[08b.content] No interaction files found under: {input_path}")
                return

            print(f"[08b.content] Input : {input_path}")
            print(f"[08b.content] Output: {output_path}")
            print(f"[08b.content] Files : {len(files)}")

            written = 0
            skipped = 0
            for src in files:
                rel_path = src.relative_to(input_path)
                dest_dir = output_path / rel_path.parent
                dest = compute_output_file_for_input_file(src, dest_dir)

                if dest.exists() and not args.overwrite:
                    skipped += 1
                    continue

                if args.dry_run:
                    print(f"[dry-run] Would write: {dest}")
                    written += 1
                    continue

                print(f"\n[08b.content] {src.name} -> {dest.name}")
                process_interaction_file(src, dest)
                written += 1

            print("")
            print("[08b.content] Done.")
            print(f"  written : {written}")
            print(f"  skipped : {skipped}")
            return

        # Single file input
        dest = output_path if output_path.suffix else compute_output_file_for_input_file(input_path, output_path)

        if dest.exists() and not args.overwrite:
            print(f"[08b.content] Output exists, skipping: {dest}")
            return

        if args.dry_run:
            print(f"[dry-run] Would write: {dest}")
            return

        print(f"[08b.content] {input_path} -> {dest}")
        process_interaction_file(input_path, dest)

    if args.sources:
        sources_path = Path(args.sources)
        if not sources_path.is_absolute():
            sources_path = (repo_root() / sources_path).resolve()
        if not sources_path.exists():
            raise SystemExit(f"Missing sources file: {sources_path}")

        for src_name, src_url in parse_sources_file(sources_path):
            in_dir = structure_root() / src_name
            if not in_dir.exists():
                print(f"[08b.content] Skipping {src_name}: no 08a.structure output found")
                continue
            out_dir = output_root() / src_name
            video_filter = args.video or extract_video_id_from_url(src_url)
            run_one(in_dir, out_dir, video_filter=video_filter)
        return

    if args.input:
        resolved = resolve_existing_path(Path(args.input))
        if not resolved and name:
            resolved = resolve_existing_path(structure_root() / args.input)
        if not resolved:
            raise SystemExit(f"Input not found: {args.input}")
        input_path = resolved
    else:
        if not name:
            raise SystemExit("Missing input: provide --input or a <name>/--channel.")
        input_path = structure_root() / name
        if not input_path.exists():
            raise SystemExit(f"Expected structure folder not found: {input_path}")

    inferred_name = infer_name_from_input(input_path)
    if not name:
        name = inferred_name

    if args.output:
        output_path = resolve_existing_path(Path(args.output)) or (repo_root() / args.output).resolve()
    else:
        if not name:
            raise SystemExit("Missing output: provide --output, or use an input under data/<stage>/<name>.")
        output_path = output_root() / name

    video_filter = args.video or extract_video_id_from_url(args.youtube_url or "")
    run_one(input_path, output_path, video_filter=video_filter)


if __name__ == "__main__":
    main()
