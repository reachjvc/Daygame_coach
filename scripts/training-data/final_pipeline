#!/usr/bin/env bash
#
# scripts/training-data/final_pipeline
#
# FINAL TRAINING-DATA PIPELINE
#
# Runs steps 01‚Äí07 per source, then ingests the enriched results into Supabase
# (step 08 / `./scripts/training-data/08.ingest.ts`).
#
# Use:
#   A) One source (video / playlist / channel):
#      ./scripts/training-data/final_pipeline "daily_evolution" "https://www.youtube.com/watch?v=utuuVOXJunM"
#
#   B) Batch from sources file:
#      ./scripts/training-data/final_pipeline --sources
#      ./scripts/training-data/final_pipeline --sources docs/sources.txt
#
#   C) Manifest batch (process specific videos):
#      ./scripts/training-data/final_pipeline --manifest docs/pipeline/batches/P001.txt
#      ./scripts/training-data/final_pipeline --manifest docs/pipeline/batches/P001.txt --stages 02-05
#      ./scripts/training-data/final_pipeline --manifest docs/pipeline/batches/P001.txt --stages 06-08
#
# Optional flags:
#   --skip-ingest        stop before step 08 (ingest)
#   --parallel <N>       max concurrent videos per stage (default: auto)
#   --stages <range>     only run specific stages (e.g., "02-05", "06-08", "02")
#   --ingest-full        pass `--full` to `./scripts/training-data/08.ingest.ts`
#   --ingest-dry-run     run ingest in dry-run mode
#   --ingest-verify      verify ingest without writing to the DB
#   --ingest-arg <arg>   forward any other flag to `./scripts/training-data/08.ingest.ts`

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
REPO_ROOT="$(cd "${SCRIPT_DIR}/../.." && pwd)"
cd "$REPO_ROOT"

PER_SOURCE_STEPS=(
  "$REPO_ROOT/scripts/training-data/01.download"
  "$REPO_ROOT/scripts/training-data/02.transcribe"
  "$REPO_ROOT/scripts/training-data/03.align"
  "$REPO_ROOT/scripts/training-data/04.diarize"
  "$REPO_ROOT/scripts/training-data/05.audio-features"
  "$REPO_ROOT/scripts/training-data/06.video-type"
  "$REPO_ROOT/scripts/training-data/06b.verify"
  "$REPO_ROOT/scripts/training-data/06c.patch"
  "$REPO_ROOT/scripts/training-data/07.content"
)
# Step numbers: 01=0, 02=1, 03=2, 04=3, 05=4, 06=5, 06b=6, 06c=7, 07=8
TOTAL_PER_SOURCE_STEPS=${#PER_SOURCE_STEPS[@]}
GLOBAL_STEP_DESCRIPTIONS=("Ingest to vector store")
TOTAL_GLOBAL_STEPS=${#GLOBAL_STEP_DESCRIPTIONS[@]}
TOTAL_STEPS=$((TOTAL_PER_SOURCE_STEPS + TOTAL_GLOBAL_STEPS))

DEFAULT_SOURCES="docs/sources.txt"
MODE="single"
SOURCES_FILE=""
MANIFEST_FILE=""
STAGE_RANGE=""
SKIP_INGEST=false
declare -a INGEST_ARGS=()

# Default parallelism per stage (manifest mode only).
# Stages 01-05 stay sequential (fast enough, GPU models would OOM).
# LLM stages (06, 06b, 06c, 07) are I/O-bound ‚Äî safe to parallelize.
# 01=0, 02=1, 03=2, 04=3, 05=4, 06=5, 06b=6, 06c=7, 07=8
STAGE_PARALLEL=(1 1 1 1 1 10 10 10 10)
PARALLEL_OVERRIDE=""

# Global state for parallel job cleanup (signal handler needs access)
PARALLEL_TMPDIR=""
declare -a PARALLEL_PIDS=()

usage() {
  cat <<'EOF'
Usage:
  ./scripts/training-data/final_pipeline "<source_name>" "<youtube_url>"
  ./scripts/training-data/final_pipeline --sources [path/to/sources.txt]
  ./scripts/training-data/final_pipeline --manifest path/to/manifest.txt [--stages 02-05]

Options:
  --sources <file>        Use the provided sources file (default: docs/sources.txt)
  --manifest <file>       Process only videos listed in manifest file
  --stages <range>        Only run specific stages (e.g., "02-05", "06-07", "02")
  --parallel <N>          Max concurrent videos per stage (default: auto per stage)
  --skip-ingest           Stop before the vector-store ingestion step
  --ingest-full           Pass --full to `./scripts/training-data/08.ingest.ts` (force reingest)
  --ingest-dry-run        Forward --dry-run to `./scripts/training-data/08.ingest.ts`
  --ingest-verify         Forward --verify to `./scripts/training-data/08.ingest.ts`
  --ingest-arg <arg>      Forward any extra flag to `./scripts/training-data/08.ingest.ts`
EOF
}

cli_error() {
  echo "ERROR: $*" >&2
  usage
  exit 1
}

trim() {
  local value="$1"
  value="${value#"${value%%[![:space:]]*}"}"
  value="${value%"${value##*[![:space:]]}"}"
  printf '%s' "$value"
}

# Parse --stages range (e.g., "02-05", "06", "02-07") into min/max step numbers
parse_stage_range() {
  local range="$1"
  if [[ "$range" == *-* ]]; then
    STAGE_MIN="${range%%-*}"
    STAGE_MAX="${range##*-}"
  else
    STAGE_MIN="$range"
    STAGE_MAX="$range"
  fi
  # Remove leading zeros for arithmetic
  STAGE_MIN=$((10#$STAGE_MIN))
  STAGE_MAX=$((10#$STAGE_MAX))
  if [[ $STAGE_MIN -lt 1 || $STAGE_MAX -gt 9 || $STAGE_MIN -gt $STAGE_MAX ]]; then
    cli_error "Invalid --stages range: $range (must be 01-09)"
  fi
}

# Check if a step index (0-based) is within the stage range
step_in_range() {
  local idx="$1"
  local step_num=$((idx + 1))
  if [[ -z "$STAGE_RANGE" ]]; then
    return 0  # no filter, run all
  fi
  [[ $step_num -ge $STAGE_MIN && $step_num -le $STAGE_MAX ]]
}

cleanup_parallel() {
  if [[ ${#PARALLEL_PIDS[@]} -gt 0 ]]; then
    echo "  Killing ${#PARALLEL_PIDS[@]} background jobs..."
    for pid in "${PARALLEL_PIDS[@]}"; do
      kill "$pid" 2>/dev/null || true
    done
    wait 2>/dev/null || true
    PARALLEL_PIDS=()
  fi
  if [[ -n "$PARALLEL_TMPDIR" && -d "$PARALLEL_TMPDIR" ]]; then
    rm -rf "$PARALLEL_TMPDIR"
    PARALLEL_TMPDIR=""
  fi
}

trap cleanup_parallel INT TERM

get_parallel_jobs() {
  local idx="$1"
  if [[ -n "$PARALLEL_OVERRIDE" ]]; then
    echo "$PARALLEL_OVERRIDE"
  else
    echo "${STAGE_PARALLEL[$idx]}"
  fi
}

# Run a stage on all manifest videos with up to max_jobs concurrent workers.
# Falls back to sequential (full manifest) when max_jobs <= 1.
run_stage_parallel() {
  local script="$1"
  local manifest="$2"
  local max_jobs="$3"
  local name
  name="$(basename "$script")"

  # Sequential fallback: call stage once with full manifest
  if [[ "$max_jobs" -le 1 ]]; then
    "$script" --manifest "$manifest"
    return $?
  fi

  PARALLEL_TMPDIR=$(mktemp -d "${TMPDIR:-/tmp}/pipeline_parallel.XXXXXX")

  # Parse manifest into per-video sub-manifests
  local -a sub_manifests=()
  local total=0
  while IFS= read -r line; do
    [[ -z "$line" || "$line" == \#* ]] && continue
    local sub="${PARALLEL_TMPDIR}/video_${total}.txt"
    printf '%s\n' "$line" > "$sub"
    sub_manifests+=("$sub")
    ((total++))
  done < "$manifest"

  if [[ "$total" -eq 0 ]]; then
    echo "  No videos in manifest, skipping"
    rm -rf "$PARALLEL_TMPDIR"; PARALLEL_TMPDIR=""
    return 0
  fi

  # Cap workers to video count
  if [[ "$max_jobs" -gt "$total" ]]; then
    max_jobs="$total"
  fi

  echo "  Parallel: ${max_jobs} workers, ${total} videos"

  # GPU stage warning
  case "$name" in
    02.*|03.*|04.*)
      if [[ "$max_jobs" -gt 1 ]]; then
        echo "  WARNING: $name loads GPU models. parallel=$max_jobs may cause OOM."
      fi
      ;;
  esac

  # Job tracking
  local -A pid_to_idx=()
  local running=0
  local completed=0
  local failures=0
  local next=0
  PARALLEL_PIDS=()

  # Launch initial batch
  while [[ $next -lt $total && $running -lt $max_jobs ]]; do
    local logfile="${PARALLEL_TMPDIR}/log_${next}.txt"
    "$script" --manifest "${sub_manifests[$next]}" >"$logfile" 2>&1 &
    local pid=$!
    pid_to_idx[$pid]=$next
    PARALLEL_PIDS+=("$pid")
    ((running++))
    ((next++))
  done

  # Process completions and launch new jobs
  while [[ $running -gt 0 ]]; do
    local finished_pid=""
    local exit_code=0
    wait -n -p finished_pid "${!pid_to_idx[@]}" || exit_code=$?

    ((running--))
    ((completed++))

    local vidx="${pid_to_idx[$finished_pid]:-?}"
    local video_label="unknown"
    if [[ "$vidx" != "?" ]]; then
      video_label=$(head -1 "${sub_manifests[$vidx]}")
    fi

    if [[ $exit_code -ne 0 ]]; then
      ((failures++))
      echo "  FAIL [${completed}/${total}]: ${video_label} (exit=${exit_code})"
      if [[ "$vidx" != "?" && -f "${PARALLEL_TMPDIR}/log_${vidx}.txt" ]]; then
        tail -5 "${PARALLEL_TMPDIR}/log_${vidx}.txt" | sed 's/^/    /'
      fi
    else
      echo "  OK   [${completed}/${total}]: ${video_label}"
    fi

    unset "pid_to_idx[$finished_pid]"

    # Launch next job if available
    if [[ $next -lt $total ]]; then
      local logfile="${PARALLEL_TMPDIR}/log_${next}.txt"
      "$script" --manifest "${sub_manifests[$next]}" >"$logfile" 2>&1 &
      local pid=$!
      pid_to_idx[$pid]=$next
      PARALLEL_PIDS+=("$pid")
      ((running++))
      ((next++))
    fi

    # Early halt: check failure budget (need >=5 attempts for meaningful rate)
    if [[ $completed -ge 5 && $failures -gt 0 ]]; then
      local rate=$((failures * 100 / completed))
      if [[ $rate -gt 20 ]]; then
        echo "  HALT: ${failures}/${completed} failures (${rate}% > 20% threshold)"
        cleanup_parallel
        return 1
      fi
    fi
  done

  echo "  Stage complete: ${completed} processed, ${failures} failed"

  # Final failure budget check
  if [[ $total -ge 5 && $failures -gt 0 ]]; then
    local rate=$((failures * 100 / total))
    if [[ $rate -gt 20 ]]; then
      echo "  HALT: ${failures}/${total} failures (${rate}% > 20% threshold)"
      cleanup_parallel
      return 1
    fi
  fi

  rm -rf "$PARALLEL_TMPDIR"; PARALLEL_TMPDIR=""
  PARALLEL_PIDS=()
  return 0
}

run_pipeline_for_source() {
  local source="$1"
  local url="$2"

  echo ""
  echo "==========================================================="
  echo "‚û°Ô∏è  Running training-data pipeline for: $source"
  echo "    URL: $url"
  if [[ -n "$STAGE_RANGE" ]]; then
    echo "    Stages: $STAGE_RANGE"
  fi
  echo "==========================================================="

  for idx in "${!PER_SOURCE_STEPS[@]}"; do
    if ! step_in_range "$idx"; then
      continue
    fi

    local stepNumber=$((idx + 1))
    local script="${PER_SOURCE_STEPS[$idx]}"
    local name
    name="$(basename "$script")"

    echo ""
    echo "Step ${stepNumber}/${TOTAL_STEPS} ‚Äî $name"
    "$script" "$source" "$url"
  done

  echo ""
  echo "‚úÖ Completed pipeline for $source"
}

run_manifest_pipeline() {
  local manifest="$1"
  if [[ ! -f "$manifest" ]]; then
    echo "ERROR: Manifest file not found: $manifest" >&2
    exit 1
  fi

  echo ""
  echo "==========================================================="
  echo "üìã Running manifest-based pipeline"
  echo "    Manifest: $manifest"
  if [[ -n "$STAGE_RANGE" ]]; then
    echo "    Stages: $STAGE_RANGE"
  fi
  echo "==========================================================="

  for idx in "${!PER_SOURCE_STEPS[@]}"; do
    if ! step_in_range "$idx"; then
      continue
    fi

    local stepNumber=$((idx + 1))
    local script="${PER_SOURCE_STEPS[$idx]}"
    local name
    name="$(basename "$script")"

    # Skip 01.download in manifest mode (videos already downloaded)
    if [[ "$stepNumber" -eq 1 ]]; then
      echo ""
      echo "Step 1/${TOTAL_STEPS} ‚Äî $name (SKIPPED: manifest mode, downloads already exist)"
      continue
    fi

    local jobs
    jobs=$(get_parallel_jobs "$idx")

    echo ""
    echo "Step ${stepNumber}/${TOTAL_STEPS} ‚Äî $name (parallel=${jobs})"

    if ! run_stage_parallel "$script" "$manifest" "$jobs"; then
      echo "FATAL: Stage $name failed, halting pipeline"
      exit 1
    fi
  done

  echo ""
  echo "‚úÖ Completed manifest pipeline"
}

process_sources_file() {
  local path="$1"
  if [[ ! -f "$path" ]]; then
    echo "ERROR: Sources file not found: $path" >&2
    exit 1
  fi

  local processed=0
  while IFS= read -r raw_line || [[ -n "$raw_line" ]]; do
    local line="${raw_line//$'\r'/}"
    line="$(trim "$line")"
    [[ -z "$line" || "${line:0:1}" == "#" ]] && continue

    local source_name
    local youtube_url
    if [[ "$line" == *"|"* ]]; then
      source_name="${line%%|*}"
      youtube_url="${line#*|}"
    else
      source_name="${line%%[[:space:]]*}"
      youtube_url="${line#"$source_name"}"
    fi

    source_name="$(trim "$source_name")"
    youtube_url="$(trim "$youtube_url")"
    [[ -z "$source_name" || -z "$youtube_url" ]] && continue

    run_pipeline_for_source "$source_name" "$youtube_url"
    processed=$((processed + 1))
  done < "$path"

  if [[ "$processed" -eq 0 ]]; then
    echo "ERROR: No valid sources were found in $path" >&2
    exit 1
  fi
}

run_ingest() {
  if [[ "$SKIP_INGEST" == true ]]; then
    echo "‚ö†Ô∏è  Skipping ingestion (--skip-ingest)"
    return
  fi

  echo "==========================================================="
  echo "üß† Ingesting to vector store"
  echo "==========================================================="

  local ingest_cmd=("node" "$REPO_ROOT/node_modules/tsx/dist/cli.mjs" "$REPO_ROOT/scripts/training-data/08.ingest.ts")
  if [[ "${#INGEST_ARGS[@]}" -gt 0 ]]; then
    ingest_cmd+=("${INGEST_ARGS[@]}")
  fi
  "${ingest_cmd[@]}"
}

run_cross_stage_validation() {
  echo ""
  echo "==========================================================="
  echo "üîç Cross-stage validation (Stage 06 ‚Üî Stage 07)"
  echo "==========================================================="

  local validator="$REPO_ROOT/scripts/training-data/validate_cross_stage.py"
  if [[ ! -f "$validator" ]]; then
    echo "WARNING: Cross-stage validator not found at $validator"
    return 0
  fi

  python3 "$validator" --all
  local exit_code=$?

  if [[ $exit_code -ne 0 ]]; then
    echo ""
    echo "‚ö†Ô∏è  Cross-stage validation found errors."
    echo "    Review the output above before proceeding to ingest."
    echo ""
    read -r -p "Continue to ingest despite validation errors? [y/N] " response
    if [[ ! "$response" =~ ^[Yy]$ ]]; then
      echo "Pipeline halted by cross-stage validation errors."
      return 1
    fi
    echo "Continuing despite cross-stage validation errors (user confirmed)."
  fi

  return 0
}

run_global_steps() {
  # Run cross-stage validation before ingest
  run_cross_stage_validation || return 1

  for idx in "${!GLOBAL_STEP_DESCRIPTIONS[@]}"; do
    local stepNumber=$((TOTAL_PER_SOURCE_STEPS + idx + 1))
    local description="${GLOBAL_STEP_DESCRIPTIONS[$idx]}"

    echo ""
    echo "Step ${stepNumber}/${TOTAL_STEPS} ‚Äî ${description}"

    run_ingest
  done
}

while [[ $# -gt 0 ]]; do
  case "$1" in
    -h|--help)
      usage
      exit 0
      ;;
    --sources)
      MODE="sources"
      if [[ $# -gt 1 && "$2" != --* ]]; then
        SOURCES_FILE="$2"
        shift
      else
        SOURCES_FILE="$DEFAULT_SOURCES"
      fi
      shift
      ;;
    --sources=*)
      MODE="sources"
      SOURCES_FILE="${1#--sources=}"
      shift
      ;;
    --manifest)
      MODE="manifest"
      if [[ $# -lt 2 ]]; then
        cli_error "--manifest requires a file path"
      fi
      MANIFEST_FILE="$2"
      shift 2
      ;;
    --manifest=*)
      MODE="manifest"
      MANIFEST_FILE="${1#--manifest=}"
      shift
      ;;
    --stages)
      if [[ $# -lt 2 ]]; then
        cli_error "--stages requires a range (e.g., 02-05)"
      fi
      STAGE_RANGE="$2"
      parse_stage_range "$STAGE_RANGE"
      shift 2
      ;;
    --stages=*)
      STAGE_RANGE="${1#--stages=}"
      parse_stage_range "$STAGE_RANGE"
      shift
      ;;
    --parallel)
      if [[ $# -lt 2 ]]; then
        cli_error "--parallel requires a number"
      fi
      PARALLEL_OVERRIDE="$2"
      shift 2
      ;;
    --parallel=*)
      PARALLEL_OVERRIDE="${1#--parallel=}"
      shift
      ;;
    --skip-ingest)
      SKIP_INGEST=true
      shift
      ;;
    --ingest-full)
      INGEST_ARGS+=("--full")
      shift
      ;;
    --ingest-dry-run)
      INGEST_ARGS+=("--dry-run")
      shift
      ;;
    --ingest-verify)
      INGEST_ARGS+=("--verify")
      shift
      ;;
    --ingest-arg)
      if [[ $# -lt 2 ]]; then
        cli_error "--ingest-arg requires a value"
      fi
      INGEST_ARGS+=("$2")
      shift 2
      ;;
    --ingest-arg=*)
      INGEST_ARGS+=("${1#--ingest-arg=}")
      shift
      ;;
    *)
      break
      ;;
  esac
done

if [[ "$MODE" == "sources" && -z "$SOURCES_FILE" ]]; then
  SOURCES_FILE="$DEFAULT_SOURCES"
fi

# Sync video exclusions into yt-dlp archives
"$REPO_ROOT/scripts/training-data/sync-exclusions"

if [[ "$MODE" == "manifest" ]]; then
  if [[ -z "$MANIFEST_FILE" ]]; then
    cli_error "--manifest requires a file path"
  fi
  run_manifest_pipeline "$MANIFEST_FILE"
elif [[ "$MODE" == "single" ]]; then
  if [[ $# -lt 2 ]]; then
    cli_error "Provide a <source_name> and <youtube_url>, or use --sources or --manifest"
  fi
  SOURCE_NAME="$1"
  YOUTUBE_URL="$2"
  if [[ $# -gt 2 ]]; then
    cli_error "Unexpected arguments: ${*:3}"
  fi
  run_pipeline_for_source "$SOURCE_NAME" "$YOUTUBE_URL"
else
  if [[ $# -gt 0 ]]; then
    cli_error "Unexpected positional arguments when using --sources"
  fi
  process_sources_file "$SOURCES_FILE"
fi

run_global_steps

echo ""
echo "‚úÖ Final pipeline finished"
