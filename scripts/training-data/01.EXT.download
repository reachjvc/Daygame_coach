#!/usr/bin/env bash
# scripts/training-data/01.EXT.download
#
# Polite/reliable batch downloader:
# - Fixed pacing between items (playlist/channel safe)
# - Optional bandwidth cap
# - Outer exponential backoff on failure
# - Abort early on "bot-check" style responses (don't keep retrying)
#
# NOTE: This is NOT ‚Äústealth‚Äù. It just avoids abusive request patterns.

set -euo pipefail

usage() {
  cat <<'EOF'
Usage:

  Download one source (video/playlist/channel):
    ./scripts/training-data/01.EXT.download "<source_name>" "<youtube_url>"

  Download all sources from config:
    ./scripts/training-data/01.EXT.download --sources docs/pipeline/sources.txt

Examples:
  ./scripts/training-data/01.EXT.download "daily_evolution" "https://www.youtube.com/watch?v=utuuVOXJunM"
  ./scripts/training-data/01.EXT.download --sources
EOF
}

safe_name() {
  printf '%s' "$1" | tr -cs 'A-Za-z0-9._-' '_' | sed -E 's/^_+//;s/_+$//'
}

have_cmd() { command -v "$1" >/dev/null 2>&1; }

# Pick downloader
DOWNLOADER="yt-dlp"
if ! have_cmd yt-dlp; then
  if have_cmd youtube-dl; then
    DOWNLOADER="youtube-dl"
  else
    echo "‚ùå Error: yt-dlp not found. Install:"
    echo "   pip install -U yt-dlp yt-dlp-ejs"
    exit 1
  fi
fi

# Need ffmpeg
if ! have_cmd ffmpeg; then
  echo "‚ùå Error: ffmpeg not found."
  exit 1
fi

FFPROBE_OK=0
if have_cmd ffprobe; then FFPROBE_OK=1; fi

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
ROOT_DIR="$(cd "$SCRIPT_DIR/../.." && pwd)"

OUTPUT_ROOT="${OUTPUT_ROOT:-"$ROOT_DIR/data/01.download"}"
COOKIES_FILE="${YOUTUBE_COOKIES_FILE:-"$ROOT_DIR/docs/data_docs/www.youtube.com_cookies.txt"}"

# --------------------------
# Anti-bot detection pacing (for scaled operations)
# --------------------------
# Random delay range between items (seconds)
SLEEP_MIN_SEC="${SLEEP_MIN_SEC:-30}"
SLEEP_MAX_SEC="${SLEEP_MAX_SEC:-120}"

# Jitter percentage (¬±20% by default)
JITTER_PCT="${JITTER_PCT:-20}"

# Randomize per-run parameters (1 = on)
RANDOMIZE_RUN_PARAMS="${RANDOMIZE_RUN_PARAMS:-1}"

# Randomize per-source sleep ranges (1 = on)
RANDOMIZE_SLEEP_RANGES="${RANDOMIZE_SLEEP_RANGES:-1}"
# If randomized, pick per-source sleep ranges from these bounds
SLEEP_MIN_SEC_LOW="${SLEEP_MIN_SEC_LOW:-$SLEEP_MIN_SEC}"
SLEEP_MIN_SEC_HIGH="${SLEEP_MIN_SEC_HIGH:-$((SLEEP_MIN_SEC * 2))}"
SLEEP_MAX_SEC_LOW="${SLEEP_MAX_SEC_LOW:-$SLEEP_MAX_SEC}"
SLEEP_MAX_SEC_HIGH="${SLEEP_MAX_SEC_HIGH:-$((SLEEP_MAX_SEC * 2))}"
# Runtime sleep bounds (set per source)
SLEEP_MIN_RUNTIME="$SLEEP_MIN_SEC"
SLEEP_MAX_RUNTIME="$SLEEP_MAX_SEC"

# Session limits: pause after N videos
SESSION_MAX_VIDEOS="${SESSION_MAX_VIDEOS:-30}"  # 20-40 range
SESSION_MAX_VIDEOS_MIN="${SESSION_MAX_VIDEOS_MIN:-20}"
SESSION_MAX_VIDEOS_MAX="${SESSION_MAX_VIDEOS_MAX:-40}"
SESSION_PAUSE_MIN_SEC="${SESSION_PAUSE_MIN_SEC:-7200}"   # 2 hours
SESSION_PAUSE_MAX_SEC="${SESSION_PAUSE_MAX_SEC:-21600}"  # 6 hours

# --------------------------
# Video download (DISABLED by default - pipeline only uses audio)
# --------------------------
# To enable video download for future visual analysis:
#   SKIP_VIDEO=0 ./scripts/training-data/01.EXT.download ...
# Or set in environment: export SKIP_VIDEO=0
SKIP_VIDEO="${SKIP_VIDEO:-1}"

# Extra delay between processing each line in --sources mode (with jitter)
SLEEP_BETWEEN_SOURCES_MIN_SEC="${SLEEP_BETWEEN_SOURCES_MIN_SEC:-60}"
SLEEP_BETWEEN_SOURCES_MAX_SEC="${SLEEP_BETWEEN_SOURCES_MAX_SEC:-180}"
SLEEP_BETWEEN_SOURCES_MIN_LOW="${SLEEP_BETWEEN_SOURCES_MIN_LOW:-$SLEEP_BETWEEN_SOURCES_MIN_SEC}"
SLEEP_BETWEEN_SOURCES_MIN_HIGH="${SLEEP_BETWEEN_SOURCES_MIN_HIGH:-$((SLEEP_BETWEEN_SOURCES_MIN_SEC * 2))}"
SLEEP_BETWEEN_SOURCES_MAX_LOW="${SLEEP_BETWEEN_SOURCES_MAX_LOW:-$SLEEP_BETWEEN_SOURCES_MAX_SEC}"
SLEEP_BETWEEN_SOURCES_MAX_HIGH="${SLEEP_BETWEEN_SOURCES_MAX_HIGH:-$((SLEEP_BETWEEN_SOURCES_MAX_SEC * 2))}"
SLEEP_BETWEEN_SOURCES_MIN_RUNTIME="$SLEEP_BETWEEN_SOURCES_MIN_SEC"
SLEEP_BETWEEN_SOURCES_MAX_RUNTIME="$SLEEP_BETWEEN_SOURCES_MAX_SEC"

# Optional bandwidth cap for downloads (yt-dlp: --limit-rate). Examples: 500K, 2M, 10M
LIMIT_RATE="${LIMIT_RATE:-2M}"
LIMIT_RATE_RANDOMIZE="${LIMIT_RATE_RANDOMIZE:-1}"
LIMIT_RATE_CHOICES="${LIMIT_RATE_CHOICES:-750K 1M 1500K 2M 3M}"

# Outer retry/backoff (script-level) for whole yt-dlp call
OUTER_MAX_ATTEMPTS="${OUTER_MAX_ATTEMPTS:-3}"
OUTER_BACKOFF_BASE_SEC="${OUTER_BACKOFF_BASE_SEC:-15}"
OUTER_BACKOFF_MAX_SEC="${OUTER_BACKOFF_MAX_SEC:-300}"

# Avoid downloading during suspicious hours (1am-6am local)
AVOID_NIGHT_HOURS="${AVOID_NIGHT_HOURS:-1}"

# Session video counter (persists in state file)
SESSION_STATE_FILE="${SESSION_STATE_FILE:-$ROOT_DIR/data/.download_session_state}"

# User-agent rotation pool
USER_AGENTS=(
  "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
  "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
  "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0"
  "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15"
  "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
  "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
  "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:121.0) Gecko/20100101 Firefox/121.0"
)

# Inner yt-dlp retry knobs (still useful for flaky fragments)
CONCURRENT_FRAGMENTS="${CONCURRENT_FRAGMENTS:-1}"
RETRIES="${RETRIES:-8}"
FRAGMENT_RETRIES="${FRAGMENT_RETRIES:-8}"
RETRY_SLEEP="${RETRY_SLEEP:-2}"

# Observation flags set by dl_with_backoff (used for post-run integrity checks)
# NOTE: these are intentionally global (not local) so download_one can branch on them.
DL_AUTH_GATE_DETECTED=0

# ASR audio standardization
ASR_SAMPLE_RATE="${ASR_SAMPLE_RATE:-16000}"
ASR_RESYNC_FILTER="${ASR_RESYNC_FILTER:-aresample=async=1:first_pts=0}"

MAKE_PREVIEW_MP3="${MAKE_PREVIEW_MP3:-1}"
PREVIEW_MP3_BITRATE="${PREVIEW_MP3_BITRATE:-128k}"

FFMPEG_TIMEOUT_SEC="${FFMPEG_TIMEOUT_SEC:-600}"
USE_TIMEOUT=0
if have_cmd timeout; then USE_TIMEOUT=1; fi

# --------------------------
# JS runtime detection (yt-dlp)
# --------------------------
js_runtime_args=()
extractor_args=()

if [[ "$DOWNLOADER" == "yt-dlp" ]]; then
  if have_cmd deno; then
    js_runtime_args=(--js-runtimes deno)
  elif have_cmd node; then
    js_runtime_args=(--js-runtimes node)
  elif have_cmd qjs; then
    js_runtime_args=(--js-runtimes quickjs)
  elif have_cmd bun; then
    js_runtime_args=(--js-runtimes bun)
  else
    echo "‚ùå Error: No JS runtime found (needed for reliable extraction). Install deno or node."
    exit 1
  fi
  extractor_args=()
fi

# --------------------------
# Common yt-dlp args (built dynamically per call)
# --------------------------
build_common_dl_args() {
  local user_agent
  user_agent="$(get_random_user_agent)"

  common_dl_args=()
  if [[ "$DOWNLOADER" == "yt-dlp" ]]; then
    common_dl_args=(
      --retries "$RETRIES"
      --fragment-retries "$FRAGMENT_RETRIES"
      --file-access-retries "$FRAGMENT_RETRIES"
      --retry-sleep "$RETRY_SLEEP"
      --concurrent-fragments "$CONCURRENT_FRAGMENTS"
      --continue
      --no-post-overwrites
      --ignore-errors
      --progress
      --newline

      # Randomized user-agent
      --user-agent "$user_agent"

      # Randomized pacing between playlist items
      --sleep-interval "$SLEEP_MIN_RUNTIME"
      --max-sleep-interval "$SLEEP_MAX_RUNTIME"

      # Also add sleep for subtitles/metadata requests
      --sleep-requests "$(random_between 1 3)"

      # Avoid cluttering output dirs with playlist-level metadata directories like:
      #   data/01.download/<source>/<playlist_title> [<playlist_id>]/*.info.json
      # This is the yt-dlp default when using --write-info-json on playlists.
      --no-write-playlist-metafiles
    )
    if [[ -n "${LIMIT_RATE// }" ]]; then
      common_dl_args+=( --limit-rate "$LIMIT_RATE" )
    fi
  else
    common_dl_args=( --continue --ignore-errors )
  fi
}

# --------------------------
# Anti-detection helpers
# --------------------------

# Random integer between min and max (inclusive)
random_between() {
  local min="$1" max="$2"
  echo $(( min + RANDOM % (max - min + 1) ))
}

# Pick random token from a space-separated list
random_choice() {
  local list="$1"
  read -r -a _choices <<< "$list"
  local idx=$(( RANDOM % ${#_choices[@]} ))
  echo "${_choices[$idx]}"
}

# Add jitter to a value (¬±JITTER_PCT%)
add_jitter() {
  local val="$1"
  local jitter_range=$(( val * JITTER_PCT / 100 ))
  local jitter=$(( (RANDOM % (2 * jitter_range + 1)) - jitter_range ))
  echo $(( val + jitter ))
}

# Random sleep between min and max seconds, with jitter
random_sleep() {
  local min="$1" max="$2"
  local base=$(random_between "$min" "$max")
  local with_jitter=$(add_jitter "$base")
  [[ "$with_jitter" -lt 1 ]] && with_jitter=1
  echo "üí§ Sleeping ${with_jitter}s (anti-detection)..."
  sleep "$with_jitter"
}

# Randomize sleep range per source
compute_sleep_range() {
  if [[ "$RANDOMIZE_SLEEP_RANGES" != "1" ]]; then
    SLEEP_MIN_RUNTIME="$SLEEP_MIN_SEC"
    SLEEP_MAX_RUNTIME="$SLEEP_MAX_SEC"
    return
  fi

  local min_rt max_rt
  min_rt=$(random_between "$SLEEP_MIN_SEC_LOW" "$SLEEP_MIN_SEC_HIGH")
  max_rt=$(random_between "$SLEEP_MAX_SEC_LOW" "$SLEEP_MAX_SEC_HIGH")
  if [[ "$max_rt" -le "$min_rt" ]]; then
    max_rt=$((min_rt + 5))
  fi

  SLEEP_MIN_RUNTIME="$min_rt"
  SLEEP_MAX_RUNTIME="$max_rt"
}

randomize_run_params() {
  if [[ "$RANDOMIZE_RUN_PARAMS" != "1" ]]; then
    SLEEP_BETWEEN_SOURCES_MIN_RUNTIME="$SLEEP_BETWEEN_SOURCES_MIN_SEC"
    SLEEP_BETWEEN_SOURCES_MAX_RUNTIME="$SLEEP_BETWEEN_SOURCES_MAX_SEC"
    return
  fi

  SESSION_MAX_VIDEOS=$(random_between "$SESSION_MAX_VIDEOS_MIN" "$SESSION_MAX_VIDEOS_MAX")

  if [[ "$LIMIT_RATE_RANDOMIZE" == "1" ]]; then
    LIMIT_RATE="$(random_choice "$LIMIT_RATE_CHOICES")"
  fi

  local min_rt max_rt
  min_rt=$(random_between "$SLEEP_BETWEEN_SOURCES_MIN_LOW" "$SLEEP_BETWEEN_SOURCES_MIN_HIGH")
  max_rt=$(random_between "$SLEEP_BETWEEN_SOURCES_MAX_LOW" "$SLEEP_BETWEEN_SOURCES_MAX_HIGH")
  if [[ "$max_rt" -le "$min_rt" ]]; then
    max_rt=$((min_rt + 10))
  fi
  SLEEP_BETWEEN_SOURCES_MIN_RUNTIME="$min_rt"
  SLEEP_BETWEEN_SOURCES_MAX_RUNTIME="$max_rt"

  echo "üé≤ Run randomization:"
  echo "   Session max videos: $SESSION_MAX_VIDEOS"
  echo "   Limit rate: $LIMIT_RATE"
  echo "   Between-source sleep: ${SLEEP_BETWEEN_SOURCES_MIN_RUNTIME}-${SLEEP_BETWEEN_SOURCES_MAX_RUNTIME}s"
}

# Pick a random user-agent
get_random_user_agent() {
  local idx=$(( RANDOM % ${#USER_AGENTS[@]} ))
  echo "${USER_AGENTS[$idx]}"
}

# Check if we should avoid current hour (1am-6am)
is_suspicious_hour() {
  [[ "$AVOID_NIGHT_HOURS" != "1" ]] && return 1
  local hour
  hour=$(date +%H)
  hour=$((10#$hour))  # Remove leading zero
  [[ "$hour" -ge 1 && "$hour" -lt 6 ]]
}

# Wait until safe hours if needed
wait_for_safe_hours() {
  while is_suspicious_hour; do
    local hour
    hour=$(date +%H)
    echo "‚è∞ Current hour ($hour) is in suspicious range (1-6am). Waiting until 6am..."
    # Calculate seconds until 6am
    local now_sec
    now_sec=$(date +%s)
    local today_6am
    today_6am=$(date -d "today 06:00" +%s 2>/dev/null || date -d "06:00" +%s 2>/dev/null || echo "0")
    if [[ "$today_6am" -le "$now_sec" ]]; then
      today_6am=$(date -d "tomorrow 06:00" +%s 2>/dev/null || echo "0")
    fi
    if [[ "$today_6am" -gt 0 ]]; then
      local wait_sec=$(( today_6am - now_sec + 60 ))  # +60 for buffer
      echo "   Sleeping until 6am (~${wait_sec}s)..."
      sleep "$wait_sec"
    else
      # Fallback: sleep 1 hour and check again
      sleep 3600
    fi
  done
}

# Session state management
load_session_state() {
  if [[ -f "$SESSION_STATE_FILE" ]]; then
    source "$SESSION_STATE_FILE"
  fi
  # Ensure defaults if not set (handles empty or partial state files)
  SESSION_VIDEO_COUNT=${SESSION_VIDEO_COUNT:-0}
  SESSION_START_TIME=${SESSION_START_TIME:-$(date +%s)}
}

save_session_state() {
  cat > "$SESSION_STATE_FILE" <<EOF
SESSION_VIDEO_COUNT=$SESSION_VIDEO_COUNT
SESSION_START_TIME=$SESSION_START_TIME
EOF
}

reset_session() {
  SESSION_VIDEO_COUNT=0
  SESSION_START_TIME=$(date +%s)
  save_session_state
}

increment_session_count() {
  SESSION_VIDEO_COUNT=$((SESSION_VIDEO_COUNT + 1))
  save_session_state
}

check_session_limit() {
  load_session_state
  if [[ "$SESSION_VIDEO_COUNT" -ge "$SESSION_MAX_VIDEOS" ]]; then
    local pause_sec
    pause_sec=$(random_between "$SESSION_PAUSE_MIN_SEC" "$SESSION_PAUSE_MAX_SEC")
    local pause_hours=$(( pause_sec / 3600 ))
    local pause_mins=$(( (pause_sec % 3600) / 60 ))
    echo ""
    echo "üõë SESSION LIMIT REACHED ($SESSION_VIDEO_COUNT videos)"
    echo "   Pausing for ${pause_hours}h ${pause_mins}m to avoid detection..."
    echo "   Resume at: $(date -d "+${pause_sec} seconds" 2>/dev/null || date -v+${pause_sec}S 2>/dev/null || echo "~${pause_hours}h from now")"
    echo ""
    sleep "$pause_sec"
    reset_session
    echo "‚úÖ Session reset. Resuming downloads..."
  fi
}

# Shuffle array (Fisher-Yates)
shuffle_array() {
  local -n arr=$1
  local i j temp
  for ((i=${#arr[@]}-1; i>0; i--)); do
    j=$((RANDOM % (i+1)))
    temp="${arr[$i]}"
    arr[$i]="${arr[$j]}"
    arr[$j]="$temp"
  done
}

# --------------------------
# Helpers
# --------------------------
ffprobe_duration_sec() {
  local f="$1"
  if [[ "$FFPROBE_OK" -ne 1 || ! -f "$f" ]]; then
    echo "0"
    return 0
  fi
  ffprobe -v error -show_entries format=duration \
    -of default=nokey=1:noprint_wrappers=1 "$f" 2>/dev/null \
    | awk '{printf "%.3f\n", $1}'
}

run_ffmpeg() {
  local log_file="$1"; shift
  if [[ "$USE_TIMEOUT" -eq 1 ]]; then
    timeout "$FFMPEG_TIMEOUT_SEC" ffmpeg -nostdin "$@" 2>>"$log_file"
  else
    ffmpeg -nostdin "$@" 2>>"$log_file"
  fi
}

detect_botcheck_in_file() {
  # Conservative patterns that usually indicate a human verification gate.
  local f="$1"
  grep -Eqi \
    "unusual traffic|not a robot|captcha|verify you are|robot check|sorry.*cannot process|access denied" \
    "$f"
}

detect_auth_required_in_file() {
  # Age/sign-in gates: skip item but keep going.
  local f="$1"
  grep -Eqi \
    "sign in to confirm your age|confirm your age|sign in to confirm|this video may be inappropriate for some users|please sign in|age-restricted|age restricted|private video|cookies are no longer valid" \
    "$f"
}

dl_with_backoff() {
  # dl_with_backoff <log_file> <cmd...>
  local log_file="$1"; shift
  local attempt=1
  local tmp
  tmp="$(mktemp)"

  while [[ "$attempt" -le "$OUTER_MAX_ATTEMPTS" ]]; do
    echo "" >>"$log_file"
    echo "----- Attempt $attempt/$OUTER_MAX_ATTEMPTS -----" >>"$log_file"

    set +e
    "$@" 2>&1 | tee "$tmp"
    local status="${PIPESTATUS[0]}"
    set -e

    cat "$tmp" >>"$log_file"

    local auth_gate=0
    if detect_auth_required_in_file "$tmp"; then
      auth_gate=1
      DL_AUTH_GATE_DETECTED=1
      echo "‚ö†Ô∏è Authentication/age gate detected (some items may be skipped). See log for details." | tee -a "$log_file"
    fi

    if detect_botcheck_in_file "$tmp"; then
      echo "‚ùå Detected a likely human-verification/bot-check response. Stopping (do not hammer retries)." | tee -a "$log_file"
      rm -f "$tmp"
      return 77
    fi

    if [[ "$status" -eq 0 ]]; then
      rm -f "$tmp"
      return 0
    fi

    # Auth-gated items typically won't succeed with retries. Treat as a structured skip.
    if [[ "$auth_gate" -eq 1 ]]; then
      rm -f "$tmp"
      return 78
    fi

    # Backoff before next attempt
    local sleep_sec
    sleep_sec="$(awk -v b="$OUTER_BACKOFF_BASE_SEC" -v a="$attempt" 'BEGIN{v=b*(2^(a-1)); printf "%.0f", v}')"
    if [[ "$sleep_sec" -gt "$OUTER_BACKOFF_MAX_SEC" ]]; then
      sleep_sec="$OUTER_BACKOFF_MAX_SEC"
    fi
    echo "‚ö†Ô∏è Download failed (exit $status). Backing off ${sleep_sec}s before retry..." | tee -a "$log_file"
    sleep "$sleep_sec"
    attempt=$((attempt + 1))
  done

  rm -f "$tmp"
  return 1
}

# --------------------------
# ASR building
# --------------------------
make_asr_outputs_for_input() {
  local in_audio="$1"
  local log_file="$2"

  local stem="${in_audio%.*}"
  local raw_out="${stem}.asr.raw16k.wav"
  local mp3_out="${stem}.listen.mp3"

  if [[ ! -f "$raw_out" ]]; then
    run_ffmpeg "$log_file" -hide_banner -loglevel warning -y \
      -i "$in_audio" \
      -map 0:a:0? -vn -sn -dn \
      -ac 1 -ar "$ASR_SAMPLE_RATE" -c:a pcm_s16le \
      -af "$ASR_RESYNC_FILTER" \
      "$raw_out" || echo "‚ö†Ô∏è RAW WAV failed: $raw_out" >>"$log_file"
  fi

  if [[ "$MAKE_PREVIEW_MP3" == "1" && ! -f "$mp3_out" ]]; then
    run_ffmpeg "$log_file" -hide_banner -loglevel warning -y \
      -i "$in_audio" \
      -map 0:a:0? -vn -sn -dn \
      -c:a libmp3lame -b:a "$PREVIEW_MP3_BITRATE" \
      "$mp3_out" || echo "‚ö†Ô∏è MP3 preview failed: $mp3_out" >>"$log_file"
  fi
}

make_asr_files() {
  local output_dir="$1"
  local log_file="$output_dir/audio-asr-build.log"
  : > "$log_file"

  local found_any=0
  while IFS= read -r -d '' in_audio; do
    found_any=1
    make_asr_outputs_for_input "$in_audio" "$log_file"
    done < <(
    # Only actual audio containers (avoid *.info.json etc.)
    find "$output_dir" -type f \( \
        -iname "*.audio.webm" -o \
        -iname "*.audio.m4a"  -o \
        -iname "*.audio.mp3"  -o \
        -iname "*.audio.mp4"  -o \
        -iname "*.audio.mkv"  -o \
        -iname "*.audio.opus" -o \
        -iname "*.audio.mka" \
      \) -print0
  )


  if [[ "$found_any" -eq 0 ]]; then
    while IFS= read -r -d '' mp4; do
      make_asr_outputs_for_input "$mp4" "$log_file"
    done < <(find "$output_dir" -type f -name "*.mp4" -print0)
  fi
}

download_one() {
  local source_name="$1"
  local youtube_url="$2"

  # Anti-detection: wait for safe hours
  wait_for_safe_hours

  # Anti-detection: check session limit
  check_session_limit

  # Anti-detection: randomize sleep range per source and build args with fresh random user-agent
  compute_sleep_range
  build_common_dl_args

  # Reset per-source observation flags.
  DL_AUTH_GATE_DETECTED=0

  local safe_source
  safe_source="$(safe_name "$source_name")"
  local output_dir="$OUTPUT_ROOT/$safe_source"

  local archive_audio="$output_dir/.youtube-dl-archive.audio.txt"
  local archive_video="$output_dir/.youtube-dl-archive.video.txt"
  local log_audio="$output_dir/download-audio.log"
  local log_video="$output_dir/download-video.log"

  mkdir -p "$output_dir"

  local -a cookies_args=()
  if [[ -f "$COOKIES_FILE" ]]; then
    local runtime_cookie="$output_dir/.yt-dlp-cookies.runtime.txt"
    cp "$COOKIES_FILE" "$runtime_cookie"
    chmod 600 "$runtime_cookie" 2>/dev/null || true
    cookies_args=(--cookies "$runtime_cookie")
  fi

  local base="$output_dir/%(title)s [%(id)s]/%(title)s [%(id)s]"

  local user_agent
  user_agent="$(get_random_user_agent)"
  echo "================================"
  echo "üì• $source_name"
  echo "   $youtube_url"
  echo "   -> $output_dir"
  echo "   üé≠ User-Agent: ${user_agent:0:50}..."
  echo "   üìä Session: $SESSION_VIDEO_COUNT/$SESSION_MAX_VIDEOS"
  echo "================================"

  # AUDIO
  : > "$log_audio"
  dl_with_backoff "$log_audio" \
    "$DOWNLOADER" \
      --format "bestaudio[abr>50]/bestaudio/best" \
      --output "${base}.audio.%(ext)s" \
      --write-info-json \
      --download-archive "$archive_audio" \
      --no-post-overwrites \
      "${common_dl_args[@]}" \
      "${js_runtime_args[@]}" \
      "${extractor_args[@]}" \
      "${cookies_args[@]}" \
      "$youtube_url" || {
        rc=$?
        echo "‚ö†Ô∏è Audio step ended (code $rc). Log: $log_audio"
        [[ "$rc" -eq 77 ]] && return 77
        [[ "$rc" -eq 78 ]] && return 78
      }

  make_asr_files "$output_dir"

  # Integrity: if we didn't produce any ASR-ready audio, this source is effectively not downloaded.
  # This commonly happens when a playlist/video is private/age-restricted and cookies are invalid.
  local asr_raw_count
  asr_raw_count="$(find "$output_dir" -type f -name "*.audio.asr.raw16k.wav" 2>/dev/null | wc -l | tr -d ' ')"
  if [[ "${asr_raw_count:-0}" -eq 0 ]]; then
    echo "‚ùå No ASR-ready audio produced (0 *.audio.asr.raw16k.wav). Treating as NOT DOWNLOADED." | tee -a "$log_audio"
    if [[ "${DL_AUTH_GATE_DETECTED:-0}" -eq 1 ]]; then
      echo "‚ö†Ô∏è Likely auth/age gate. Update cookies (docs/data_docs/www.youtube.com_cookies.txt) and retry." | tee -a "$log_audio"
      return 78
    fi
    return 1
  fi

  # VIDEO (disabled by default - pipeline only uses audio)
  # Enable with: SKIP_VIDEO=0 ./scripts/training-data/01.EXT.download ...
  if [[ "${SKIP_VIDEO:-1}" != "1" ]]; then
    : > "$log_video"
    VIDEO_FORMAT="${VIDEO_FORMAT:-best[ext=mp4]/best}"
    if [[ "${HIGH_QUALITY_VIDEO:-0}" == "1" ]]; then
      VIDEO_FORMAT="bv*[ext=mp4]+ba[ext=m4a]/b[ext=mp4]/bv*+ba/b"
    fi

    dl_with_backoff "$log_video" \
      "$DOWNLOADER" \
        --format "$VIDEO_FORMAT" \
        --merge-output-format mp4 \
        --output "${base}.%(ext)s" \
        --write-info-json \
        --download-archive "$archive_video" \
        --no-post-overwrites \
        "${common_dl_args[@]}" \
        "${js_runtime_args[@]}" \
        "${extractor_args[@]}" \
        "${cookies_args[@]}" \
        "$youtube_url" || {
          rc=$?
          echo "‚ö†Ô∏è Video step ended (code $rc). Log: $log_video"
          [[ "$rc" -eq 77 ]] && return 77
          [[ "$rc" -eq 78 ]] && return 78
        }
    make_asr_files "$output_dir"
  else
    echo "‚è≠Ô∏è Skipping video download (SKIP_VIDEO=1). Audio-only mode."
  fi

  # Anti-detection: increment session counter
  increment_session_count

  if [[ "${DL_AUTH_GATE_DETECTED:-0}" -eq 1 ]]; then
    echo "‚ö†Ô∏è Note: auth/age-gated items were detected for this source. Some playlist entries may be missing."
  fi
  echo "‚úÖ Done: $source_name (session: $SESSION_VIDEO_COUNT/$SESSION_MAX_VIDEOS)"
}

download_from_sources() {
  local sources_file="${1:-$ROOT_DIR/docs/pipeline/sources.txt}"
  [[ -f "$sources_file" ]] || { echo "‚ùå Sources file not found: $sources_file"; exit 1; }

  # Initialize session state
  load_session_state
  randomize_run_params
  echo "üìä Resuming session: $SESSION_VIDEO_COUNT videos already downloaded"
  echo "   Session limit: $SESSION_MAX_VIDEOS videos before ${SESSION_PAUSE_MIN_SEC}s-${SESSION_PAUSE_MAX_SEC}s pause"
  echo ""
  mkdir -p "$OUTPUT_ROOT"

  # Load sources into array
  local -a sources=()
  while IFS= read -r line; do
    [[ -z "${line//[[:space:]]/}" ]] && continue
    [[ "$line" =~ ^[[:space:]]*# ]] && continue

    local source_name youtube_url
    if [[ "$line" == *"|"* ]]; then
      source_name="${line%%|*}"
      youtube_url="${line#*|}"
    else
      source_name="${line%%[[:space:]]*}"
      youtube_url="${line#"$source_name"}"
      youtube_url="${youtube_url#"${youtube_url%%[![:space:]]*}"}"
    fi

    [[ -z "$source_name" || -z "$youtube_url" ]] && continue
    sources+=("$source_name|$youtube_url")
  done < "$sources_file"

  # Anti-detection: shuffle download order
  echo "üîÄ Shuffling ${#sources[@]} sources for randomized order..."
  shuffle_array sources

  local idx=0
  for entry in "${sources[@]}"; do
    idx=$((idx + 1))
    local source_name="${entry%%|*}"
    local youtube_url="${entry#*|}"

    echo ""
    echo "[$idx/${#sources[@]}] Processing: $source_name"

    download_one "$source_name" "$youtube_url" || {
      rc=$?
      if [[ "$rc" -eq 77 ]]; then
        echo "‚ùå Stopped due to likely verification gate. Fix auth/permissions, then resume."
        exit 77
      fi
      if [[ "$rc" -eq 78 ]]; then
        echo "‚ö†Ô∏è Skipped due to auth/age gate. Continuing."
        echo "$(date -Iseconds) | $source_name | $youtube_url | AUTH_GATE" >> "$OUTPUT_ROOT/.skipped_sources.log"
        continue
      fi
      echo "‚ö†Ô∏è Failed source: $source_name (code $rc) ‚Äî continuing..."
    }

    # Anti-detection: random sleep between sources
    if [[ "$idx" -lt "${#sources[@]}" ]]; then
      random_sleep "$SLEEP_BETWEEN_SOURCES_MIN_RUNTIME" "$SLEEP_BETWEEN_SOURCES_MAX_RUNTIME"
    fi
  done

  echo ""
  echo "üéâ All sources processed!"
}


case "${1:-}" in
  -h|--help) usage; exit 0 ;;
  --sources) download_from_sources "${2:-}" ;;
  "") usage; exit 1 ;;
  *) [[ $# -ge 2 ]] || { echo "‚ùå Need <source_name> <youtube_url>"; usage; exit 1; }
     download_one "$1" "$2"
     ;;
esac
