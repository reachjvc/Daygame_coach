#!/usr/bin/env python3
"""
scripts/training-data/06e.LLM.quality-check

Focused transcript quality assessment using Claude Code CLI.

Reads:
  - data/06d.DET.sanitized/<source>/<video>/*.conversations.json

Writes:
  - data/06e.LLM.quality-check/<source>/<video>/*.quality-check.json
"""

from __future__ import annotations

import argparse
import json
import re
import shlex
import subprocess
import sys
import time
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple

from batch.manifest_parser import load_manifest_sources, manifest_filter_files
from batch.quarantine_helpers import get_quarantine_block_reason, load_quarantine_video_ids

try:
    import jsonschema  # type: ignore
except Exception:  # pragma: no cover
    jsonschema = None


LOG_PREFIX = "[06e.LLM.quality-check]"
PIPELINE_VERSION = "06e.LLM.quality-check-v1.0"
PROMPT_PATH = Path(__file__).resolve().parent / "prompts" / "06e.quality-check.prompt.md"
SCHEMA_PATH = Path(__file__).resolve().parent / "schemas" / "06e.quality-check.schema.json"
CLAUDE_BINARY_PATHS = [
    "claude",
    Path.home() / ".vscode-server/extensions/anthropic.claude-code-2.1.17-linux-x64/resources/native-binary/claude",
    Path.home() / ".vscode/extensions/anthropic.claude-code-2.1.17-linux-x64/resources/native-binary/claude",
    "/usr/local/bin/claude",
]

# Artifact damage severity mapping: how much does this artifact type hurt comprehension?
# Used by Stage 09 to graduate chunk confidence penalties.
ARTIFACT_DAMAGE_SEVERITY: Dict[str, str] = {
    "nonsense": "high",           # genuine gibberish, unrecoverable meaning
    "language_confusion": "medium",  # wrong language mixed in, still partially understandable
    "word_repetition": "low",     # trivial stutter/doubled word, fully understandable
}

# Transcript artifact repair: minimum confidence to accept a repair suggestion.
REPAIR_ACCEPT_THRESHOLD = 0.85


def repo_root() -> Path:
    return Path(__file__).resolve().parents[2]


def input_root() -> Path:
    return repo_root() / "data" / "06d.DET.sanitized"


def output_root() -> Path:
    return repo_root() / "data" / "06e.LLM.quality-check"


def test_input_root() -> Path:
    return repo_root() / "data" / "test" / "06d.DET.sanitized"


def test_output_root() -> Path:
    return repo_root() / "data" / "test" / "06e.LLM.quality-check"


def resolve_root_path(raw_path: Optional[str], default_root: Path) -> Path:
    if not raw_path:
        return default_root
    path = Path(raw_path)
    if not path.is_absolute():
        path = repo_root() / path
    return path


def parse_sources_file(path: Path) -> List[Tuple[str, str]]:
    sources: List[Tuple[str, str]] = []
    for raw in path.read_text(encoding="utf-8").splitlines():
        line = raw.strip()
        if not line or line.startswith("#"):
            continue
        if "|" in line:
            name, url = line.split("|", 1)
            sources.append((name.strip(), url.strip()))
            continue
        parts = shlex.split(line)
        if len(parts) >= 2:
            sources.append((parts[0], parts[1]))
    return sources


def find_input_files(in_dir: Path) -> List[Path]:
    return sorted(in_dir.rglob("*.conversations.json"))


def compute_output_path(input_path: Path, output_dir: Path) -> Path:
    stem = input_path.stem
    if stem.endswith(".conversations"):
        base = stem[: -len(".conversations")]
    else:
        base = stem
    return output_dir / f"{base}.quality-check.json"


def compute_output_path_with_layout(
    input_path: Path,
    output_dir: Path,
    input_root_dir: Optional[Path] = None,
) -> Path:
    canonical = compute_output_path(input_path, output_dir)
    if input_root_dir is not None:
        try:
            rel_parent = input_path.parent.relative_to(input_root_dir)
            if rel_parent != Path("."):
                return output_dir / rel_parent / canonical.name
        except ValueError:
            pass
    return canonical


def find_existing_output_path(
    input_path: Path,
    preferred_output_dir: Path,
    output_root_dir: Optional[Path] = None,
    input_root_dir: Optional[Path] = None,
) -> Optional[Path]:
    preferred = compute_output_path_with_layout(
        input_path,
        preferred_output_dir,
        input_root_dir=input_root_dir,
    )
    if preferred.exists():
        return preferred
    return None


def _safe_int(value: Any) -> Optional[int]:
    if isinstance(value, bool):
        return None
    if isinstance(value, int):
        return value
    if isinstance(value, float) and value.is_integer():
        return int(value)
    return None


def _read_json(path: Path) -> Optional[Dict[str, Any]]:
    try:
        data = json.loads(path.read_text(encoding="utf-8"))
    except Exception:
        return None
    return data if isinstance(data, dict) else None


def _load_prompt_template() -> str:
    if not PROMPT_PATH.exists():
        raise RuntimeError(f"Prompt template missing: {PROMPT_PATH}")
    return PROMPT_PATH.read_text(encoding="utf-8")


def _load_schema() -> Optional[Dict[str, Any]]:
    if not SCHEMA_PATH.exists():
        return None
    try:
        schema = json.loads(SCHEMA_PATH.read_text(encoding="utf-8"))
    except Exception:
        return None
    return schema if isinstance(schema, dict) else None


def _find_claude_binary() -> Optional[str]:
    for cand in CLAUDE_BINARY_PATHS:
        p = Path(cand)
        if str(cand) == "claude":
            try:
                res = subprocess.run(["which", "claude"], capture_output=True, text=True)
            except Exception:
                res = None
            if res and res.returncode == 0:
                return "claude"
            continue
        if p.exists() and p.is_file():
            return str(p)
    return None


def _call_claude(
    prompt: str,
    *,
    model: Optional[str],
    timeout_seconds: int,
    retries: int,
) -> Optional[str]:
    claude_bin = _find_claude_binary()
    if not claude_bin:
        print(f"{LOG_PREFIX} ERROR: Claude CLI binary not found")
        return None

    for attempt in range(max(1, retries)):
        try:
            cmd = [claude_bin]
            if isinstance(model, str) and model.strip():
                cmd += ["--model", model.strip()]
            cmd += ["-p", prompt, "--output-format", "text"]
            res = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=max(1, timeout_seconds),
            )
            if res.returncode == 0:
                return (res.stdout or "").strip()
            if attempt < retries - 1:
                wait = 2 ** attempt
                print(f"{LOG_PREFIX} Claude CLI non-zero exit, retrying in {wait}s...")
                time.sleep(wait)
        except subprocess.TimeoutExpired:
            if attempt < retries - 1:
                wait = 2 ** attempt
                print(f"{LOG_PREFIX} Claude CLI timeout, retrying in {wait}s...")
                time.sleep(wait)
    return None


def _extract_json(text: str) -> Optional[Dict[str, Any]]:
    raw = text.strip()
    if not raw:
        return None

    # Strip fenced blocks.
    if raw.startswith("```"):
        raw = re.sub(r"^```(?:json)?\s*", "", raw, flags=re.IGNORECASE)
        raw = re.sub(r"\s*```$", "", raw)

    try:
        parsed = json.loads(raw)
        if isinstance(parsed, dict):
            return parsed
    except Exception:
        pass

    start = raw.find("{")
    end = raw.rfind("}")
    if start >= 0 and end > start:
        snippet = raw[start : end + 1]
        try:
            parsed = json.loads(snippet)
            if isinstance(parsed, dict):
                return parsed
        except Exception:
            return None
    return None


def _validate_schema(payload: Dict[str, Any], schema: Optional[Dict[str, Any]]) -> bool:
    if schema is None or jsonschema is None:
        return True
    try:
        jsonschema.validate(instance=payload, schema=schema)
        return True
    except Exception:
        return False


def _format_transcript(segments: List[Dict[str, Any]]) -> str:
    """Format segments as [SEG_ID] SPEAKER: text for prompt injection."""
    lines: List[str] = []
    for seg in segments:
        if not isinstance(seg, dict):
            continue
        sid = _safe_int(seg.get("id"))
        if sid is None:
            continue
        speaker = seg.get("speaker_role", "unknown")
        text = seg.get("text", "")
        is_synthetic = bool(seg.get("synthetic_segment"))
        prefix = "(SYNTHETIC) " if is_synthetic else ""
        lines.append(f"[{sid}] {speaker}: {prefix}{text}")
    return "\n".join(lines)


def quality_check_file(
    input_path: Path,
    output_path: Path,
    *,
    args: argparse.Namespace,
    input_root_dir: Path,
    prompt_template: str,
    schema: Optional[Dict[str, Any]],
) -> Dict[str, int]:
    data = _read_json(input_path)
    if not data:
        raise RuntimeError(f"Could not read 06d input JSON: {input_path}")

    segments = data.get("segments")
    if not isinstance(segments, list):
        raise RuntimeError("Invalid 06d JSON: missing 'segments' list")

    # Sort segments by id
    valid_segments = [s for s in segments if isinstance(s, dict) and _safe_int(s.get("id")) is not None]
    valid_segments.sort(key=lambda s: _safe_int(s.get("id")) or 0)

    transcript_text = _format_transcript(valid_segments)
    prompt = prompt_template.replace("{{TRANSCRIPT}}", transcript_text)

    if args.dry_run:
        print(
            f"{LOG_PREFIX} [DRY RUN] {input_path.name}: "
            f"{len(valid_segments)} segments"
        )
        return {"segments_total": len(valid_segments), "low_quality": 0, "artifacts": 0}

    raw = _call_claude(
        prompt,
        model=args.model,
        timeout_seconds=args.timeout_seconds,
        retries=args.retries,
    )

    if not raw:
        raise RuntimeError(f"Claude CLI returned no output for {input_path.name}")

    parsed = _extract_json(raw)
    if not isinstance(parsed, dict) or not _validate_schema(parsed, schema):
        raise RuntimeError(f"Invalid/unparseable JSON response for {input_path.name}")

    low_quality_segments = parsed.get("low_quality_segments", [])
    transcript_artifacts = parsed.get("transcript_artifacts", [])

    if not isinstance(low_quality_segments, list):
        low_quality_segments = []
    if not isinstance(transcript_artifacts, list):
        transcript_artifacts = []

    # Filter out synthetic segments from quality flags
    synthetic_ids: Set[int] = {
        _safe_int(s.get("id"))
        for s in valid_segments
        if isinstance(s, dict) and bool(s.get("synthetic_segment"))
        and _safe_int(s.get("id")) is not None
    }
    if synthetic_ids:
        low_quality_segments = [
            r for r in low_quality_segments
            if isinstance(r, dict) and r.get("segment") not in synthetic_ids
        ]
        transcript_artifacts = [
            r for r in transcript_artifacts
            if isinstance(r, dict) and r.get("segment_index") not in synthetic_ids
        ]

    # Count LQ segments with high-confidence repairs
    lq_repair_candidates = sum(
        1 for lq in low_quality_segments
        if isinstance(lq, dict)
        and isinstance(lq.get("repair_confidence"), (int, float))
        and lq["repair_confidence"] >= REPAIR_ACCEPT_THRESHOLD
    )

    # Stamp damage_severity on each artifact
    for artifact in transcript_artifacts:
        if not isinstance(artifact, dict):
            continue
        atype = artifact.get("artifact_type", "")
        artifact["damage_severity"] = ARTIFACT_DAMAGE_SEVERITY.get(atype, "medium")

    # Extract video_id
    video_id = data.get("video_id", "unknown")

    out = {
        "video_id": video_id,
        "generated_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        "pipeline_version": PIPELINE_VERSION,
        "source_file": str(input_path),
        "model": args.model,
        "low_quality_segments": low_quality_segments,
        "transcript_artifacts": transcript_artifacts,
        "summary": {
            "segments_total": len(valid_segments),
            "low_quality_count": len(low_quality_segments),
            "artifact_count": len(transcript_artifacts),
            "lq_repair_candidates": lq_repair_candidates,
            "artifact_types": dict(
                __import__("collections").Counter(
                    a.get("artifact_type", "unknown")
                    for a in transcript_artifacts
                    if isinstance(a, dict)
                )
            ),
        },
    }

    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(json.dumps(out, indent=2, ensure_ascii=False) + "\n", encoding="utf-8")

    print(
        f"{LOG_PREFIX} {input_path.name}: "
        f"low_quality={len(low_quality_segments)} (repairable={lq_repair_candidates}), artifacts={len(transcript_artifacts)}"
    )
    print(f"{LOG_PREFIX}   Output: {output_path}")
    return {
        "segments_total": len(valid_segments),
        "low_quality": len(low_quality_segments),
        "artifacts": len(transcript_artifacts),
    }


def _run_directory_with_files(
    files: List[Path],
    in_dir: Path,
    out_dir: Path,
    args: argparse.Namespace,
    *,
    output_root_dir: Optional[Path] = None,
    input_root_dir: Path,
    prompt_template: str,
    schema: Optional[Dict[str, Any]],
) -> None:
    if not files:
        return
    print(f"{LOG_PREFIX} Input : {in_dir}")
    print(f"{LOG_PREFIX} Output: {out_dir}")
    print(f"{LOG_PREFIX} Files : {len(files)}")

    processed = 0
    skipped = 0
    skipped_quarantine = 0
    failed = 0
    totals = {
        "segments_total": 0,
        "low_quality": 0,
        "artifacts": 0,
    }
    quarantine_ids: Set[str] = getattr(args, "_quarantine_ids", set())

    for input_file in files:
        quarantine_reason = get_quarantine_block_reason(input_file, quarantine_ids)
        if quarantine_reason:
            print(f"{LOG_PREFIX} SKIP: {input_file.name} - {quarantine_reason}")
            skipped_quarantine += 1
            continue
        preferred_output = compute_output_path_with_layout(
            input_file,
            out_dir,
            input_root_dir=in_dir,
        )
        existing_output = find_existing_output_path(
            input_file,
            out_dir,
            output_root_dir=output_root_dir,
            input_root_dir=in_dir,
        )
        if existing_output and not args.overwrite:
            skipped += 1
            continue
        try:
            counts = quality_check_file(
                input_file,
                preferred_output,
                args=args,
                input_root_dir=input_root_dir,
                prompt_template=prompt_template,
                schema=schema,
            )
            processed += 1
            for key in totals:
                totals[key] += int(counts.get(key, 0))
        except Exception as exc:
            failed += 1
            print(f"{LOG_PREFIX} ERROR: {input_file} -> {exc}")

    print(f"\n{LOG_PREFIX} Done.")
    print(f"  Processed:       {processed}")
    print(f"  Skipped:         {skipped}")
    print(f"  Skipped (quarantine): {skipped_quarantine}")
    print(f"  Failed:          {failed}")
    print(f"  Segments total:  {totals['segments_total']}")
    print(f"  Low quality:     {totals['low_quality']}")
    print(f"  Artifacts:       {totals['artifacts']}")
    if failed > 0:
        sys.exit(1)


def _run_directory(
    in_dir: Path,
    out_dir: Path,
    args: argparse.Namespace,
    *,
    input_root_dir: Path,
    prompt_template: str,
    schema: Optional[Dict[str, Any]],
) -> None:
    files = find_input_files(in_dir)
    if not files:
        print(f"{LOG_PREFIX} No .conversations.json files found in: {in_dir}")
        return
    _run_directory_with_files(
        files,
        in_dir,
        out_dir,
        args,
        input_root_dir=input_root_dir,
        prompt_template=prompt_template,
        schema=schema,
    )


def _run_input(
    args: argparse.Namespace,
    in_base: Path,
    out_base: Path,
    *,
    prompt_template: str,
    schema: Optional[Dict[str, Any]],
) -> None:
    input_path = Path(args.input)
    if not input_path.exists():
        input_path = repo_root() / args.input
    if not input_path.exists():
        raise SystemExit(f"Input not found: {args.input}")
    input_path = input_path.resolve()

    if input_path.is_file():
        quarantine_ids: Set[str] = getattr(args, "_quarantine_ids", set())
        quarantine_reason = get_quarantine_block_reason(input_path, quarantine_ids)
        if quarantine_reason:
            print(f"{LOG_PREFIX} SKIP: {input_path.name} - {quarantine_reason}")
            return
        out_dir = Path(args.output) if args.output else out_base
        output_path = compute_output_path_with_layout(input_path, out_dir, input_root_dir=in_base)
        if output_path.exists() and not args.overwrite:
            print(f"{LOG_PREFIX} Output exists, skipping: {output_path}")
            return
        quality_check_file(
            input_path,
            output_path,
            args=args,
            input_root_dir=in_base,
            prompt_template=prompt_template,
            schema=schema,
        )
        return

    out_dir = Path(args.output) if args.output else out_base
    _run_directory(
        input_path,
        out_dir,
        args,
        input_root_dir=in_base,
        prompt_template=prompt_template,
        schema=schema,
    )


def _run_sources(
    args: argparse.Namespace,
    in_base: Path,
    out_base: Path,
    *,
    prompt_template: str,
    schema: Optional[Dict[str, Any]],
) -> None:
    sources_path = repo_root() / args.sources
    if not sources_path.exists():
        raise SystemExit(f"Sources file not found: {sources_path}")
    for src_name, _ in parse_sources_file(sources_path):
        src_in_dir = in_base / src_name
        if not src_in_dir.exists():
            print(f"{LOG_PREFIX} Skipping {src_name}: no 06d.DET.sanitized output")
            continue
        src_out_dir = out_base / src_name
        files = find_input_files(src_in_dir)
        _run_directory_with_files(
            files,
            src_in_dir,
            src_out_dir,
            args,
            output_root_dir=out_base,
            input_root_dir=in_base,
            prompt_template=prompt_template,
            schema=schema,
        )


def _run_manifest(
    args: argparse.Namespace,
    in_base: Path,
    out_base: Path,
    *,
    prompt_template: str,
    schema: Optional[Dict[str, Any]],
) -> None:
    manifest_path = Path(args.manifest)
    if not manifest_path.is_absolute():
        manifest_path = repo_root() / manifest_path
    if not manifest_path.exists():
        raise SystemExit(f"Manifest file not found: {manifest_path}")
    sources_map = load_manifest_sources(manifest_path)
    for src_name, vid_ids in sorted(sources_map.items()):
        src_in_dir = in_base / src_name
        if not src_in_dir.exists():
            print(f"{LOG_PREFIX} Skipping {src_name}: no 06d.DET.sanitized output")
            continue
        src_out_dir = out_base / src_name
        files = manifest_filter_files(find_input_files(src_in_dir), vid_ids)
        if not files:
            print(f"{LOG_PREFIX} Skipping {src_name}: no manifest videos found in input")
            continue
        print(f"{LOG_PREFIX} Manifest: {src_name} ({len(files)} videos)")
        _run_directory_with_files(
            files,
            src_in_dir,
            src_out_dir,
            args,
            output_root_dir=out_base,
            input_root_dir=in_base,
            prompt_template=prompt_template,
            schema=schema,
        )


def _run_named_source(
    args: argparse.Namespace,
    in_base: Path,
    out_base: Path,
    *,
    prompt_template: str,
    schema: Optional[Dict[str, Any]],
) -> None:
    name = args.name
    in_dir = in_base / name
    if not in_dir.exists():
        raise SystemExit(f"Input directory not found: {in_dir}")
    out_dir = Path(args.output) if args.output else out_base / name
    _run_directory(
        in_dir,
        out_dir,
        args,
        input_root_dir=in_base,
        prompt_template=prompt_template,
        schema=schema,
    )


def main() -> None:
    parser = argparse.ArgumentParser(description="Stage 06e LLM quality check")
    parser.add_argument("name", nargs="?", help="Source name (folder under data/06d.DET.sanitized/)")
    parser.add_argument("youtube_url", nargs="?", help="Unused (pipeline compatibility)")
    parser.add_argument("--input", help="Input .conversations.json file or directory")
    parser.add_argument(
        "--input-root",
        help=(
            "Root directory for source/manifest runs "
            "(default: data/06d.DET.sanitized, or data/test/06d.sanitized with --test)"
        ),
    )
    parser.add_argument("--output", help="Output directory (default: data/06e.LLM.quality-check/)")
    parser.add_argument("--model", default="opus", help="Claude model (default: opus)")
    parser.add_argument("--timeout-seconds", type=int, default=600, help="Per-call timeout seconds")
    parser.add_argument("--retries", type=int, default=2, help="Retries per LLM call")
    parser.add_argument(
        "--llm-retries",
        type=int,
        help="Alias for --retries (for consistency with other LLM stages)",
    )
    parser.add_argument("--test", action="store_true", help="Use test roots under data/test/")
    parser.add_argument(
        "--sources",
        nargs="?",
        const="docs/pipeline/sources.txt",
        help="Process all sources from sources.txt file",
    )
    parser.add_argument("--manifest", help="Manifest file: process listed videos only")
    parser.add_argument("--dry-run", action="store_true", help="Preview without writing files")
    parser.add_argument("--overwrite", action="store_true", help="Overwrite existing output files")
    parser.add_argument(
        "--quarantine-file",
        help="Optional JSON file listing quarantined video IDs to skip",
    )
    args = parser.parse_args()

    if args.llm_retries is not None:
        args.retries = args.llm_retries

    args.timeout_seconds = max(1, int(args.timeout_seconds))
    args.retries = max(1, int(args.retries))

    args._quarantine_ids = set()
    if args.quarantine_file:
        quarantine_path = Path(args.quarantine_file)
        if not quarantine_path.is_absolute():
            quarantine_path = repo_root() / quarantine_path
        if not quarantine_path.exists():
            raise SystemExit(f"Quarantine file not found: {quarantine_path}")
        args._quarantine_ids = load_quarantine_video_ids(quarantine_path)
        print(f"{LOG_PREFIX} Loaded quarantine file: {quarantine_path} ({len(args._quarantine_ids)} video ids)")

    prompt_template = _load_prompt_template()
    schema = _load_schema()

    if args.test:
        in_root = resolve_root_path(args.input_root, test_input_root())
        out_root = Path(args.output) if args.output else test_output_root()
    else:
        in_root = resolve_root_path(args.input_root, input_root())
        out_root = Path(args.output) if args.output else output_root()

    if args.test:
        _run_directory(
            in_root,
            out_root,
            args,
            input_root_dir=in_root,
            prompt_template=prompt_template,
            schema=schema,
        )
    elif args.manifest:
        _run_manifest(
            args,
            in_root,
            out_root,
            prompt_template=prompt_template,
            schema=schema,
        )
    elif args.input:
        _run_input(
            args,
            in_root,
            out_root,
            prompt_template=prompt_template,
            schema=schema,
        )
    elif args.sources:
        _run_sources(
            args,
            in_root,
            out_root,
            prompt_template=prompt_template,
            schema=schema,
        )
    elif args.name:
        _run_named_source(
            args,
            in_root,
            out_root,
            prompt_template=prompt_template,
            schema=schema,
        )
    else:
        raise SystemExit("Provide a source name, --input, --test, --manifest, or --sources")


if __name__ == "__main__":
    main()
