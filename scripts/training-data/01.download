#!/usr/bin/env bash
# scripts/training-data/01.download
#
# Polite/reliable batch downloader:
# - Fixed pacing between items (playlist/channel safe)
# - Optional bandwidth cap
# - Outer exponential backoff on failure
# - Abort early on "bot-check" style responses (don't keep retrying)
#
# NOTE: This is NOT ‚Äústealth‚Äù. It just avoids abusive request patterns.

set -euo pipefail

usage() {
  cat <<'EOF'
Usage:

  Download one source (video/playlist/channel):
    ./scripts/training-data/01.download "<source_name>" "<youtube_url>"

  Download all sources from config:
    ./scripts/training-data/01.download --sources docs/sources.txt

Examples:
  ./scripts/training-data/01.download "daily_evolution" "https://www.youtube.com/watch?v=utuuVOXJunM"
  ./scripts/training-data/01.download --sources
EOF
}

safe_name() {
  printf '%s' "$1" | tr -cs 'A-Za-z0-9._-' '_' | sed -E 's/^_+//;s/_+$//'
}

have_cmd() { command -v "$1" >/dev/null 2>&1; }

# Pick downloader
DOWNLOADER="yt-dlp"
if ! have_cmd yt-dlp; then
  if have_cmd youtube-dl; then
    DOWNLOADER="youtube-dl"
  else
    echo "‚ùå Error: yt-dlp not found. Install:"
    echo "   pip install -U yt-dlp yt-dlp-ejs"
    exit 1
  fi
fi

# Need ffmpeg
if ! have_cmd ffmpeg; then
  echo "‚ùå Error: ffmpeg not found."
  exit 1
fi

FFPROBE_OK=0
if have_cmd ffprobe; then FFPROBE_OK=1; fi

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
ROOT_DIR="$(cd "$SCRIPT_DIR/../.." && pwd)"

OUTPUT_ROOT="${OUTPUT_ROOT:-"$ROOT_DIR/data/01.download"}"
COOKIES_FILE="${YOUTUBE_COOKIES_FILE:-"$ROOT_DIR/docs/data_docs/www.youtube.com_cookies.txt"}"

# --------------------------
# Gentle / compliance-friendly pacing knobs
# --------------------------
# Fixed delay between items within playlist/channel downloads (seconds).
# Kept fixed (not randomized) on purpose.
SLEEP_BETWEEN_ITEMS_SEC="${SLEEP_BETWEEN_ITEMS_SEC:-8}"

# Extra fixed delay between processing each line in --sources mode.
SLEEP_BETWEEN_SOURCES_SEC="${SLEEP_BETWEEN_SOURCES_SEC:-12}"

# Optional bandwidth cap for downloads (yt-dlp: --limit-rate). Examples: 500K, 2M, 10M
LIMIT_RATE="${LIMIT_RATE:-2M}"

# Outer retry/backoff (script-level) for whole yt-dlp call
OUTER_MAX_ATTEMPTS="${OUTER_MAX_ATTEMPTS:-3}"
OUTER_BACKOFF_BASE_SEC="${OUTER_BACKOFF_BASE_SEC:-15}"
OUTER_BACKOFF_MAX_SEC="${OUTER_BACKOFF_MAX_SEC:-300}"

# Inner yt-dlp retry knobs (still useful for flaky fragments)
CONCURRENT_FRAGMENTS="${CONCURRENT_FRAGMENTS:-1}"
RETRIES="${RETRIES:-8}"
FRAGMENT_RETRIES="${FRAGMENT_RETRIES:-8}"
RETRY_SLEEP="${RETRY_SLEEP:-2}"

# ASR audio standardization
ASR_SAMPLE_RATE="${ASR_SAMPLE_RATE:-16000}"

ASR_CLEAN_FILTERS="${ASR_CLEAN_FILTERS:-highpass=f=80,lowpass=f=8000,afftdn=nf=-25,alimiter=limit=0.97}"
ASR_RESYNC_FILTER="${ASR_RESYNC_FILTER:-aresample=async=1:first_pts=0}"

MAKE_PREVIEW_MP3="${MAKE_PREVIEW_MP3:-1}"
PREVIEW_MP3_BITRATE="${PREVIEW_MP3_BITRATE:-128k}"

FFMPEG_TIMEOUT_SEC="${FFMPEG_TIMEOUT_SEC:-600}"
USE_TIMEOUT=0
if have_cmd timeout; then USE_TIMEOUT=1; fi

# --------------------------
# JS runtime detection (yt-dlp)
# --------------------------
js_runtime_args=()
extractor_args=()

if [[ "$DOWNLOADER" == "yt-dlp" ]]; then
  if have_cmd deno; then
    js_runtime_args=(--js-runtimes deno)
  elif have_cmd node; then
    js_runtime_args=(--js-runtimes node)
  elif have_cmd qjs; then
    js_runtime_args=(--js-runtimes quickjs)
  elif have_cmd bun; then
    js_runtime_args=(--js-runtimes bun)
  else
    echo "‚ùå Error: No JS runtime found (needed for reliable extraction). Install deno or node."
    exit 1
  fi
  extractor_args=()
fi

# --------------------------
# Common yt-dlp args
# --------------------------
common_dl_args=()
if [[ "$DOWNLOADER" == "yt-dlp" ]]; then
  common_dl_args=(
    --retries "$RETRIES"
    --fragment-retries "$FRAGMENT_RETRIES"
    --file-access-retries "$FRAGMENT_RETRIES"
    --retry-sleep "$RETRY_SLEEP"
    --concurrent-fragments "$CONCURRENT_FRAGMENTS"
    --continue
    --no-post-overwrites
    --ignore-errors
    --progress
    --newline

    # Gentle pacing between playlist items (fixed)
    --sleep-interval "$SLEEP_BETWEEN_ITEMS_SEC"
    --max-sleep-interval "$SLEEP_BETWEEN_ITEMS_SEC"
  )
  if [[ -n "${LIMIT_RATE// }" ]]; then
    common_dl_args+=( --limit-rate "$LIMIT_RATE" )
  fi
else
  common_dl_args=( --continue --ignore-errors )
fi

# --------------------------
# Helpers
# --------------------------
ffprobe_duration_sec() {
  local f="$1"
  if [[ "$FFPROBE_OK" -ne 1 || ! -f "$f" ]]; then
    echo "0"
    return 0
  fi
  ffprobe -v error -show_entries format=duration \
    -of default=nokey=1:noprint_wrappers=1 "$f" 2>/dev/null \
    | awk '{printf "%.3f\n", $1}'
}

run_ffmpeg() {
  local log_file="$1"; shift
  if [[ "$USE_TIMEOUT" -eq 1 ]]; then
    timeout "$FFMPEG_TIMEOUT_SEC" ffmpeg -nostdin "$@" 2>>"$log_file"
  else
    ffmpeg -nostdin "$@" 2>>"$log_file"
  fi
}

detect_botcheck_in_file() {
  # Conservative patterns that usually indicate a human verification gate.
  local f="$1"
  grep -Eqi \
    "unusual traffic|not a robot|captcha|verify you are|confirm you|sign in to confirm|robot check|sorry.*cannot process|access denied" \
    "$f"
}

dl_with_backoff() {
  # dl_with_backoff <log_file> <cmd...>
  local log_file="$1"; shift
  local attempt=1
  local tmp
  tmp="$(mktemp)"

  while [[ "$attempt" -le "$OUTER_MAX_ATTEMPTS" ]]; do
    echo "" >>"$log_file"
    echo "----- Attempt $attempt/$OUTER_MAX_ATTEMPTS -----" >>"$log_file"

    set +e
    "$@" 2>&1 | tee "$tmp"
    local status="${PIPESTATUS[0]}"
    set -e

    cat "$tmp" >>"$log_file"

    if detect_botcheck_in_file "$tmp"; then
      echo "‚ùå Detected a likely human-verification/bot-check response. Stopping (do not hammer retries)." | tee -a "$log_file"
      rm -f "$tmp"
      return 77
    fi

    if [[ "$status" -eq 0 ]]; then
      rm -f "$tmp"
      return 0
    fi

    # Backoff before next attempt
    local sleep_sec
    sleep_sec="$(awk -v b="$OUTER_BACKOFF_BASE_SEC" -v a="$attempt" 'BEGIN{v=b*(2^(a-1)); printf "%.0f", v}')"
    if [[ "$sleep_sec" -gt "$OUTER_BACKOFF_MAX_SEC" ]]; then
      sleep_sec="$OUTER_BACKOFF_MAX_SEC"
    fi
    echo "‚ö†Ô∏è Download failed (exit $status). Backing off ${sleep_sec}s before retry..." | tee -a "$log_file"
    sleep "$sleep_sec"
    attempt=$((attempt + 1))
  done

  rm -f "$tmp"
  return 1
}

# --------------------------
# ASR building (same as your logic)
# --------------------------
make_asr_outputs_for_input() {
  local in_audio="$1"
  local log_file="$2"

  local stem="${in_audio%.*}"
  local raw_out="${stem}.asr.raw16k.wav"
  local clean_out="${stem}.asr.clean16k.wav"
  local mp3_out="${stem}.listen.mp3"

  if [[ ! -f "$raw_out" ]]; then
    run_ffmpeg "$log_file" -hide_banner -loglevel warning -y \
      -i "$in_audio" \
      -map 0:a:0? -vn -sn -dn \
      -ac 1 -ar "$ASR_SAMPLE_RATE" -c:a pcm_s16le \
      -af "$ASR_RESYNC_FILTER" \
      "$raw_out" || echo "‚ö†Ô∏è RAW WAV failed: $raw_out" >>"$log_file"
  fi

  if [[ ! -f "$clean_out" ]]; then
    run_ffmpeg "$log_file" -hide_banner -loglevel warning -y \
      -i "$in_audio" \
      -map 0:a:0? -vn -sn -dn \
      -ac 1 -ar "$ASR_SAMPLE_RATE" -c:a pcm_s16le \
      -af "$ASR_CLEAN_FILTERS,$ASR_RESYNC_FILTER" \
      "$clean_out" || echo "‚ö†Ô∏è CLEAN WAV failed: $clean_out" >>"$log_file"
  fi

  if [[ -f "$raw_out" && -f "$clean_out" && "$FFPROBE_OK" -eq 1 ]]; then
    local d_raw d_clean min_ok
    d_raw="$(ffprobe_duration_sec "$raw_out")"
    d_clean="$(ffprobe_duration_sec "$clean_out")"
    min_ok="$(awk -v r="$d_raw" 'BEGIN{printf "%.3f", (r - 0.500)}')"

    if awk -v c="$d_clean" -v m="$min_ok" 'BEGIN{exit !(c < m)}'; then
      local safer_filters="highpass=f=80,lowpass=f=8000,alimiter=limit=0.97"
      rm -f "$clean_out" 2>/dev/null || true
      run_ffmpeg "$log_file" -hide_banner -loglevel warning -y \
        -i "$in_audio" \
        -map 0:a:0? -vn -sn -dn \
        -ac 1 -ar "$ASR_SAMPLE_RATE" -c:a pcm_s16le \
        -af "$safer_filters,$ASR_RESYNC_FILTER" \
        "$clean_out" || true

      d_clean="$(ffprobe_duration_sec "$clean_out")"
      min_ok="$(awk -v r="$d_raw" 'BEGIN{printf "%.3f", (r - 0.500)}')"
      if awk -v c="$d_clean" -v m="$min_ok" 'BEGIN{exit !(c < m)}'; then
        cp -f "$raw_out" "$clean_out"
      fi
    fi
  fi

  if [[ "$MAKE_PREVIEW_MP3" == "1" && ! -f "$mp3_out" ]]; then
    run_ffmpeg "$log_file" -hide_banner -loglevel warning -y \
      -i "$in_audio" \
      -map 0:a:0? -vn -sn -dn \
      -c:a libmp3lame -b:a "$PREVIEW_MP3_BITRATE" \
      "$mp3_out" || echo "‚ö†Ô∏è MP3 preview failed: $mp3_out" >>"$log_file"
  fi
}

make_asr_files() {
  local output_dir="$1"
  local log_file="$output_dir/audio-asr-build.log"
  : > "$log_file"

  local found_any=0
  while IFS= read -r -d '' in_audio; do
    found_any=1
    make_asr_outputs_for_input "$in_audio" "$log_file"
    done < <(
    # Only actual audio containers (avoid *.info.json etc.)
    find "$output_dir" -type f \( \
        -iname "*.audio.webm" -o \
        -iname "*.audio.m4a"  -o \
        -iname "*.audio.mp3"  -o \
        -iname "*.audio.mp4"  -o \
        -iname "*.audio.mkv"  -o \
        -iname "*.audio.opus" -o \
        -iname "*.audio.mka" \
      \) -print0
  )


  if [[ "$found_any" -eq 0 ]]; then
    while IFS= read -r -d '' mp4; do
      make_asr_outputs_for_input "$mp4" "$log_file"
    done < <(find "$output_dir" -type f -name "*.mp4" -print0)
  fi
}

download_one() {
  local source_name="$1"
  local youtube_url="$2"

  local safe_source
  safe_source="$(safe_name "$source_name")"
  local output_dir="$OUTPUT_ROOT/$safe_source"

  local archive_audio="$output_dir/.youtube-dl-archive.audio.txt"
  local archive_video="$output_dir/.youtube-dl-archive.video.txt"
  local log_audio="$output_dir/download-audio.log"
  local log_video="$output_dir/download-video.log"

  mkdir -p "$output_dir"

  local -a cookies_args=()
  if [[ -f "$COOKIES_FILE" ]]; then
    local runtime_cookie="$output_dir/.yt-dlp-cookies.runtime.txt"
    cp "$COOKIES_FILE" "$runtime_cookie"
    chmod 600 "$runtime_cookie" 2>/dev/null || true
    cookies_args=(--cookies "$runtime_cookie")
  fi

  local base="$output_dir/%(title)s [%(id)s]/%(title)s [%(id)s]"

  echo "================================"
  echo "üì• $source_name"
  echo "   $youtube_url"
  echo "   -> $output_dir"
  echo "================================"

  # AUDIO
  : > "$log_audio"
  dl_with_backoff "$log_audio" \
    "$DOWNLOADER" \
      --format "bestaudio/best" \
      --output "${base}.audio.%(ext)s" \
      --write-info-json \
      --download-archive "$archive_audio" \
      --no-post-overwrites \
      "${common_dl_args[@]}" \
      "${js_runtime_args[@]}" \
      "${extractor_args[@]}" \
      "${cookies_args[@]}" \
      "$youtube_url" || {
        rc=$?
        echo "‚ö†Ô∏è Audio step ended (code $rc). Log: $log_audio"
        [[ "$rc" -eq 77 ]] && return 77
      }

  make_asr_files "$output_dir"

  # VIDEO
  : > "$log_video"
  VIDEO_FORMAT="${VIDEO_FORMAT:-best[ext=mp4]/best}"
  if [[ "${HIGH_QUALITY_VIDEO:-0}" == "1" ]]; then
    VIDEO_FORMAT="bv*[ext=mp4]+ba[ext=m4a]/b[ext=mp4]/bv*+ba/b"
  fi

  dl_with_backoff "$log_video" \
    "$DOWNLOADER" \
      --format "$VIDEO_FORMAT" \
      --merge-output-format mp4 \
      --output "${base}.%(ext)s" \
      --write-info-json \
      --download-archive "$archive_video" \
      --no-post-overwrites \
      "${common_dl_args[@]}" \
      "${js_runtime_args[@]}" \
      "${extractor_args[@]}" \
      "${cookies_args[@]}" \
      "$youtube_url" || {
        rc=$?
        echo "‚ö†Ô∏è Video step ended (code $rc). Log: $log_video"
        [[ "$rc" -eq 77 ]] && return 77
      }
  make_asr_files "$output_dir"
  echo "‚úÖ Done: $source_name"
}

download_from_sources() {
  local sources_file="${1:-$ROOT_DIR/docs/sources.txt}"
  [[ -f "$sources_file" ]] || { echo "‚ùå Sources file not found: $sources_file"; exit 1; }

  while IFS= read -r line <&3; do
    [[ -z "${line//[[:space:]]/}" ]] && continue
    [[ "$line" =~ ^[[:space:]]*# ]] && continue

    local source_name youtube_url
    if [[ "$line" == *"|"* ]]; then
      source_name="${line%%|*}"
      youtube_url="${line#*|}"
    else
      source_name="${line%%[[:space:]]*}"
      youtube_url="${line#"$source_name"}"
      youtube_url="${youtube_url#"${youtube_url%%[![:space:]]*}"}"
    fi

    [[ -z "$source_name" || -z "$youtube_url" ]] && continue

    download_one "$source_name" "$youtube_url" || {
      rc=$?
      if [[ "$rc" -eq 77 ]]; then
        echo "‚ùå Stopped due to likely verification gate. Fix auth/permissions, then resume."
        exit 77
      fi
      echo "‚ö†Ô∏è Failed source: $source_name (code $rc) ‚Äî continuing..."
    }

    sleep "$SLEEP_BETWEEN_SOURCES_SEC"
  done 3< "$sources_file"
}


case "${1:-}" in
  -h|--help) usage; exit 0 ;;
  --sources) download_from_sources "${2:-}" ;;
  "") usage; exit 1 ;;
  *) [[ $# -ge 2 ]] || { echo "‚ùå Need <source_name> <youtube_url>"; usage; exit 1; }
     download_one "$1" "$2"
     ;;
esac
