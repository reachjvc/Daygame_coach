#!/usr/bin/env python3
"""
scripts/training-data/08.content

Content Enrichment using Claude Code CLI

Reads:
  - Speaker-corrected conversation files:
      data/07.speaker-correction/<source>/<video>/*.corrected.json

Writes:
  - Enriched conversation files:
      data/08.content/<source>/<video>/*.enriched.json

The enrichment adds:
  - Detailed technique detection with explanations
  - Topic extraction from conversation content
  - Interaction quality assessment
  - Per-conversation analysis

Architecture:
  - Single Claude CLI call per VIDEO (not per interaction)
  - All conversations in one video processed together
  - Taxonomy sent once, outputs JSONL

Use:

  A) Test videos:
     ./scripts/training-data/08.content --test

  B) Single file:
     ./scripts/training-data/08.content --input data/test/07.speaker-correction/video.corrected.json

  C) Batch from sources file:
     ./scripts/training-data/08.content --sources

Requirements:
  - Claude Code CLI installed and authenticated (claude command available)
"""

from __future__ import annotations

import argparse
import hashlib
import json
import re
import shlex
import subprocess
import time
from dataclasses import dataclass, asdict
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple


# ---------------------------
# Technique and Topic Taxonomies (synced with STAGE_08_content.md)
# ---------------------------

# 31 techniques across 5 categories
TECHNIQUE_TAXONOMY = {
    # Openers (5)
    "direct_opener": "Explicitly stating attraction/interest upfront ('I think you're attractive')",
    "indirect_opener": "Starting conversation without revealing intent (asking for directions, opinion)",
    "situational_opener": "Opening based on something happening in the environment",
    "observation_opener": "Commenting on something specific about her (outfit, book, behavior)",
    "gambit": "Pre-planned opener or routine to spark conversation",

    # Attraction (9)
    "push_pull": "Giving a compliment then taking it away, or vice versa ('You seem cool... for a tourist')",
    "tease": "Playful mocking or joking at her expense in a fun way",
    "cold_read": "Making an assumption about her personality/life ('You look like a yoga teacher')",
    "role_play": "Creating imaginary scenarios together ('We'd make terrible dance partners')",
    "disqualification": "Playfully suggesting you two wouldn't work out",
    "DHV": "Demonstration of higher value through stories or behavior",
    "frame_control": "Maintaining your perspective/reality in the interaction",
    "takeaway": "Withdrawing attention or threatening to leave",
    "false_time_constraint": "Saying you need to leave soon to reduce pressure",

    # Connection (8)
    "qualification": "Asking what makes her special beyond looks ('What's your passion?')",
    "statement_of_intent": "Clearly expressing romantic/sexual interest",
    "grounding": "Sharing personal details to build trust and rapport",
    "storytelling": "Using engaging stories to convey personality",
    "vulnerability": "Sharing something genuine/personal to create connection",
    "callback_humor": "Referencing something mentioned earlier in conversation",
    "screening": "Asking questions to evaluate her as a potential partner",
    "appreciation": "Expressing genuine appreciation for something about her",

    # Compliance (1)
    "compliance": "Getting her to agree to small requests, building investment",

    # Closing (8)
    "number_close": "Asking for her phone number",
    "instagram_close": "Asking for her Instagram handle",
    "soft_close": "Suggesting future meeting without immediate commitment",
    "assumptive_close": "Acting as if she's already agreed ('So when are you free?')",
    "instant_date": "Suggesting to continue hanging out right now",
    "bounce": "Moving to a different location together",
    "time_bridge": "Setting up specific future plans",
    "logistics_check": "Asking about her schedule/availability",
}

# 22 topics across 5 categories
TOPIC_TAXONOMY = {
    # Personal (8)
    "name": "Her name or introductions",
    "origin": "Where she's from, nationality, hometown",
    "career": "Job, profession, what she does for work",
    "education": "Studies, university, school",
    "hobby": "Interests, activities, passions",
    "travel": "Trips, places visited, travel plans",
    "living_situation": "Where she lives, roommates, neighborhood",
    "ambitions": "Goals, dreams, future plans",

    # Appearance (1)
    "appearance": "General looks, attractiveness comments, style",

    # Personality (4)
    "personality": "Character traits, demeanor",
    "age": "How old she is, age-related topics",
    "behavior": "How she acts, mannerisms",
    "values": "What she cares about, beliefs",

    # Logistics (5)
    "plans": "What she's doing today, schedule",
    "contact": "Exchanging numbers, social media",
    "logistics": "Meeting up, availability, dating",
    "relationship": "Boyfriend, dating status",
    "duration": "How long she's in town, staying",

    # Context (4)
    "food_drinks": "Coffee, restaurants, bars",
    "location": "The current place, area, city",
    "humor": "Jokes, banter, playful exchanges",
    "flirting": "Romantic/sexual tension, attraction",
}


@dataclass
class ConversationEnrichment:
    conversation_id: int
    type: str  # "approach" or "commentary"
    description: str
    techniques_used: List[Dict[str, Any]]
    topics_discussed: List[str]
    quality: Dict[str, Any]


@dataclass
class ProcessingState:
    version: int
    completed_files: List[str]
    in_progress: Optional[str]
    failures: List[Dict[str, str]]


def load_state(state_path: Path) -> ProcessingState:
    """Load processing state from file."""
    if state_path.exists():
        try:
            data = json.loads(state_path.read_text())
            return ProcessingState(
                version=data.get("version", 1),
                completed_files=data.get("completed_files", []),
                in_progress=data.get("in_progress"),
                failures=data.get("failures", []),
            )
        except (json.JSONDecodeError, KeyError):
            pass
    return ProcessingState(version=1, completed_files=[], in_progress=None, failures=[])


def save_state(state_path: Path, state: ProcessingState) -> None:
    """Save processing state to file."""
    state_path.parent.mkdir(parents=True, exist_ok=True)
    state_path.write_text(json.dumps(asdict(state), indent=2))


def call_claude(prompt: str, retries: int = 3, timeout: int = 600) -> Optional[str]:
    """Call Claude Code CLI with retry logic."""
    for attempt in range(retries):
        try:
            result = subprocess.run(
                ["claude", "-p", prompt, "--output-format", "text"],
                capture_output=True,
                text=True,
                timeout=timeout
            )
            if result.returncode == 0:
                return result.stdout.strip()
            else:
                if attempt < retries - 1:
                    wait = 2 ** attempt
                    print(f"[08.content] Claude CLI error, retrying in {wait}s...")
                    time.sleep(wait)
                    continue
                print(f"[08.content] Claude CLI error: {result.stderr[:200]}")
        except subprocess.TimeoutExpired:
            if attempt < retries - 1:
                print(f"[08.content] Timeout, retrying...")
                time.sleep(2 ** attempt)
                continue
            print(f"[08.content] Claude CLI timeout after {timeout}s")
        except FileNotFoundError:
            print("[08.content] Error: 'claude' command not found. Install Claude Code CLI.")
            return None
    return None


def group_segments_by_conversation(segments: List[Dict]) -> Dict[int, List[Dict]]:
    """Group segments by conversation_id."""
    conversations: Dict[int, List[Dict]] = {}
    for seg in segments:
        conv_id = seg.get("conversation_id", 0)
        if conv_id not in conversations:
            conversations[conv_id] = []
        conversations[conv_id].append(seg)
    return conversations


def build_video_prompt(conversations: Dict[int, List[Dict]], video_id: str) -> str:
    """Build a single prompt for all conversations in a video."""

    # Build technique list (all 31)
    technique_list = "\n".join([f"  - {k}: {v}" for k, v in TECHNIQUE_TAXONOMY.items()])

    # Build topic list
    topic_list = ", ".join(TOPIC_TAXONOMY.keys())

    # Format all conversations
    conversation_blocks = []
    for conv_id in sorted(conversations.keys()):
        if conv_id == 0:
            continue  # Skip commentary/transitions

        segments = conversations[conv_id]
        turns = []
        for i, seg in enumerate(segments):
            speaker = seg.get("speaker_role", seg.get("speaker_id", "unknown"))
            text = seg.get("text", "").strip()
            turns.append(f"  [{i}] {speaker.upper()}: {text}")

        conversation_blocks.append(f"""
CONVERSATION #{conv_id}
Segments: {len(segments)}
Start: {segments[0].get('start', 0):.1f}s
End: {segments[-1].get('end', 0):.1f}s

{chr(10).join(turns)}
""")

    all_conversations = "\n---\n".join(conversation_blocks)

    prompt = f"""You are an expert daygame analyst. Analyze ALL conversations in this video and extract detailed metadata.

VIDEO: {video_id}
TOTAL CONVERSATIONS: {len([c for c in conversations if c > 0])}

TECHNIQUE REFERENCE (31 techniques):
{technique_list}

TOPIC REFERENCE: {topic_list}

CONVERSATIONS TO ANALYZE:
{all_conversations}

FOR EACH CONVERSATION, analyze:

1. TYPE: "approach" (coach talking to woman) or "commentary" (explaining to camera)

2. DESCRIPTION: Concise 10-20 word summary

3. TECHNIQUES: List techniques demonstrated with segment index and brief example quote

4. TOPICS: List topics discussed (only include actually discussed topics)

5. QUALITY:
   - hook_point_reached: true/false (did she become engaged?)
   - investment_level: low/medium/high
   - vibe_quality: awkward/neutral/good/great
   - close_attempted: true/false
   - close_success: true/false/partial/unknown

OUTPUT FORMAT: Return a JSON array with one object per conversation.
Output ONLY valid JSON, no explanation text.

EXAMPLE:
[
  {{
    "conversation_id": 1,
    "type": "approach",
    "description": "Direct opener on tourist, good vibe, number close",
    "techniques_used": [
      {{"technique": "direct_opener", "segment": 0, "example": "Hey, I saw you and had to say hi"}},
      {{"technique": "cold_read", "segment": 3, "example": "You look like you do yoga"}}
    ],
    "topics_discussed": ["origin", "career", "travel"],
    "quality": {{
      "hook_point_reached": true,
      "investment_level": "medium",
      "vibe_quality": "good",
      "close_attempted": true,
      "close_success": true
    }}
  }},
  {{
    "conversation_id": 2,
    ...
  }}
]

YOUR JSON RESPONSE:"""

    return prompt


def parse_enrichment_response(response: str) -> List[Dict]:
    """Parse JSON array from LLM response."""
    if not response:
        return []

    try:
        # Try to find JSON array in code block
        code_block_match = re.search(r"```(?:json)?\s*(\[[\s\S]*?\])\s*```", response)
        if code_block_match:
            return json.loads(code_block_match.group(1))

        # Try to find raw JSON array
        start = response.find("[")
        if start != -1:
            bracket_count = 0
            for i, char in enumerate(response[start:], start):
                if char == "[":
                    bracket_count += 1
                elif char == "]":
                    bracket_count -= 1
                    if bracket_count == 0:
                        json_str = response[start:i + 1]
                        return json.loads(json_str)
    except (json.JSONDecodeError, ValueError) as e:
        print(f"[08.content] JSON parse error: {e}")
        print(f"[08.content] Response preview: {response[:500]}...")

    return []


def process_video_file(input_path: Path, output_path: Path, dry_run: bool = False) -> Dict[str, Any]:
    """Process a single video's corrected.json file."""

    print(f"[08.content] Processing: {input_path.name}")

    # Load input
    with input_path.open("r", encoding="utf-8") as f:
        data = json.load(f)

    segments = data.get("segments", [])
    video_id = data.get("video_id", input_path.stem)

    if not segments:
        print(f"[08.content] No segments found")
        return {"conversations": 0, "enriched": 0}

    # Group by conversation
    conversations = group_segments_by_conversation(segments)
    approach_convs = {k: v for k, v in conversations.items() if k > 0}

    print(f"[08.content]   {len(segments)} segments, {len(approach_convs)} conversations")

    if not approach_convs:
        print(f"[08.content]   No approach conversations to enrich")
        # Still write output with empty enrichments
        output = {
            "metadata": {
                "source_file": str(input_path),
                "processed_at": time.strftime("%Y-%m-%dT%H:%M:%SZ"),
                "conversations_enriched": 0,
            },
            "video_id": video_id,
            "video_type": data.get("video_type"),
            "speaker_labels": data.get("speaker_labels"),
            "speaker_corrections": data.get("speaker_corrections", []),
            "segments": segments,
            "enrichments": [],
        }
        if not dry_run:
            output_path.parent.mkdir(parents=True, exist_ok=True)
            with output_path.open("w", encoding="utf-8") as f:
                json.dump(output, f, ensure_ascii=False)
        return {"conversations": 0, "enriched": 0}

    if dry_run:
        print(f"[08.content]   [DRY RUN] Would call Claude CLI to enrich {len(approach_convs)} conversations")
        return {"conversations": len(approach_convs), "enriched": 0}

    # Build prompt and call Claude (single call for all conversations)
    prompt = build_video_prompt(conversations, video_id)
    print(f"[08.content]   Calling Claude CLI (single call for {len(approach_convs)} conversations)...")

    start_time = time.time()
    response = call_claude(prompt, timeout=600)
    elapsed = time.time() - start_time

    enrichments = []
    if response:
        enrichments = parse_enrichment_response(response)
        print(f"[08.content]   Got {len(enrichments)} enrichments in {elapsed:.1f}s")
    else:
        print(f"[08.content]   Claude call failed, using empty enrichments")

    # Build enrichment lookup
    enrichment_map = {e.get("conversation_id"): e for e in enrichments}

    # Build output
    output = {
        "metadata": {
            "source_file": str(input_path),
            "processed_at": time.strftime("%Y-%m-%dT%H:%M:%SZ"),
            "conversations_enriched": len(enrichments),
            "processing_time_sec": elapsed,
            "model": "claude-cli",
        },
        "video_id": video_id,
        "video_type": data.get("video_type"),
        "speaker_labels": data.get("speaker_labels"),
        "speaker_corrections": data.get("speaker_corrections", []),
        "segments": segments,
        "enrichments": enrichments,
        "summary": {
            "total_conversations": len(approach_convs),
            "enriched_conversations": len(enrichments),
            "techniques_found": sorted(set(
                t.get("technique", "")
                for e in enrichments
                for t in e.get("techniques_used", [])
                if t.get("technique")
            )),
            "topics_found": sorted(set(
                topic
                for e in enrichments
                for topic in e.get("topics_discussed", [])
            )),
        },
    }

    # Write output
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with output_path.open("w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False)

    print(f"[08.content]   Wrote: {output_path}")

    return {
        "conversations": len(approach_convs),
        "enriched": len(enrichments),
    }


# ---------------------------
# Path helpers
# ---------------------------

def repo_root() -> Path:
    return Path(__file__).resolve().parents[2]


def input_root() -> Path:
    return repo_root() / "data" / "07.speaker-correction"


def output_root() -> Path:
    return repo_root() / "data" / "08.content"


def test_input_root() -> Path:
    return repo_root() / "data" / "test" / "07.speaker-correction"


def test_output_root() -> Path:
    return repo_root() / "data" / "test" / "08.content"


def compute_output_path(input_path: Path, output_dir: Path) -> Path:
    """Compute output path from input path."""
    stem = input_path.stem
    if stem.endswith(".corrected"):
        stem = stem[:-len(".corrected")]
    return output_dir / f"{stem}.enriched.json"


def parse_sources_file(path: Path) -> List[Tuple[str, str]]:
    """Parse sources.txt file."""
    sources: List[Tuple[str, str]] = []
    for raw in path.read_text(encoding="utf-8").splitlines():
        line = raw.strip()
        if not line or line.startswith("#"):
            continue
        if "|" in line:
            name, url = line.split("|", 1)
            sources.append((name.strip(), url.strip()))
            continue
        parts = shlex.split(line)
        if len(parts) >= 2:
            sources.append((parts[0], parts[1]))
    return sources


def find_input_files(in_dir: Path) -> List[Path]:
    """Find all corrected JSON files in directory."""
    return sorted(in_dir.rglob("*.corrected.json"))


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Enrich conversations with technique/topic analysis using Claude CLI"
    )
    parser.add_argument(
        "--input",
        help="Input .corrected.json file or directory"
    )
    parser.add_argument(
        "--output",
        help="Output directory (defaults to data/08.content/)"
    )
    parser.add_argument(
        "--test",
        action="store_true",
        help="Process test videos (data/test/07.speaker-correction/)"
    )
    parser.add_argument(
        "--sources",
        nargs="?",
        const="docs/sources.txt",
        help="Process all sources from sources.txt file"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Preview what would be processed"
    )
    parser.add_argument(
        "--overwrite",
        action="store_true",
        help="Overwrite existing output files"
    )

    args = parser.parse_args()

    # Test Claude CLI availability
    try:
        result = subprocess.run(
            ["claude", "--version"],
            capture_output=True,
            text=True,
            timeout=10
        )
        if result.returncode != 0:
            print("[08.content] Warning: Claude CLI not responding properly")
    except FileNotFoundError:
        print("[08.content] Error: 'claude' command not found")
        print("[08.content] Install Claude Code CLI: https://claude.ai/code")
        return
    except subprocess.TimeoutExpired:
        print("[08.content] Warning: Claude CLI slow to respond")

    # Determine input/output paths
    if args.test:
        in_dir = test_input_root()
        out_dir = test_output_root()
    elif args.input:
        input_path = Path(args.input)
        if not input_path.exists():
            input_path = repo_root() / args.input
        if not input_path.exists():
            raise SystemExit(f"Input not found: {args.input}")

        if input_path.is_file():
            # Single file mode
            out_dir = Path(args.output) if args.output else output_root()
            output_path = compute_output_path(input_path, out_dir)

            if output_path.exists() and not args.overwrite:
                print(f"[08.content] Output exists, skipping: {output_path}")
                return

            result = process_video_file(input_path, output_path, dry_run=args.dry_run)
            print(f"\n[08.content] Done. Enriched {result['enriched']}/{result['conversations']} conversations")
            return

        in_dir = input_path
        out_dir = Path(args.output) if args.output else output_root()
    elif args.sources:
        sources_path = repo_root() / args.sources
        if not sources_path.exists():
            raise SystemExit(f"Sources file not found: {sources_path}")

        total_convs = 0
        total_enriched = 0

        for src_name, _ in parse_sources_file(sources_path):
            src_in_dir = input_root() / src_name
            if not src_in_dir.exists():
                print(f"[08.content] Skipping {src_name}: no 07.speaker-correction output")
                continue

            src_out_dir = output_root() / src_name
            files = find_input_files(src_in_dir)

            for input_file in files:
                output_file = compute_output_path(input_file, src_out_dir)
                if output_file.exists() and not args.overwrite:
                    continue
                result = process_video_file(input_file, output_file, dry_run=args.dry_run)
                total_convs += result["conversations"]
                total_enriched += result["enriched"]

        print(f"\n[08.content] Done. Enriched {total_enriched}/{total_convs} conversations total")
        return
    else:
        raise SystemExit("Provide --input, --test, or --sources")

    # Directory mode
    files = find_input_files(in_dir)
    if not files:
        print(f"[08.content] No .corrected.json files found in: {in_dir}")
        return

    print(f"[08.content] Input : {in_dir}")
    print(f"[08.content] Output: {out_dir}")
    print(f"[08.content] Files : {len(files)}")

    # Load state for checkpointing
    state_path = out_dir / ".enrichment_state.json"
    state = load_state(state_path)

    total_convs = 0
    total_enriched = 0
    processed = 0
    skipped = 0

    for input_file in files:
        file_key = str(input_file.relative_to(in_dir))

        # Skip if already completed
        if file_key in state.completed_files and not args.overwrite:
            skipped += 1
            continue

        output_file = compute_output_path(input_file, out_dir)

        if output_file.exists() and not args.overwrite:
            skipped += 1
            state.completed_files.append(file_key)
            save_state(state_path, state)
            continue

        # Mark as in progress
        state.in_progress = file_key
        save_state(state_path, state)

        try:
            result = process_video_file(input_file, output_file, dry_run=args.dry_run)
            total_convs += result["conversations"]
            total_enriched += result["enriched"]
            processed += 1

            # Mark as completed
            if not args.dry_run:
                state.completed_files.append(file_key)
                state.in_progress = None
                save_state(state_path, state)
        except Exception as e:
            print(f"[08.content] Error processing {input_file}: {e}")
            state.failures.append({"file": file_key, "error": str(e)})
            state.in_progress = None
            save_state(state_path, state)

    print(f"\n[08.content] Done.")
    print(f"  Processed: {processed}")
    print(f"  Skipped  : {skipped}")
    print(f"  Enriched : {total_enriched}/{total_convs} conversations")


if __name__ == "__main__":
    main()
