#!/usr/bin/env python3
"""
scripts/training-data/07.content

Content Enrichment using Claude Code CLI

Reads:
  - Conversation files (from Stage 06c patched output):
      data/06c.patched/<source>/<video>/*.conversations.json

Writes:
  - Enriched conversation files:
      data/07.content/<source>/<video>/*.enriched.json

The enrichment adds:
  For infield/compilation videos:
    - Per-approach: technique detection, topic extraction, turn phases, hook/investment
    - Per-commentary-block: teaching points, techniques/topics discussed
    - unlisted_concepts: taxonomy gap detection on all enrichments

  For talking_head/podcast videos:
    - Per-section: topic identification, techniques discussed, description
    - unlisted_concepts: taxonomy gap detection on all enrichments

Architecture:
  - Single Claude CLI call per VIDEO (not per interaction)
  - Two prompt variants: infield (approaches + commentary) vs talking_head (topic sections)
  - Taxonomy sent once, outputs JSON

Use:

  A) Test videos:
     ./scripts/training-data/07.content --test

  B) Single file:
     ./scripts/training-data/07.content --input data/test/06c.patched/video.conversations.json

  C) Batch from sources file:
     ./scripts/training-data/07.content --sources

Requirements:
  - Claude Code CLI installed and authenticated (claude command available)
"""

from __future__ import annotations

import argparse
import difflib
import hashlib
import json
import re
import shlex
import subprocess
import sys
import time
from dataclasses import dataclass, asdict, field
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple

from batch.manifest_parser import load_manifest, load_manifest_sources, manifest_filter_files


# ---------------------------
# Claude CLI Binary Paths (for VS Code extension and system installs)
# ---------------------------

CLAUDE_BINARY_PATHS = [
    "claude",
    Path.home() / ".vscode-server/extensions/anthropic.claude-code-2.1.17-linux-x64/resources/native-binary/claude",
    Path.home() / ".vscode/extensions/anthropic.claude-code-2.1.17-linux-x64/resources/native-binary/claude",
    "/usr/local/bin/claude",
]


# ---------------------------
# Technique and Topic Taxonomies (synced with STAGE_07_content.md)
# ---------------------------

# 31 techniques across 5 categories
TECHNIQUE_TAXONOMY = {
    # Openers (5)
    "direct_opener": "Explicitly stating attraction/interest upfront ('I think you're attractive')",
    "indirect_opener": "Starting conversation without revealing intent (asking for directions, opinion)",
    "situational_opener": "Opening based on something happening in the environment",
    "observation_opener": "Commenting on something specific about her (outfit, book, behavior)",
    "gambit": "Pre-planned opener or routine to spark conversation",

    # Attraction (9)
    "push_pull": "Giving a compliment then taking it away, or vice versa ('You seem cool... for a tourist')",
    "tease": "Playful mocking or joking at her expense in a fun way",
    "cold_read": "Making an assumption about her personality/life ('You look like a yoga teacher')",
    "role_play": "Creating imaginary scenarios together ('We'd make terrible dance partners')",
    "disqualification": "Playfully suggesting you two wouldn't work out",
    "DHV": "Demonstration of higher value through stories or behavior",
    "frame_control": "Maintaining your perspective/reality in the interaction",
    "takeaway": "Withdrawing attention or threatening to leave",
    "false_time_constraint": "Saying you need to leave soon to reduce pressure",

    # Connection (8)
    "qualification": "Asking what makes her special beyond looks ('What's your passion?')",
    "statement_of_intent": "Clearly expressing romantic/sexual interest",
    "grounding": "Sharing personal details to build trust and rapport",
    "storytelling": "Using engaging stories to convey personality",
    "vulnerability": "Sharing something genuine/personal to create connection",
    "callback_humor": "Referencing something mentioned earlier in conversation",
    "screening": "Asking questions to evaluate her as a potential partner",
    "appreciation": "Expressing genuine appreciation for something about her",

    # Compliance (1)
    "compliance": "Getting her to agree to small requests, building investment",

    # Closing (8)
    "number_close": "Asking for her phone number",
    "instagram_close": "Asking for her Instagram handle",
    "soft_close": "Suggesting future meeting without immediate commitment",
    "assumptive_close": "Acting as if she's already agreed ('So when are you free?')",
    "instant_date": "Suggesting to continue hanging out right now",
    "bounce": "Moving to a different location together",
    "time_bridge": "Setting up specific future plans",
    "logistics_check": "Asking about her schedule/availability",
}

# 22 topics across 5 categories
TOPIC_TAXONOMY = {
    # Personal (8)
    "name": "Her name or introductions",
    "origin": "Where she's from, nationality, hometown",
    "career": "Job, profession, what she does for work",
    "education": "Studies, university, school",
    "hobby": "Interests, activities, passions",
    "travel": "Trips, places visited, travel plans",
    "living_situation": "Where she lives, roommates, neighborhood",
    "ambitions": "Goals, dreams, future plans",

    # Appearance (1)
    "appearance": "General looks, attractiveness comments, style",

    # Personality (4)
    "personality": "Character traits, demeanor",
    "age": "How old she is, age-related topics",
    "behavior": "How she acts, mannerisms",
    "values": "What she cares about, beliefs",

    # Logistics (5)
    "plans": "What she's doing today, schedule",
    "contact": "Exchanging numbers, social media",
    "logistics": "Meeting up, availability, dating",
    "relationship": "Boyfriend, dating status",
    "duration": "How long she's in town, staying",

    # Context (4)
    "food_drinks": "Coffee, restaurants, bars",
    "location": "The current place, area, city",
    "humor": "Jokes, banter, playful exchanges",
    "flirting": "Romantic/sexual tension, attraction",
}

LOG_PREFIX = "[07.content]"

PROMPT_VERSION = "1.2.2"  # v1.2.2: Require technique evidence segments to be COACH turns
PIPELINE_VERSION = "07.content-v1.6"  # v1.6: Normalize technique evidence anchored to non-coach segments (best-effort shift)

# Failure budget
MAX_CONSECUTIVE_FAILURES = 3
MAX_FAILURE_RATE = 0.20

# Phase progression order (must go forward only)
PHASE_ORDER = ["open", "pre_hook", "post_hook", "close"]


# ---------------------------
# Validation
# ---------------------------

@dataclass
class ValidationResult:
    severity: str  # "error", "warning", "info"
    check: str
    message: str

    def to_dict(self) -> Dict[str, str]:
        return {"severity": self.severity, "check": self.check, "message": self.message}


def fuzzy_evidence_match(evidence: str, transcript_text: str, threshold: float = 0.7) -> bool:
    """Check if evidence string roughly appears in transcript.

    Uses SequenceMatcher to find the best matching substring.
    Returns True if a reasonable match is found.
    """
    if not evidence or not transcript_text:
        return True  # can't check, don't flag

    evidence_lower = evidence.lower().strip()
    transcript_lower = transcript_text.lower()

    # Exact substring match
    if evidence_lower in transcript_lower:
        return True

    # Try matching against sliding windows of similar length
    ev_len = len(evidence_lower)
    best_ratio = 0.0

    # Check chunks of similar size throughout the transcript
    step = max(1, ev_len // 4)
    for i in range(0, max(1, len(transcript_lower) - ev_len + 1), step):
        chunk = transcript_lower[i:i + ev_len + ev_len // 2]
        ratio = difflib.SequenceMatcher(None, evidence_lower, chunk).ratio()
        if ratio > best_ratio:
            best_ratio = ratio
        if best_ratio >= threshold:
            return True

    return best_ratio >= threshold


def normalize_enrichments(
    enrichments: List[Dict[str, Any]],
    seg_by_id: Optional[Dict[int, Dict[str, Any]]] = None,
    conversations: Optional[Dict[int, List[Dict[str, Any]]]] = None,
) -> List[str]:
    """Normalize known LLM drift patterns before validation.

    Keep this conservative: only coerce obviously-invalid combinations that
    otherwise block the pipeline, and prefer dropping derived fields over
    inventing missing structure.
    """
    repairs: List[str] = []
    valid_topics = set(TOPIC_TAXONOMY.keys())
    valid_techniques = set(TECHNIQUE_TAXONOMY.keys())
    topic_canon = {k.lower(): k for k in valid_topics}
    technique_canon = {k.lower(): k for k in valid_techniques}

    for i, e in enumerate(enrichments):
        if not isinstance(e, dict):
            repairs.append(f"enrichment {i}: non-dict entry ignored")
            continue

        # Ensure unlisted_concepts is present and writable
        unlisted = e.get("unlisted_concepts")
        if not isinstance(unlisted, dict):
            unlisted = {}
        unlisted_techniques = unlisted.get("techniques")
        if not isinstance(unlisted_techniques, list):
            unlisted_techniques = []
        unlisted_topics = unlisted.get("topics")
        if not isinstance(unlisted_topics, list):
            unlisted_topics = []
        unlisted["techniques"] = unlisted_techniques
        unlisted["topics"] = unlisted_topics
        e["unlisted_concepts"] = unlisted

        # Normalize topics_discussed: keep only taxonomy entries; auto-move invalid ones to unlisted_concepts.
        topics_discussed = e.get("topics_discussed")
        if topics_discussed is not None and not isinstance(topics_discussed, list):
            repairs.append(f"enrichment {i}: topics_discussed not a list -> []")
            topics_discussed = []
            e["topics_discussed"] = topics_discussed
        if isinstance(topics_discussed, list):
            normalized_topics: List[str] = []
            for t in topics_discussed:
                if not isinstance(t, str):
                    continue
                raw = t.strip()
                if not raw:
                    continue
                canon = topic_canon.get(raw.lower())
                if canon:
                    normalized_topics.append(canon)
                else:
                    unlisted_topics.append(
                        f"{raw}: auto-moved from topics_discussed (not in taxonomy)"
                    )
                    repairs.append(
                        f"enrichment {i}: invalid topic '{raw}' moved to unlisted_concepts"
                    )
            e["topics_discussed"] = normalized_topics

        def normalize_technique_list(field_name: str) -> None:
            items = e.get(field_name)
            if items is None:
                return
            if not isinstance(items, list):
                repairs.append(f"enrichment {i}: {field_name} not a list -> []")
                e[field_name] = []
                return

            kept: List[Dict[str, Any]] = []
            for item in items:
                if not isinstance(item, dict):
                    continue
                tech_name = item.get("technique")
                if not isinstance(tech_name, str) or not tech_name.strip():
                    kept.append(item)
                    continue

                raw = tech_name.strip()
                canon = technique_canon.get(raw.lower())
                if canon:
                    if raw != canon:
                        repairs.append(
                            f"enrichment {i}: normalized technique '{raw}' -> '{canon}'"
                        )
                        item["technique"] = canon
                    kept.append(item)
                    continue

                unlisted_techniques.append(
                    f"{raw}: auto-moved from {field_name} (not in taxonomy)"
                )
                repairs.append(
                    f"enrichment {i}: invalid technique '{raw}' moved to unlisted_concepts"
                )
                # Drop invalid technique entry

            e[field_name] = kept

        normalize_technique_list("techniques_used")
        normalize_technique_list("techniques_discussed")

        if e.get("type") != "approach":
            continue

        # If a technique cites a TARGET/OTHER segment, try shifting it to the nearest prior COACH segment
        # in the same conversation. This is a best-effort repair: keep the technique, but anchor evidence
        # to the coach's line when possible (better for RAG quoting and downstream segment-linking).
        if seg_by_id is not None and conversations is not None:
            conv_id = e.get("conversation_id")
            if isinstance(conv_id, int) and conv_id in conversations:
                conv_segs = [s for s in conversations.get(conv_id, []) if isinstance(s.get("id"), int)]
                conv_segs.sort(key=lambda s: s.get("id", 0))
                id_to_idx = {int(s["id"]): idx for idx, s in enumerate(conv_segs)}

                for tech in e.get("techniques_used", []) or []:
                    if not isinstance(tech, dict):
                        continue
                    seg_id = tech.get("segment")
                    if not isinstance(seg_id, int):
                        continue
                    seg = seg_by_id.get(seg_id) if seg_by_id else None
                    role = seg.get("speaker_role") if isinstance(seg, dict) else None
                    if role == "coach" or role is None:
                        continue
                    start_idx = id_to_idx.get(seg_id)
                    if start_idx is None:
                        continue

                    # Walk backwards to find a coach turn.
                    new_seg_id: Optional[int] = None
                    for j in range(start_idx - 1, -1, -1):
                        cand = conv_segs[j]
                        cand_id = cand.get("id")
                        cand_role = cand.get("speaker_role")
                        if isinstance(cand_id, int) and cand_role == "coach":
                            new_seg_id = cand_id
                            break

                    if new_seg_id is None:
                        continue

                    old_seg_id = seg_id
                    tech["segment"] = new_seg_id
                    # Prefer anchoring the example to the coach line we point at.
                    coach_text = (seg_by_id.get(new_seg_id, {}).get("text", "") if seg_by_id else "").strip()
                    if coach_text:
                        tech["example"] = coach_text

                    repairs.append(
                        f"conv {conv_id}: shifted technique '{tech.get('technique', '?')}' "
                        f"segment {old_seg_id} ({role}) -> {new_seg_id} (coach)"
                    )

        # Normalize empty-ish fields
        if e.get("hook_point") in ("", {}, []):
            e["hook_point"] = None
        if e.get("investment_level") in ("", {}, []):
            e["investment_level"] = None

        turn_phases = e.get("turn_phases")
        if turn_phases is None:
            e["turn_phases"] = []
            turn_phases = e["turn_phases"]
        elif not isinstance(turn_phases, list):
            repairs.append(
                f"conv {e.get('conversation_id', '?')}: turn_phases not a list -> []"
            )
            e["turn_phases"] = []
            turn_phases = e["turn_phases"]

        phases_present = {
            tp.get("phase")
            for tp in turn_phases
            if isinstance(tp, dict) and tp.get("phase")
        }

        # hook_point + investment_level are only meaningful if post_hook is reached.
        if "post_hook" not in phases_present:
            cleared = False
            if e.get("hook_point") is not None:
                e["hook_point"] = None
                cleared = True
            if e.get("investment_level") is not None:
                e["investment_level"] = None
                cleared = True
            if cleared:
                repairs.append(
                    f"conv {e.get('conversation_id', '?')}: cleared hook_point/investment_level (no post_hook phase)"
                )
            continue

        # Enforce investment_level vocabulary when post_hook exists.
        inv = e.get("investment_level")
        if inv not in (None, "low", "medium", "high"):
            repairs.append(
                f"conv {e.get('conversation_id', '?')}: invalid investment_level {inv!r} -> null"
            )
            e["investment_level"] = None

    return repairs


def validate_enrichment_output(
    output: Dict,
    stage06_data: Optional[Dict] = None,
) -> List[ValidationResult]:
    """Comprehensive validation of Stage 07 output.

    Args:
        output: The Stage 07 enriched output
        stage06_data: Optional Stage 06 output for cross-reference checks
    """
    results: List[ValidationResult] = []

    enrichments = output.get("enrichments", [])

    # Build full transcript text for evidence checking
    segments = output.get("segments", [])
    full_transcript = " ".join(s.get("text", "") for s in segments)
    seg_by_id = {
        s.get("id"): s
        for s in segments
        if isinstance(s, dict) and isinstance(s.get("id"), int)
    }

    # --- 1. Technique taxonomy enforcement ---
    valid_techniques = set(TECHNIQUE_TAXONOMY.keys())
    for i, enrichment in enumerate(enrichments):
        for tech in enrichment.get("techniques_used", []):
            technique_name = tech.get("technique", "")
            if technique_name and technique_name not in valid_techniques:
                results.append(ValidationResult(
                    "error", "invalid_technique",
                    f"Enrichment {i}: technique '{technique_name}' not in taxonomy. "
                    f"Should be in unlisted_concepts instead."
                ))
        for tech in enrichment.get("techniques_discussed", []):
            technique_name = tech.get("technique", "")
            if technique_name and technique_name not in valid_techniques:
                results.append(ValidationResult(
                    "error", "invalid_technique_discussed",
                    f"Enrichment {i}: discussed technique '{technique_name}' not in taxonomy."
                ))

    # --- 2. Topic taxonomy enforcement ---
    valid_topics = set(TOPIC_TAXONOMY.keys())
    for i, enrichment in enumerate(enrichments):
        for topic in enrichment.get("topics_discussed", []):
            topic_name = topic if isinstance(topic, str) else ""
            if topic_name and topic_name not in valid_topics:
                results.append(ValidationResult(
                    "error", "invalid_topic",
                    f"Enrichment {i}: topic '{topic_name}' not in taxonomy."
                ))

    # --- 3. Evidence string verification ---
    if full_transcript:
        evidence_mismatches = 0
        evidence_total = 0
        empty_evidence = 0
        for i, enrichment in enumerate(enrichments):
            for tech in enrichment.get("techniques_used", []):
                example = tech.get("example", "")
                if example:
                    evidence_total += 1
                    if not fuzzy_evidence_match(example, full_transcript):
                        evidence_mismatches += 1
                        results.append(ValidationResult(
                            "warning", "evidence_mismatch",
                            f"Enrichment {i}: technique '{tech.get('technique', '?')}' "
                            f"evidence not found in transcript: \"{example[:80]}...\""
                        ))
                else:
                    empty_evidence += 1

        if empty_evidence > 0:
            results.append(ValidationResult(
                "warning", "empty_evidence",
                f"{empty_evidence} technique(s) have no example/evidence string"
            ))

        if evidence_total > 0:
            mismatch_rate = evidence_mismatches / evidence_total
            if mismatch_rate > 0.3:
                results.append(ValidationResult(
                    "error", "high_evidence_mismatch_rate",
                    f"{evidence_mismatches}/{evidence_total} ({mismatch_rate:.0%}) evidence strings "
                    f"don't match transcript (threshold: 30%)"
                ))
            elif mismatch_rate > 0.1:
                results.append(ValidationResult(
                    "warning", "elevated_evidence_mismatch_rate",
                    f"{evidence_mismatches}/{evidence_total} ({mismatch_rate:.0%}) evidence strings "
                    f"don't match transcript"
                ))

    # --- 3b. Technique evidence should anchor to coach turns ---
    for i, enrichment in enumerate(enrichments):
        if enrichment.get("type") != "approach":
            continue
        for tech in enrichment.get("techniques_used", []) or []:
            if not isinstance(tech, dict):
                continue
            seg_id = tech.get("segment")
            if not isinstance(seg_id, int):
                continue
            seg = seg_by_id.get(seg_id)
            if not seg:
                continue
            role = seg.get("speaker_role")
            if role and role != "coach":
                results.append(ValidationResult(
                    "warning", "technique_on_non_coach_segment",
                    f"Enrichment {i} (conv {enrichment.get('conversation_id', '?')}): "
                    f"technique '{tech.get('technique', '?')}' cites seg {seg_id} spoken by '{role}'"
                ))

    # --- 4. Turn phase progression ---
    for i, enrichment in enumerate(enrichments):
        if enrichment.get("type") != "approach":
            continue
        turn_phases = enrichment.get("turn_phases", [])
        if not turn_phases:
            continue

        last_phase_idx = -1
        for tp in turn_phases:
            phase = tp.get("phase", "")
            if phase in PHASE_ORDER:
                phase_idx = PHASE_ORDER.index(phase)
                if phase_idx < last_phase_idx:
                    results.append(ValidationResult(
                        "error", "phase_regression",
                        f"Enrichment {i} (conv {enrichment.get('conversation_id', '?')}): "
                        f"phase goes backward: '{PHASE_ORDER[last_phase_idx]}' → '{phase}'"
                    ))
                    break
                last_phase_idx = phase_idx

    # --- 5. Cross-reference with upstream data ---
    # Derive conversation IDs from segments (not stale conversations array)
    # This handles 06c boundary fixes (merges/splits) correctly
    if stage06_data:
        upstream_segments = stage06_data.get("segments", [])
        # Build conv_ids from actual segment data (ground truth after 06c patches)
        segment_conv_ids = {
            s.get("conversation_id") for s in upstream_segments
            if s.get("conversation_id", 0) > 0
        }

        for i, enrichment in enumerate(enrichments):
            conv_id = enrichment.get("conversation_id")
            if conv_id is not None and conv_id > 0 and conv_id not in segment_conv_ids:
                results.append(ValidationResult(
                    "error", "phantom_conversation",
                    f"Enrichment {i}: conversation_id {conv_id} does not exist in segment data"
                ))

        # Enrichment count vs actual conversation count from segments
        approach_enrichments = [e for e in enrichments if e.get("type") == "approach"]
        if len(approach_enrichments) != len(segment_conv_ids):
            results.append(ValidationResult(
                "warning", "enrichment_count_mismatch",
                f"Stage 07 has {len(approach_enrichments)} approach enrichments but "
                f"segment data has {len(segment_conv_ids)} conversations"
            ))

    # --- 6. Hook point / investment consistency ---
    for i, enrichment in enumerate(enrichments):
        if enrichment.get("type") != "approach":
            continue

        phases_present = {tp.get("phase") for tp in enrichment.get("turn_phases", [])}

        if enrichment.get("hook_point") and "post_hook" not in phases_present:
            results.append(ValidationResult(
                "error", "hook_without_post_hook",
                f"Enrichment {i} (conv {enrichment.get('conversation_id', '?')}): "
                f"hook_point is set but post_hook phase not found in turn_phases"
            ))

        if enrichment.get("investment_level") and "post_hook" not in phases_present:
            results.append(ValidationResult(
                "error", "investment_without_post_hook",
                f"Enrichment {i} (conv {enrichment.get('conversation_id', '?')}): "
                f"investment_level is set but post_hook phase not found in turn_phases"
            ))

    # --- 7. Transcript artifact reporting ---
    artifacts = output.get("transcript_artifacts", [])
    if artifacts:
        for artifact in artifacts:
            results.append(ValidationResult(
                "warning", "transcript_artifact",
                f"Seg {artifact.get('segment_index', '?')}: "
                f"{artifact.get('artifact_type', '?')} — "
                f"{artifact.get('description', 'no description')}"
            ))

    # --- Summary ---
    if not any(r.severity == "error" for r in results):
        results.append(ValidationResult("info", "validation_passed", "All checks passed"))

    return results


def write_validation_results(
    results: List[ValidationResult], output_path: Path, video_id: str
) -> None:
    """Write validation results to a .validation.json file alongside the output."""
    validation_output = {
        "video_id": video_id,
        "validated_at": time.strftime("%Y-%m-%dT%H:%M:%SZ"),
        "pipeline_version": PIPELINE_VERSION,
        "prompt_version": PROMPT_VERSION,
        "summary": {
            "errors": sum(1 for r in results if r.severity == "error"),
            "warnings": sum(1 for r in results if r.severity == "warning"),
            "info": sum(1 for r in results if r.severity == "info"),
            "passed": all(r.severity != "error" for r in results),
        },
        "results": [r.to_dict() for r in results],
    }

    validation_path = output_path.with_suffix(".validation.json")
    validation_path.parent.mkdir(parents=True, exist_ok=True)
    with validation_path.open("w", encoding="utf-8") as f:
        json.dump(validation_output, f, indent=2, ensure_ascii=False)

    errors = validation_output["summary"]["errors"]
    warnings = validation_output["summary"]["warnings"]
    if errors > 0:
        print(f"{LOG_PREFIX} VALIDATION FAILED: {errors} error(s), {warnings} warning(s)")
        for r in results:
            if r.severity == "error":
                print(f"{LOG_PREFIX}   ERROR: [{r.check}] {r.message}")
    elif warnings > 0:
        print(f"{LOG_PREFIX} VALIDATION PASSED with {warnings} warning(s)")
        for r in results:
            if r.severity == "warning":
                print(f"{LOG_PREFIX}   WARN: [{r.check}] {r.message}")
    else:
        print(f"{LOG_PREFIX} VALIDATION PASSED (clean)")


@dataclass
class ConversationEnrichment:
    conversation_id: int
    type: str  # "approach" or "commentary"
    description: str
    techniques_used: List[Dict[str, Any]]
    topics_discussed: List[str]
    turn_phases: List[Dict[str, Any]]
    hook_point: Optional[Dict[str, str]]  # {"signal": "..."} or None
    investment_level: Optional[str]  # "low"/"medium"/"high" or None if no post_hook


@dataclass
class ProcessingState:
    version: int
    completed_files: List[str]
    in_progress: Optional[str]
    failures: List[Dict[str, str]]


def load_state(state_path: Path) -> ProcessingState:
    """Load processing state from file."""
    if state_path.exists():
        try:
            data = json.loads(state_path.read_text())
            return ProcessingState(
                version=data.get("version", 1),
                completed_files=data.get("completed_files", []),
                in_progress=data.get("in_progress"),
                failures=data.get("failures", []),
            )
        except (json.JSONDecodeError, KeyError):
            pass
    return ProcessingState(version=1, completed_files=[], in_progress=None, failures=[])


def save_state(state_path: Path, state: ProcessingState) -> None:
    """Save processing state to file."""
    state_path.parent.mkdir(parents=True, exist_ok=True)
    state_path.write_text(json.dumps(asdict(state), indent=2))


def find_claude_binary() -> Optional[str]:
    """Find Claude CLI binary in known locations."""
    for path in CLAUDE_BINARY_PATHS:
        path = Path(path)
        if path.exists() and path.is_file():
            return str(path)
        if str(path) == "claude":
            try:
                result = subprocess.run(["which", "claude"], capture_output=True, text=True)
                if result.returncode == 0:
                    return "claude"
            except Exception:
                pass
    return None


def call_claude(prompt: str, retries: int = 3, timeout: int = 600) -> Optional[str]:
    """Call Claude Code CLI with retry logic."""
    claude_bin = find_claude_binary()
    if not claude_bin:
        print(f"{LOG_PREFIX} Error: Claude CLI binary not found")
        print(f"{LOG_PREFIX} Searched: {[str(p) for p in CLAUDE_BINARY_PATHS]}")
        return None

    for attempt in range(retries):
        try:
            result = subprocess.run(
                [claude_bin, "-p", prompt, "--output-format", "text"],
                capture_output=True,
                text=True,
                timeout=timeout
            )
            if result.returncode == 0:
                return result.stdout.strip()
            else:
                if attempt < retries - 1:
                    wait = 2 ** attempt
                    print(f"{LOG_PREFIX} Claude CLI error, retrying in {wait}s...")
                    time.sleep(wait)
                    continue
                print(f"{LOG_PREFIX} Claude CLI error: {result.stderr[:200]}")
        except subprocess.TimeoutExpired:
            if attempt < retries - 1:
                print(f"{LOG_PREFIX} Timeout, retrying...")
                time.sleep(2 ** attempt)
                continue
            print(f"{LOG_PREFIX} Claude CLI timeout after {timeout}s")
        except FileNotFoundError:
            print(f"{LOG_PREFIX} Error: 'claude' command not found. Install Claude Code CLI.")
            return None
    return None


def group_segments_by_conversation(segments: List[Dict]) -> Dict[int, List[Dict]]:
    """Group segments by conversation_id."""
    conversations: Dict[int, List[Dict]] = {}
    for seg in segments:
        conv_id = seg.get("conversation_id", 0)
        if conv_id not in conversations:
            conversations[conv_id] = []
        conversations[conv_id].append(seg)
    return conversations


def get_video_type_str(data: Dict) -> str:
    """Extract video type string from stage 06 output."""
    vt = data.get("video_type", {})
    if isinstance(vt, dict):
        return vt.get("type", "compilation")
    if isinstance(vt, str):
        return vt
    return "compilation"


def group_commentary_blocks(segments: List[Dict]) -> List[Dict]:
    """Group consecutive commentary segments (conversation_id=0) into blocks."""
    blocks: List[Dict] = []
    current_segs: List[Dict] = []

    for seg in segments:
        if seg.get("conversation_id", 0) == 0:
            current_segs.append(seg)
        else:
            if current_segs:
                blocks.append({
                    "segments": current_segs,
                    "start": current_segs[0].get("start", 0),
                    "end": current_segs[-1].get("end", 0),
                })
                current_segs = []

    if current_segs:
        blocks.append({
            "segments": current_segs,
            "start": current_segs[0].get("start", 0),
            "end": current_segs[-1].get("end", 0),
        })

    return blocks


def remap_enrichment_segment_indices(
    enrichments: List[Dict],
    conversations: Dict[int, List[Dict]],
) -> None:
    """Convert relative segment indices in enrichments to global segment IDs.

    The prompt sent to Claude uses relative indices [0], [1], [2]... for each
    conversation (cleaner for the LLM to read). But the segments in the output
    JSON use global IDs. This function remaps the enrichment references to match.

    Modifies enrichments in place.
    """
    for enrichment in enrichments:
        if enrichment.get("type") != "approach":
            continue

        conv_id = enrichment.get("conversation_id")
        if conv_id is None or conv_id not in conversations:
            continue

        conv_segments = conversations[conv_id]

        # Build mapping: relative index -> global segment ID
        rel_to_global = {i: seg["id"] for i, seg in enumerate(conv_segments)}

        # Remap techniques_used[].segment
        for tech in enrichment.get("techniques_used", []):
            rel_idx = tech.get("segment")
            if rel_idx is not None and rel_idx in rel_to_global:
                tech["segment"] = rel_to_global[rel_idx]

        # Remap turn_phases[].segment
        for phase in enrichment.get("turn_phases", []):
            rel_idx = phase.get("segment")
            if rel_idx is not None and rel_idx in rel_to_global:
                phase["segment"] = rel_to_global[rel_idx]


def compute_phase_confidence(
    enrichment: Dict,
    conversations: Dict[int, List[Dict]],
    low_quality_segments: List[Dict],
    speaker_labels: Dict[str, Dict],
) -> Dict[str, float]:
    """Compute confidence score for each phase in a conversation.

    Confidence is based on:
    - Proportion of segments with good transcription quality
    - Speaker diarization issues (collapsed/unknown speakers)

    Returns dict mapping phase name to confidence score (0.0-1.0).
    """
    if enrichment.get("type") != "approach":
        return {}

    conv_id = enrichment.get("conversation_id")
    if conv_id is None or conv_id not in conversations:
        return {}

    conv_segments = conversations[conv_id]
    turn_phases = enrichment.get("turn_phases", [])

    if not turn_phases:
        return {}

    # Build set of low-quality segment IDs for fast lookup
    low_quality_ids = {lq.get("segment") for lq in low_quality_segments}

    # Group segments by phase
    # turn_phases has {"segment": global_id, "phase": "open"|"pre_hook"|...}
    phase_segments: Dict[str, List[Dict]] = {}
    segment_to_phase: Dict[int, str] = {}

    for tp in turn_phases:
        seg_id = tp.get("segment")
        phase = tp.get("phase")
        if seg_id is not None and phase:
            segment_to_phase[seg_id] = phase

    # Map segments to their phases
    for seg in conv_segments:
        seg_id = seg.get("id")
        phase = segment_to_phase.get(seg_id)
        if phase:
            if phase not in phase_segments:
                phase_segments[phase] = []
            phase_segments[phase].append(seg)

    # Compute confidence for each phase
    phase_confidence: Dict[str, float] = {}

    for phase, segments in phase_segments.items():
        if not segments:
            continue

        total = len(segments)
        low_quality_count = 0
        speaker_issue_count = 0

        for seg in segments:
            seg_id = seg.get("id")

            # Check if segment is flagged as low quality
            if seg_id in low_quality_ids:
                low_quality_count += 1

            # Check speaker issues
            speaker_role = (seg.get("speaker_role") or "").lower()
            speaker_id = seg.get("speaker_id")

            if speaker_role in ("collapsed", "unknown", "mixed/unclear"):
                speaker_issue_count += 1
            elif speaker_id and speaker_id in speaker_labels:
                speaker_conf = speaker_labels[speaker_id].get("confidence", 1.0)
                if speaker_conf < 0.5:
                    speaker_issue_count += 1

        # Calculate confidence
        # Base: proportion of good segments
        good_segments = total - low_quality_count
        transcript_factor = good_segments / total if total > 0 else 1.0

        # Speaker factor: proportion without issues
        clean_speakers = total - speaker_issue_count
        speaker_factor = clean_speakers / total if total > 0 else 1.0

        # Collapsed speaker is a bigger penalty
        has_collapsed = any(
            (seg.get("speaker_role") or "").lower() == "collapsed"
            for seg in segments
        )
        collapsed_penalty = 0.85 if has_collapsed else 1.0

        # Combined confidence
        confidence = transcript_factor * (0.7 + 0.3 * speaker_factor) * collapsed_penalty

        # Clamp to [0.1, 1.0]
        phase_confidence[phase] = round(max(0.1, min(1.0, confidence)), 2)

    return phase_confidence


def add_phase_confidence_to_enrichments(
    enrichments: List[Dict],
    conversations: Dict[int, List[Dict]],
    low_quality_segments: List[Dict],
    speaker_labels: Dict[str, Dict],
) -> None:
    """Add phase_confidence field to each approach enrichment. Modifies in place."""
    for enrichment in enrichments:
        if enrichment.get("type") != "approach":
            continue

        phase_conf = compute_phase_confidence(
            enrichment, conversations, low_quality_segments, speaker_labels
        )
        if phase_conf:
            enrichment["phase_confidence"] = phase_conf


def build_infield_prompt(
    conversations: Dict[int, List[Dict]],
    commentary_blocks: List[Dict],
    video_id: str,
) -> str:
    """Build prompt for infield/compilation videos: approaches + interleaved commentary."""

    technique_list = "\n".join([f"  - {k}: {v}" for k, v in TECHNIQUE_TAXONOMY.items()])
    topic_list = ", ".join(TOPIC_TAXONOMY.keys())

    # Build chronological content blocks
    content_items: List[Dict[str, Any]] = []

    # Add commentary blocks
    for i, block in enumerate(commentary_blocks):
        segs = block["segments"]
        turns = []
        for j, seg in enumerate(segs):
            seg_id = seg.get("id", j)
            speaker = seg.get("speaker_role", seg.get("speaker_id", "unknown"))
            text = seg.get("text", "").strip()
            if text:
                turns.append(f"  [{j}] (seg_id={seg_id}) {speaker.upper()}: {text}")

        if turns:
            content_items.append({
                "sort_key": block["start"],
                "text": f"""COMMENTARY BLOCK #{i + 1}
Start: {block['start']:.1f}s
End: {block['end']:.1f}s

{chr(10).join(turns)}"""
            })

    # Add approach conversations
    for conv_id in sorted(conversations.keys()):
        if conv_id == 0:
            continue

        segments = conversations[conv_id]
        turns = []
        for i, seg in enumerate(segments):
            seg_id = seg.get("id", i)
            speaker = seg.get("speaker_role", seg.get("speaker_id", "unknown"))
            text = seg.get("text", "").strip()
            turns.append(f"  [{i}] (seg_id={seg_id}) {speaker.upper()}: {text}")

        content_items.append({
            "sort_key": segments[0].get("start", 0),
            "text": f"""APPROACH CONVERSATION #{conv_id}
Segments: {len(segments)}
Start: {segments[0].get('start', 0):.1f}s
End: {segments[-1].get('end', 0):.1f}s

{chr(10).join(turns)}"""
        })

    # Sort by start time for chronological order
    content_items.sort(key=lambda x: x["sort_key"])
    all_content = "\n---\n".join(item["text"] for item in content_items)

    approach_count = len([c for c in conversations if c > 0])

    prompt = f"""You are an expert daygame analyst. Analyze ALL content in this infield coaching video.

VIDEO: {video_id}
VIDEO TYPE: infield
APPROACH CONVERSATIONS: {approach_count}
COMMENTARY BLOCKS: {len(commentary_blocks)}

TECHNIQUE REFERENCE (31 techniques):
{technique_list}

TOPIC REFERENCE: {topic_list}

CONTENT TO ANALYZE (chronological order):
{all_content}

=== ANALYSIS INSTRUCTIONS ===

FOR EACH APPROACH CONVERSATION (type: "approach"), analyze:

1. TYPE: "approach"
2. CONVERSATION_ID: The conversation number
3. DESCRIPTION: Concise 10-20 word summary
4. TECHNIQUES USED: List techniques demonstrated with segment index and brief example quote.
   CRITICAL: Only use technique names from the TECHNIQUE REFERENCE above.
   If you observe a technique not in the list, do NOT include it here — add it to UNLISTED CONCEPTS instead.
   IMPORTANT: The segment index you cite for a technique MUST refer to a COACH turn (not TARGET/OTHER).
   If the quote you want to use is spoken by TARGET/OTHER, do NOT cite it as technique evidence; instead cite the
   COACH segment that is doing the technique (or omit the technique if you can't anchor it to a COACH turn).
5. TOPICS: List topics discussed from the TOPIC REFERENCE list only.
   CRITICAL: Only use topic names from the TOPIC REFERENCE above.
   If you observe a topic not in the list, do NOT include it here — add it to UNLISTED CONCEPTS instead.
6. TURN PHASES: Label each turn with its interaction phase.
   Phases (in order of progression):
   - "open": The approach. Coach introducing himself and the interaction.
     Can be multiple turns if he's stacking assumptions or extending his opening bit.
     Her responses (if any) are pure acknowledgment.
   - "pre_hook": Coach building attraction. Still doing most of the talking,
     running game — teasing, cold reading, push-pull, being entertaining.
     She's still mostly passive.
   - "post_hook": She's flipped. Actively participating — asking questions back,
     sharing information voluntarily, initiating topics, longer responses.
   - "close": Logistics and closing — number, Instagram, instant date, time bridge.
     IMPORTANT: Once the coach initiates close logistics (asks for number, mentions Instagram,
     proposes plans), ALL remaining segments are "close" phase — even if banter/teasing continues.
     The close phase often includes continued rapport-building alongside logistics discussion.
     Don't flip back to post_hook just because there's playful banter after he's started closing.
   Rules:
   - Phases always progress forward: open -> pre_hook -> post_hook -> close
   - A turn's phase must NEVER go backwards
   - Once close begins, it continues until the end (no regression to earlier phases)
   - Not all phases are required (e.g. blowout = open only, instant hook = open -> post_hook)
   - Use the segment index [0], [1], etc. to identify each turn
7. HOOK POINT: If post_hook is reached, describe the moment she flipped.
   Provide a brief "signal".
   IMPORTANT: If you set hook_point or investment_level, you MUST label at least one turn as "post_hook" in TURN PHASES.
   If no post_hook phase is present, set hook_point to null and investment_level to null.
   If no hook point, set to null.
8. INVESTMENT LEVEL: "low"/"medium"/"high" if post_hook reached, else null.
   - "low": Barely crossed — asked one polite question back, still mostly reactive
   - "medium": Engaged, asking questions, responsive, but he's still somewhat leading
   - "high": Fully in — initiating topics, sharing unprompted, her turns match or exceed his
9. UNLISTED CONCEPTS: Techniques or topics you observe that don't fit the taxonomy.
   Format: {{"techniques": ["name: description"], "topics": ["name: description"]}}
   Empty arrays if all concepts fit.

FOR EACH COMMENTARY BLOCK (type: "commentary"), analyze:

1. TYPE: "commentary"
2. BLOCK INDEX: Sequential starting at 1
3. DESCRIPTION: 10-20 word summary of what the coach is teaching/explaining
4. TECHNIQUES DISCUSSED: Techniques from TECHNIQUE REFERENCE only. Put unlisted ones in UNLISTED CONCEPTS.
5. TOPICS DISCUSSED: Topics from TOPIC REFERENCE only. Put unlisted ones in UNLISTED CONCEPTS.
6. UNLISTED CONCEPTS: Same format as above

TRANSCRIPT QUALITY ASSESSMENT:
Evaluate the transcription quality of each segment. Flag segments where the ASR (Whisper)
appears to have produced inaccurate or garbage output. Look for:
- Text that doesn't make sense in the conversational context
- Apparent mishearings or hallucinations (words that seem wrong for what was likely said)
- Garbled or nonsensical phrases
- Language confusion (random foreign words that don't fit)
- Multiple sentences incorrectly merged without punctuation

Do NOT flag:
- Natural speech patterns (fillers like "um", "like", short responses like "yeah")
- Run-on sentences that still make sense (fast speech accurately transcribed)
- Foreign words/names that fit the context

Output a "low_quality_segments" array listing segments with poor transcription:
{{"segment": SEG_ID, "reason": "brief explanation of what seems wrong"}}
IMPORTANT: SEG_ID must be the global segment id shown as (seg_id=...) in the transcript lines,
NOT the per-conversation [0], [1], ... turn index.

Also flag specific artifact types with "transcript_artifact" entries:
{{"type": "transcript_artifact", "segment_index": SEG_ID, "artifact_type": "word_repetition"|"nonsense"|"language_confusion", "description": "brief explanation"}}
IMPORTANT: segment_index is also the global seg_id (despite the name).

Return empty arrays if transcript quality is good.

OUTPUT FORMAT: Return a JSON object with this structure:
{{
  "enrichments": [...],  // array of approach/commentary enrichments
  "low_quality_segments": [...],  // segments with poor transcription
  "transcript_artifacts": [...]  // specific artifact entries
}}

The enrichments array should contain one object for each approach conversation
AND each commentary block, in chronological order. Include any transcript_artifact entries
at the end of the array. Output ONLY valid JSON.

EXAMPLE:
{{
  "enrichments": [
    {{
      "type": "commentary",
      "block_index": 1,
      "description": "Coach introduces the session and explains his approach style",
      "techniques_discussed": [{{"technique": "direct_opener", "example": "I always open direct"}}],
      "topics_discussed": ["personality"],
      "unlisted_concepts": {{"techniques": [], "topics": []}}
    }},
    {{
      "conversation_id": 1,
      "type": "approach",
      "description": "Direct opener on tourist, builds attraction with cold reads, number close",
      "techniques_used": [
        {{"technique": "direct_opener", "segment": 0, "example": "Hey, I saw you and had to say hi"}},
        {{"technique": "cold_read", "segment": 3, "example": "You look like you do yoga"}}
      ],
      "topics_discussed": ["origin", "career", "travel"],
      "turn_phases": [
        {{"segment": 0, "phase": "open"}},
        {{"segment": 1, "phase": "open"}},
        {{"segment": 2, "phase": "pre_hook"}},
        {{"segment": 3, "phase": "pre_hook"}},
        {{"segment": 4, "phase": "post_hook"}},
        {{"segment": 5, "phase": "close"}}
      ],
      "hook_point": {{"signal": "she asked where he's from unprompted"}},
      "investment_level": "medium",
      "unlisted_concepts": {{"techniques": [], "topics": []}}
    }},
    {{
      "type": "commentary",
      "block_index": 2,
      "description": "Coach breaks down the previous approach, highlights the cold read",
      "techniques_discussed": [{{"technique": "cold_read", "example": "When I said you look like a yoga teacher..."}}],
      "topics_discussed": ["behavior"],
      "unlisted_concepts": {{"techniques": [], "topics": []}}
    }}
  ],
  "low_quality_segments": [
    {{"segment": 7, "reason": "Apparent mishearing - 'ranch me mulatto' doesn't fit context"}}
  ],
  "transcript_artifacts": []
}}

YOUR JSON RESPONSE:"""

    return prompt


def build_talking_head_prompt(segments: List[Dict], video_id: str) -> str:
    """Build prompt for talking_head/podcast videos: identify topic sections."""

    technique_list = "\n".join([f"  - {k}: {v}" for k, v in TECHNIQUE_TAXONOMY.items()])
    topic_list = ", ".join(TOPIC_TAXONOMY.keys())

    # Format full transcript
    turns = []
    for i, seg in enumerate(segments):
        seg_id = seg.get("id", i)
        speaker = seg.get("speaker_role", seg.get("speaker_id", "unknown"))
        text = seg.get("text", "").strip()
        if text:
            turns.append(f"  [{seg_id}] {speaker.upper()}: {text}")

    transcript = chr(10).join(turns)

    prompt = f"""You are an expert daygame analyst. Analyze this coaching explanation video and identify distinct topic sections.

VIDEO: {video_id}
VIDEO TYPE: talking_head
TOTAL SEGMENTS: {len(segments)}

TECHNIQUE REFERENCE (31 techniques):
{technique_list}

TOPIC REFERENCE: {topic_list}

FULL TRANSCRIPT:
{transcript}

TASK: This is a talking-head coaching video (no live approaches).
Identify distinct TOPIC SECTIONS. A new section starts when the coach transitions
to a new subject or teaching point.

FOR EACH SECTION, analyze:

1. SECTION INDEX: Sequential starting at 1
2. TYPE: "talking_head_section"
3. DESCRIPTION: Concise 10-20 word summary of what the coach is teaching
4. START SEGMENT: Global segment id (seg_id) of first segment in this section
5. END SEGMENT: Global segment id (seg_id) of last segment in this section
6. TECHNIQUES DISCUSSED: Techniques from TECHNIQUE REFERENCE only.
   CRITICAL: Only use technique names from the list above.
   If a technique is discussed but not in the list, do NOT include it here — add to UNLISTED CONCEPTS.
7. TOPICS DISCUSSED: Topics from TOPIC REFERENCE only.
   CRITICAL: Only use topic names from the list above.
   If a topic is discussed but not in the list, do NOT include it here — add to UNLISTED CONCEPTS.
8. UNLISTED CONCEPTS: Report any technique or topic that doesn't fit the taxonomy.
   Format: {{"techniques": ["concept_name: brief description"], "topics": ["concept_name: brief description"]}}
   Return empty arrays if all concepts fit.

TRANSCRIPT QUALITY ASSESSMENT:
Evaluate the transcription quality of each segment. Flag segments where the ASR (Whisper)
appears to have produced inaccurate or garbage output. Look for:
- Text that doesn't make sense in the conversational context
- Apparent mishearings or hallucinations (words that seem wrong for what was likely said)
- Garbled or nonsensical phrases
- Language confusion (random foreign words that don't fit)
- Multiple sentences incorrectly merged without punctuation

Do NOT flag:
- Natural speech patterns (fillers like "um", "like", short responses like "yeah")
- Run-on sentences that still make sense (fast speech accurately transcribed)
- Foreign words/names that fit the context

Output a "low_quality_segments" array listing segments with poor transcription:
{{"segment": SEG_ID, "reason": "brief explanation of what seems wrong"}}
IMPORTANT: SEG_ID must match the global segment id shown in the transcript lines.

Also flag specific artifact types with "transcript_artifact" entries:
{{"type": "transcript_artifact", "segment_index": SEG_ID, "artifact_type": "word_repetition"|"nonsense"|"language_confusion", "description": "brief explanation"}}
IMPORTANT: segment_index is the global seg_id (despite the name).

Return empty arrays if transcript quality is good.

OUTPUT FORMAT: Return a JSON object with this structure:
{{
  "enrichments": [...],  // array of section enrichments
  "low_quality_segments": [...],  // segments with poor transcription
  "transcript_artifacts": [...]  // specific artifact entries
}}

Output ONLY valid JSON, no explanation text.

EXAMPLE:
{{
  "enrichments": [
    {{
      "section_index": 1,
      "type": "talking_head_section",
      "description": "Introduction to direct game and why it works on the street",
      "start_segment": 0,
      "end_segment": 12,
      "techniques_discussed": [
        {{"technique": "direct_opener", "example": "You walk up and say I think you're cute"}}
      ],
      "topics_discussed": ["personality", "behavior"],
      "unlisted_concepts": {{"techniques": [], "topics": []}}
    }},
    {{
      "section_index": 2,
      "type": "talking_head_section",
      "description": "How to transition from opener to building attraction",
      "start_segment": 13,
      "end_segment": 28,
      "techniques_discussed": [
        {{"technique": "cold_read", "example": "After the opener, throw out an assumption about her"}}
      ],
      "topics_discussed": ["hobby", "personality"],
      "unlisted_concepts": {{"techniques": ["assumption_stacking: Making multiple assumptions in rapid succession"], "topics": []}}
    }}
  ],
  "low_quality_segments": [],
  "transcript_artifacts": []
}}

YOUR JSON RESPONSE:"""

    return prompt


@dataclass
class ParsedEnrichmentResponse:
    """Parsed response from Claude enrichment call."""
    enrichments: List[Dict]
    low_quality_segments: List[Dict]
    transcript_artifacts: List[Dict]


def parse_enrichment_response(response: str) -> ParsedEnrichmentResponse:
    """Parse JSON response from LLM.

    Handles both new format (JSON object with enrichments/low_quality_segments/transcript_artifacts)
    and legacy format (JSON array of enrichments with transcript_artifact entries mixed in).
    """
    empty_result = ParsedEnrichmentResponse([], [], [])

    if not response:
        return empty_result

    try:
        # Try to find JSON object in code block
        code_block_obj_match = re.search(r"```(?:json)?\s*(\{[\s\S]*?\})\s*```", response)
        if code_block_obj_match:
            data = json.loads(code_block_obj_match.group(1))
            if isinstance(data, dict) and "enrichments" in data:
                return ParsedEnrichmentResponse(
                    enrichments=data.get("enrichments", []),
                    low_quality_segments=data.get("low_quality_segments", []),
                    transcript_artifacts=data.get("transcript_artifacts", []),
                )

        # Try to find JSON array in code block (legacy format)
        code_block_arr_match = re.search(r"```(?:json)?\s*(\[[\s\S]*?\])\s*```", response)
        if code_block_arr_match:
            arr = json.loads(code_block_arr_match.group(1))
            return _parse_legacy_array(arr)

        # Try to find raw JSON object
        obj_start = response.find("{")
        if obj_start != -1:
            brace_count = 0
            for i, char in enumerate(response[obj_start:], obj_start):
                if char == "{":
                    brace_count += 1
                elif char == "}":
                    brace_count -= 1
                    if brace_count == 0:
                        json_str = response[obj_start:i + 1]
                        data = json.loads(json_str)
                        if isinstance(data, dict) and "enrichments" in data:
                            return ParsedEnrichmentResponse(
                                enrichments=data.get("enrichments", []),
                                low_quality_segments=data.get("low_quality_segments", []),
                                transcript_artifacts=data.get("transcript_artifacts", []),
                            )
                        break

        # Try to find raw JSON array (legacy format)
        arr_start = response.find("[")
        if arr_start != -1:
            bracket_count = 0
            for i, char in enumerate(response[arr_start:], arr_start):
                if char == "[":
                    bracket_count += 1
                elif char == "]":
                    bracket_count -= 1
                    if bracket_count == 0:
                        json_str = response[arr_start:i + 1]
                        arr = json.loads(json_str)
                        return _parse_legacy_array(arr)

    except (json.JSONDecodeError, ValueError) as e:
        print(f"[07.content] JSON parse error: {e}")
        print(f"[07.content] Response preview: {response[:500]}...")

    return empty_result


def _parse_legacy_array(arr: List[Dict]) -> ParsedEnrichmentResponse:
    """Parse legacy format where transcript_artifacts are mixed in the array."""
    transcript_artifacts = [e for e in arr if e.get("type") == "transcript_artifact"]
    enrichments = [e for e in arr if e.get("type") != "transcript_artifact"]
    return ParsedEnrichmentResponse(
        enrichments=enrichments,
        low_quality_segments=[],
        transcript_artifacts=transcript_artifacts,
    )


def process_video_file(input_path: Path, output_path: Path, dry_run: bool = False) -> Dict[str, Any]:
    """Process a single video's conversations.json file."""

    print(f"[07.content] Processing: {input_path.name}")

    # Load input
    with input_path.open("r", encoding="utf-8") as f:
        data = json.load(f)

    segments = data.get("segments", [])
    video_id = data.get("video_id", input_path.stem)
    video_type = get_video_type_str(data)

    if not segments:
        print(f"[07.content] No segments found")
        return {"conversations": 0, "enriched": 0}

    # Group by conversation
    conversations = group_segments_by_conversation(segments)
    approach_convs = {k: v for k, v in conversations.items() if k > 0}
    commentary_blocks = group_commentary_blocks(segments)

    print(f"[07.content]   {len(segments)} segments, {len(approach_convs)} approaches, "
          f"{len(commentary_blocks)} commentary blocks, type={video_type}")

    if dry_run:
        print(f"[07.content]   [DRY RUN] Would call Claude CLI ({video_type} prompt)")
        return {"conversations": len(approach_convs), "enriched": 0}

    # Build prompt based on video type
    if video_type in ("infield", "compilation"):
        prompt = build_infield_prompt(conversations, commentary_blocks, video_id)
    else:
        prompt = build_talking_head_prompt(segments, video_id)

    print(f"[07.content]   Calling Claude CLI ({video_type} prompt)...")

    start_time = time.time()
    response = call_claude(prompt, timeout=600)
    elapsed = time.time() - start_time

    enrichments: List[Dict] = []
    transcript_artifacts: List[Dict] = []
    low_quality_segments: List[Dict] = []
    if response:
        parsed = parse_enrichment_response(response)
        enrichments = parsed.enrichments
        transcript_artifacts = parsed.transcript_artifacts
        low_quality_segments = parsed.low_quality_segments
        quality_msg = f", {len(low_quality_segments)} low-quality segs" if low_quality_segments else ""
        artifact_msg = f", {len(transcript_artifacts)} artifacts" if transcript_artifacts else ""
        print(f"[07.content]   Got {len(enrichments)} enrichments{quality_msg}{artifact_msg} in {elapsed:.1f}s")
    else:
        print(f"[07.content]   Claude call failed, using empty enrichments")

    # Categorize enrichments by type
    approach_enrichments = [e for e in enrichments if e.get("type") == "approach"]
    commentary_enrichments = [e for e in enrichments if e.get("type") == "commentary"]
    section_enrichments = [e for e in enrichments if e.get("type") == "talking_head_section"]

    # Remap relative segment indices to global IDs
    remap_enrichment_segment_indices(enrichments, conversations)

    # Compute phase confidence for each approach enrichment
    speaker_labels = data.get("speaker_labels", {})
    add_phase_confidence_to_enrichments(
        enrichments, conversations, low_quality_segments, speaker_labels
    )

    seg_by_id = {
        s.get("id"): s
        for s in segments
        if isinstance(s, dict) and isinstance(s.get("id"), int)
    }
    normalization_repairs = normalize_enrichments(enrichments, seg_by_id=seg_by_id, conversations=conversations)
    if normalization_repairs:
        preview = "; ".join(normalization_repairs[:3])
        suffix = "" if len(normalization_repairs) <= 3 else f" (+{len(normalization_repairs) - 3} more)"
        print(f"{LOG_PREFIX}   Normalized {len(normalization_repairs)} issue(s): {preview}{suffix}")

    # Collect unlisted concepts across all enrichments (post-normalization).
    all_unlisted_techniques: List[str] = []
    all_unlisted_topics: List[str] = []
    for e in enrichments:
        unlisted = e.get("unlisted_concepts", {})
        if isinstance(unlisted, dict):
            all_unlisted_techniques.extend(unlisted.get("techniques", []) or [])
            all_unlisted_topics.extend(unlisted.get("topics", []) or [])

    # Collect all techniques (from both techniques_used and techniques_discussed)
    all_techniques = set()
    for e in enrichments:
        for t in e.get("techniques_used", []):
            if t.get("technique"):
                all_techniques.add(t["technique"])
        for t in e.get("techniques_discussed", []):
            if t.get("technique"):
                all_techniques.add(t["technique"])

    # Collect all topics
    all_topics = set()
    for e in enrichments:
        for topic in e.get("topics_discussed", []):
            if isinstance(topic, str):
                all_topics.add(topic)

    # Extract upstream patch metadata (for RAG visibility into data quality)
    upstream_patch = data.get("patch_metadata", {})

    # Build output
    output: Dict[str, Any] = {
        "metadata": {
            "source_file": str(input_path),
            "processed_at": time.strftime("%Y-%m-%dT%H:%M:%SZ"),
            "video_type": video_type,
            "prompt_variant": "infield" if video_type in ("infield", "compilation") else "talking_head",
            "conversations_enriched": len(approach_enrichments),
            "commentary_blocks_enriched": len(commentary_enrichments),
            "sections_enriched": len(section_enrichments),
            "processing_time_sec": elapsed,
            "model": "claude-cli",
            # Upstream data quality info (for RAG context)
            "upstream_verification_verdict": upstream_patch.get("verification_verdict"),
            "upstream_fixes_applied": upstream_patch.get("fixes_applied_count", 0),
            "upstream_flags_unfixed": upstream_patch.get("flags_not_fixed_count", 0),
            # LLM drift normalization (best-effort repairs) applied before validation.
            "normalization_repairs_count": len(normalization_repairs),
            "normalization_repairs_preview": normalization_repairs[:5],
        },
        # Version tags (safe additive fields; helps drift detection downstream).
        "pipeline_version": PIPELINE_VERSION,
        "prompt_version": PROMPT_VERSION,
        "video_id": video_id,
        "video_type": data.get("video_type"),
        "speaker_labels": data.get("speaker_labels"),
        "speaker_corrections": data.get("speaker_corrections", []),
        "segments": segments,
        "enrichments": enrichments,
        "low_quality_segments": low_quality_segments,
        "transcript_artifacts": transcript_artifacts,
        "summary": {
            "total_conversations": len(approach_convs),
            "enriched_conversations": len(approach_enrichments),
            "commentary_blocks_enriched": len(commentary_enrichments),
            "sections_enriched": len(section_enrichments),
            "techniques_found": sorted(all_techniques),
            "topics_found": sorted(all_topics),
            "phases_found": sorted(set(
                p.get("phase", "")
                for e in enrichments
                for p in e.get("turn_phases", [])
                if p.get("phase")
            )),
            "unlisted_concepts": {
                "techniques": sorted(set(all_unlisted_techniques)),
                "topics": sorted(set(all_unlisted_topics)),
            },
        },
    }

    # Add approach-specific summary fields when there are approaches
    if approach_enrichments:
        output["summary"]["hook_rate"] = (
            sum(1 for e in approach_enrichments if e.get("hook_point"))
            / max(len(approach_enrichments), 1)
        )
        output["summary"]["investment_levels"] = {
            level: sum(1 for e in approach_enrichments if e.get("investment_level") == level)
            for level in ["low", "medium", "high"]
        }

    # Cross-reference validation uses 06c patched data (segments are ground truth)
    stage06_data = data

    # Validate output
    validation_results = validate_enrichment_output(output, stage06_data)
    write_validation_results(validation_results, output_path, video_id)

    has_errors = any(r.severity == "error" for r in validation_results)

    if has_errors:
        print(f"{LOG_PREFIX}   SKIPPING output write due to validation errors")
    else:
        # Write output
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with output_path.open("w", encoding="utf-8") as f:
            json.dump(output, f, ensure_ascii=False)
        print(f"{LOG_PREFIX}   Wrote: {output_path}")

    print(f"{LOG_PREFIX}   Validation: {'FAILED' if has_errors else 'PASSED'}")

    return {
        "conversations": len(approach_convs),
        "enriched": len(enrichments),
        "validation_passed": not has_errors,
        "validation_errors": sum(1 for r in validation_results if r.severity == "error"),
        "validation_warnings": sum(1 for r in validation_results if r.severity == "warning"),
    }


def _summarize_enrichments(enrichments: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Compute summary fields derived from Stage 07 enrichments (deterministic)."""
    approach_enrichments = [e for e in enrichments if e.get("type") == "approach"]
    commentary_enrichments = [e for e in enrichments if e.get("type") == "commentary"]
    section_enrichments = [e for e in enrichments if e.get("type") == "talking_head_section"]

    # Collect unlisted concepts across all enrichments.
    all_unlisted_techniques: List[str] = []
    all_unlisted_topics: List[str] = []
    for e in enrichments:
        unlisted = e.get("unlisted_concepts", {})
        if isinstance(unlisted, dict):
            all_unlisted_techniques.extend(unlisted.get("techniques", []) or [])
            all_unlisted_topics.extend(unlisted.get("topics", []) or [])

    # Collect all techniques (from both techniques_used and techniques_discussed).
    all_techniques = set()
    for e in enrichments:
        for t in e.get("techniques_used", []) or []:
            if isinstance(t, dict) and t.get("technique"):
                all_techniques.add(t["technique"])
        for t in e.get("techniques_discussed", []) or []:
            if isinstance(t, dict) and t.get("technique"):
                all_techniques.add(t["technique"])

    # Collect all topics.
    all_topics = set()
    for e in enrichments:
        for topic in e.get("topics_discussed", []) or []:
            if isinstance(topic, str):
                all_topics.add(topic)

    phases_found = sorted(
        set(
            p.get("phase", "")
            for e in enrichments
            for p in (e.get("turn_phases", []) or [])
            if isinstance(p, dict) and p.get("phase")
        )
    )

    summary: Dict[str, Any] = {
        "enriched_conversations": len(approach_enrichments),
        "commentary_blocks_enriched": len(commentary_enrichments),
        "sections_enriched": len(section_enrichments),
        "techniques_found": sorted(all_techniques),
        "topics_found": sorted(all_topics),
        "phases_found": phases_found,
        "unlisted_concepts": {
            "techniques": sorted(set(all_unlisted_techniques)),
            "topics": sorted(set(all_unlisted_topics)),
        },
    }

    if approach_enrichments:
        summary["hook_rate"] = (
            sum(1 for e in approach_enrichments if e.get("hook_point"))
            / max(len(approach_enrichments), 1)
        )
        summary["investment_levels"] = {
            level: sum(1 for e in approach_enrichments if e.get("investment_level") == level)
            for level in ["low", "medium", "high"]
        }

    return summary


def revalidate_video_file(
    input_path: Path,
    output_path: Path,
    dry_run: bool = False,
) -> Dict[str, Any]:
    """Re-run deterministic normalization + validation on an existing .enriched.json (no Claude call)."""
    print(f"[07.content] Revalidating: {input_path.name}")

    # Load Stage 06c input (ground truth for segments + roles).
    with input_path.open("r", encoding="utf-8") as f:
        stage06_data = json.load(f)

    segments = stage06_data.get("segments", [])
    if not segments:
        print(f"[07.content] No segments found")
        return {"conversations": 0, "enriched": 0, "validation_passed": False}

    conversations = group_segments_by_conversation(segments)

    # Load existing Stage 07 output.
    if not output_path.exists():
        print(f"{LOG_PREFIX}   Missing Stage 07 output (cannot revalidate): {output_path}")
        return {
            "conversations": len([c for c in conversations.keys() if c > 0]),
            "enriched": 0,
            "validation_passed": False,
        }

    with output_path.open("r", encoding="utf-8") as f:
        output = json.load(f)

    # Keep Stage 06c as the source of truth for transcript fields (Stage 07 should mirror it).
    output["video_id"] = stage06_data.get("video_id", output.get("video_id"))
    output["video_type"] = stage06_data.get("video_type", output.get("video_type"))
    output["speaker_labels"] = stage06_data.get("speaker_labels", output.get("speaker_labels"))
    output["speaker_corrections"] = stage06_data.get("speaker_corrections", output.get("speaker_corrections", []))
    output["segments"] = segments

    enrichments: List[Dict[str, Any]] = output.get("enrichments", []) or []
    low_quality_segments: List[Dict[str, Any]] = output.get("low_quality_segments", []) or []

    # Recompute phase confidence (deterministic).
    speaker_labels = stage06_data.get("speaker_labels", {})
    add_phase_confidence_to_enrichments(
        enrichments, conversations, low_quality_segments, speaker_labels
    )

    # Apply normalization (deterministic repairs before validation).
    seg_by_id = {
        s.get("id"): s
        for s in segments
        if isinstance(s, dict) and isinstance(s.get("id"), int)
    }
    normalization_repairs = normalize_enrichments(enrichments, seg_by_id=seg_by_id, conversations=conversations)

    meta = output.get("metadata")
    if not isinstance(meta, dict):
        meta = {}
        output["metadata"] = meta
    meta["revalidated_at"] = time.strftime("%Y-%m-%dT%H:%M:%SZ")
    meta["revalidated_pipeline_version"] = PIPELINE_VERSION
    meta["revalidated_prompt_version"] = PROMPT_VERSION
    meta["normalization_repairs_count"] = len(normalization_repairs)
    meta["normalization_repairs_preview"] = normalization_repairs[:5]

    summary = output.get("summary")
    if not isinstance(summary, dict):
        summary = {}
        output["summary"] = summary
    summary.update(_summarize_enrichments(enrichments))
    summary["total_conversations"] = len([c for c in conversations.keys() if c > 0])

    # Top-level version tags (helps downstream drift detection; safe additive fields).
    output["pipeline_version"] = PIPELINE_VERSION
    output["prompt_version"] = PROMPT_VERSION

    # Validate output against Stage 06c ground truth.
    validation_results = validate_enrichment_output(output, stage06_data)
    has_errors = any(r.severity == "error" for r in validation_results)

    if dry_run:
        print(f"{LOG_PREFIX}   [DRY RUN] Would write validation and rewrite output ({'errors' if has_errors else 'no errors'})")
    else:
        write_validation_results(
            validation_results,
            output_path,
            output.get("video_id") or stage06_data.get("video_id") or "unknown",
        )
        if has_errors:
            print(f"{LOG_PREFIX}   SKIPPING output rewrite due to validation errors")
        else:
            with output_path.open("w", encoding="utf-8") as f:
                json.dump(output, f, ensure_ascii=False)
            print(f"{LOG_PREFIX}   Rewrote: {output_path}")

    print(f"{LOG_PREFIX}   Revalidation: {'FAILED' if has_errors else 'PASSED'}")

    return {
        "conversations": len([c for c in conversations.keys() if c > 0]),
        "enriched": len(enrichments),
        "validation_passed": not has_errors,
        "validation_errors": sum(1 for r in validation_results if r.severity == "error"),
        "validation_warnings": sum(1 for r in validation_results if r.severity == "warning"),
        "normalization_repairs": len(normalization_repairs),
    }


# ---------------------------
# Path helpers
# ---------------------------

def repo_root() -> Path:
    return Path(__file__).resolve().parents[2]


def verification_root() -> Path:
    return repo_root() / "data" / "06b.verify"


def input_root() -> Path:
    return repo_root() / "data" / "06c.patched"


def output_root() -> Path:
    return repo_root() / "data" / "07.content"


def test_input_root() -> Path:
    return repo_root() / "data" / "test" / "06c.patched"


def test_output_root() -> Path:
    return repo_root() / "data" / "test" / "07.content"


def test_verification_root() -> Path:
    return repo_root() / "data" / "test" / "06b.verify"


def extract_video_stem(input_path: Path) -> str:
    """Extract video stem from input path (remove .conversations suffix)."""
    stem = input_path.stem
    if stem.endswith(".conversations"):
        stem = stem[:-len(".conversations")]
    return stem


def _find_verification_for_input(
    input_path: Path,
    source: str,
    verify_root: Path,
) -> Optional[Path]:
    """Find a matching 06b verification report for a Stage 06c input file.

    Supports multiple on-disk layouts:
    - source-video: data/06b.verify/<source>/<video_dir>/<stem>.verification.json
    - source-flat:  data/06b.verify/<source>/<stem>.verification.json
    - root-flat:    data/06b.verify/<stem>.verification.json
    """
    video_stem = extract_video_stem(input_path)
    verification_name = f"{video_stem}.verification.json"

    # Strategy 1: mirror relative path from input_root() into verify_root
    try:
        rel = input_path.parent.relative_to(input_root())
        candidate = verify_root / rel / verification_name
        if candidate.exists():
            return candidate
    except ValueError:
        pass

    # Strategy 2: source-flat
    candidate = verify_root / source / verification_name
    if candidate.exists():
        return candidate

    # Strategy 3: root-flat
    candidate = verify_root / verification_name
    if candidate.exists():
        return candidate

    # Strategy 4: recursive search (prefer under source/)
    src_dir = verify_root / source
    if src_dir.exists():
        for found in src_dir.rglob(verification_name):
            return found
    for found in verify_root.rglob(verification_name):
        return found

    return None


def load_verification_status(input_path: Path, source: str, verify_root: Path) -> Dict[str, Any]:
    """Load 06b verification report for a video.

    Returns dict with 'verdict' key (APPROVE/FLAG/REJECT or None if not found).
    """
    verify_path = _find_verification_for_input(input_path, source, verify_root)
    if not verify_path:
        expected = verify_root / source / f"{extract_video_stem(input_path)}.verification.json"
        return {"verdict": None, "path": str(expected)}
    try:
        data = json.loads(verify_path.read_text(encoding="utf-8"))
        data["path"] = str(verify_path)
        return data
    except (json.JSONDecodeError, OSError):
        return {"verdict": None, "path": str(verify_path)}


def should_process_video(
    input_path: Path,
    source: str,
    verify_root: Path,
    skip_verification: bool = False,
    allow_flag: bool = False,
) -> Tuple[bool, str]:
    """Check if video should be processed based on 06b verification status.

    Returns (should_process, reason).
    APPROVE always proceeds. FLAG proceeds only when --allow-flag is set. REJECT is blocked.
    """
    if skip_verification:
        return True, "verification skipped (--skip-verification)"

    status = load_verification_status(input_path, source, verify_root)
    verdict = status.get("verdict")

    if verdict is None:
        return False, f"no 06b verification found at {status.get('path', 'unknown')}"
    if verdict == "APPROVE":
        return True, "APPROVE"
    if verdict == "FLAG":
        if allow_flag:
            return True, "FLAG (allowed by --allow-flag)"
        return False, "FLAG verdict - needs manual review before proceeding"
    if verdict == "REJECT":
        return False, "REJECT verdict - critical issues found"

    return False, f"unknown verdict: {verdict}"


def compute_output_path(input_path: Path, output_dir: Path) -> Path:
    """Compute output path from input path."""
    stem = input_path.stem
    if stem.endswith(".conversations"):
        stem = stem[:-len(".conversations")]
    return output_dir / f"{stem}.enriched.json"


def parse_sources_file(path: Path) -> List[Tuple[str, str]]:
    """Parse sources.txt file."""
    sources: List[Tuple[str, str]] = []
    for raw in path.read_text(encoding="utf-8").splitlines():
        line = raw.strip()
        if not line or line.startswith("#"):
            continue
        if "|" in line:
            name, url = line.split("|", 1)
            sources.append((name.strip(), url.strip()))
            continue
        parts = shlex.split(line)
        if len(parts) >= 2:
            sources.append((parts[0], parts[1]))
    return sources


def find_input_files(in_dir: Path) -> List[Path]:
    """Find all conversations JSON files in directory."""
    return sorted(in_dir.rglob("*.conversations.json"))


def _run_named_source(args) -> None:
    """Run for a named source (from pipeline: ./07.content source_name url)."""
    name = args.name
    in_dir = input_root() / name
    if not in_dir.exists():
        raise SystemExit(f"Input directory not found: {in_dir}")

    out_dir = Path(args.output) if args.output else output_root() / name
    files = find_input_files(in_dir)
    if not files:
        print(f"[07.content] No .conversations.json files found in: {in_dir}")
        return

    print(f"[07.content] Input : {in_dir}")
    print(f"[07.content] Output: {out_dir}")
    print(f"[07.content] Files : {len(files)}")

    total_convs = 0
    total_enriched = 0
    skipped_verification = 0

    for input_file in files:
        # Verification gate
        should_process, reason = should_process_video(
            input_file, name, verification_root(),
            skip_verification=args.skip_verification or args.revalidate,
            allow_flag=args.allow_flag,
        )
        if not should_process:
            print(f"{LOG_PREFIX} BLOCKED: {input_file.name} - {reason}")
            skipped_verification += 1
            continue

        output_file = compute_output_path(input_file, out_dir)
        if not args.revalidate and output_file.exists() and not args.overwrite:
            continue
        if args.revalidate:
            result = revalidate_video_file(input_file, output_file, dry_run=args.dry_run)
        else:
            result = process_video_file(input_file, output_file, dry_run=args.dry_run)
        total_convs += result["conversations"]
        total_enriched += result["enriched"]

    if skipped_verification > 0:
        print(f"{LOG_PREFIX} Blocked {skipped_verification} video(s) due to verification status")
    print(f"\n[07.content] Done. Enriched {total_enriched}/{total_convs} conversations")


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Enrich conversations with technique/topic analysis using Claude CLI"
    )
    parser.add_argument(
        "name", nargs="?",
        help="Source name (folder under data/06c.patched/)"
    )
    parser.add_argument(
        "youtube_url", nargs="?",
        help="YouTube URL (unused, accepted for pipeline compatibility)"
    )
    parser.add_argument(
        "--input",
        help="Input .conversations.json file or directory"
    )
    parser.add_argument(
        "--output",
        help="Output directory (defaults to data/07.content/)"
    )
    parser.add_argument(
        "--test",
        action="store_true",
        help="Process test videos (data/test/06c.patched/)"
    )
    parser.add_argument(
        "--sources",
        nargs="?",
        const="docs/pipeline/sources.txt",
        help="Process all sources from sources.txt file"
    )
    parser.add_argument(
        "--manifest",
        help="Manifest file: only process videos listed (docs/pipeline/batches/P001.txt)."
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Preview what would be processed"
    )
    parser.add_argument(
        "--overwrite",
        action="store_true",
        help="Overwrite existing output files"
    )
    parser.add_argument(
        "--skip-verification",
        action="store_true",
        help="Skip 06b verification gate (process all files regardless of verdict)"
    )
    parser.add_argument(
        "--allow-flag",
        action="store_true",
        help="Allow FLAG verdicts to proceed (still blocks REJECT)"
    )
    parser.add_argument(
        "--revalidate",
        action="store_true",
        help="Re-run deterministic normalization + validation on existing Stage 07 outputs (no Claude call)"
    )

    args = parser.parse_args()

    # Only require Claude CLI when we will actually call it.
    if not args.revalidate and not args.dry_run:
        claude_bin = find_claude_binary()
        if not claude_bin:
            print(f"{LOG_PREFIX} Error: Claude CLI binary not found")
            print(f"{LOG_PREFIX} Searched: {[str(p) for p in CLAUDE_BINARY_PATHS]}")
            print(f"{LOG_PREFIX} Install Claude Code CLI: https://claude.ai/code")
            return

        try:
            result = subprocess.run(
                [claude_bin, "--version"],
                capture_output=True,
                text=True,
                timeout=10
            )
            if result.returncode != 0:
                print(f"{LOG_PREFIX} Warning: Claude CLI not responding properly")
            else:
                print(f"{LOG_PREFIX} Using Claude CLI: {claude_bin}")
        except subprocess.TimeoutExpired:
            print(f"{LOG_PREFIX} Warning: Claude CLI slow to respond")

    # Determine input/output paths and verification root
    verify_root = verification_root()  # default
    is_test_mode = False

    if args.test:
        in_dir = test_input_root()
        out_dir = test_output_root()
        verify_root = test_verification_root()
        is_test_mode = True
    elif args.input:
        input_path = Path(args.input)
        if not input_path.exists():
            input_path = repo_root() / args.input
        if not input_path.exists():
            raise SystemExit(f"Input not found: {args.input}")

        if input_path.is_file():
            # Single file mode - extract source from parent directory
            source_name = input_path.parent.name
            out_dir = Path(args.output) if args.output else output_root()
            output_path = compute_output_path(input_path, out_dir)

            # Verification gate
            should_process, reason = should_process_video(
                input_path, source_name, verify_root,
                skip_verification=args.skip_verification or args.revalidate,
                allow_flag=args.allow_flag,
            )
            if not should_process:
                print(f"{LOG_PREFIX} BLOCKED: {input_path.name} - {reason}")
                print(f"{LOG_PREFIX} Use --skip-verification to override (or --allow-flag for FLAG)")
                return

            if not args.revalidate and output_path.exists() and not args.overwrite:
                print(f"[07.content] Output exists, skipping: {output_path}")
                return

            if args.revalidate:
                result = revalidate_video_file(input_path, output_path, dry_run=args.dry_run)
            else:
                result = process_video_file(input_path, output_path, dry_run=args.dry_run)
            print(f"\n[07.content] Done. Enriched {result['enriched']}/{result['conversations']} conversations")
            return

        in_dir = input_path
        out_dir = Path(args.output) if args.output else output_root()
    elif args.manifest:
        manifest_path = Path(args.manifest)
        if not manifest_path.is_absolute():
            manifest_path = repo_root() / manifest_path
        if not manifest_path.exists():
            raise SystemExit(f"Manifest file not found: {manifest_path}")

        out_base = Path(args.output) if args.output else output_root()
        sources_map = load_manifest_sources(manifest_path)
        total_convs = 0
        total_enriched = 0

        for src_name, vid_ids in sorted(sources_map.items()):
            src_in_dir = input_root() / src_name
            if not src_in_dir.exists():
                print(f"[07.content] Skipping {src_name}: no 06c.patched output")
                continue

            src_out_dir = out_base / src_name
            files = manifest_filter_files(find_input_files(src_in_dir), vid_ids)
            if not files:
                print(f"[07.content] Skipping {src_name}: no manifest videos found in input")
                continue

            print(f"[07.content] Manifest: {src_name} ({len(files)} videos)")
            skipped_verification = 0
            for input_file in files:
                # Verification gate
                should_process, reason = should_process_video(
                    input_file, src_name, verify_root,
                    skip_verification=args.skip_verification or args.revalidate,
                    allow_flag=args.allow_flag,
                )
                if not should_process:
                    print(f"{LOG_PREFIX} BLOCKED: {input_file.name} - {reason}")
                    skipped_verification += 1
                    continue

                output_file = compute_output_path(input_file, src_out_dir)
                if not args.revalidate and output_file.exists() and not args.overwrite:
                    continue
                if args.revalidate:
                    result = revalidate_video_file(input_file, output_file, dry_run=args.dry_run)
                else:
                    result = process_video_file(input_file, output_file, dry_run=args.dry_run)
                total_convs += result["conversations"]
                total_enriched += result["enriched"]

            if skipped_verification > 0:
                print(f"{LOG_PREFIX} Blocked {skipped_verification} video(s) due to verification status")

        print(f"\n[07.content] Manifest done. Enriched {total_enriched}/{total_convs} conversations total")
        return
    elif args.sources:
        sources_path = repo_root() / args.sources
        if not sources_path.exists():
            raise SystemExit(f"Sources file not found: {sources_path}")

        out_base = Path(args.output) if args.output else output_root()
        total_convs = 0
        total_enriched = 0

        for src_name, _ in parse_sources_file(sources_path):
            src_in_dir = input_root() / src_name
            if not src_in_dir.exists():
                print(f"[07.content] Skipping {src_name}: no 06c.patched output")
                continue

            src_out_dir = out_base / src_name
            files = find_input_files(src_in_dir)

            skipped_verification = 0
            for input_file in files:
                # Verification gate
                should_process, reason = should_process_video(
                    input_file, src_name, verify_root,
                    skip_verification=args.skip_verification or args.revalidate,
                    allow_flag=args.allow_flag,
                )
                if not should_process:
                    print(f"{LOG_PREFIX} BLOCKED: {input_file.name} - {reason}")
                    skipped_verification += 1
                    continue

                output_file = compute_output_path(input_file, src_out_dir)
                if not args.revalidate and output_file.exists() and not args.overwrite:
                    continue
                if args.revalidate:
                    result = revalidate_video_file(input_file, output_file, dry_run=args.dry_run)
                else:
                    result = process_video_file(input_file, output_file, dry_run=args.dry_run)
                total_convs += result["conversations"]
                total_enriched += result["enriched"]

            if skipped_verification > 0:
                print(f"{LOG_PREFIX} Blocked {skipped_verification} video(s) due to verification status")

        print(f"\n[07.content] Done. Enriched {total_enriched}/{total_convs} conversations total")
        return
    elif args.name:
        _run_named_source(args)
        return
    else:
        raise SystemExit("Provide a source name, --input, --test, --manifest, or --sources")

    # Directory mode
    files = find_input_files(in_dir)
    if not files:
        print(f"[07.content] No .conversations.json files found in: {in_dir}")
        return

    # Extract source name from directory path
    source_name = in_dir.name

    print(f"[07.content] Input : {in_dir}")
    print(f"[07.content] Output: {out_dir}")
    print(f"[07.content] Files : {len(files)}")
    print(f"[07.content] Source: {source_name}")

    # Load state for checkpointing
    state_path = out_dir / ".enrichment_state.json"
    state = load_state(state_path)

    total_convs = 0
    total_enriched = 0
    processed = 0
    skipped = 0
    failed = 0
    consecutive_failures = 0
    validation_failed = 0
    skipped_verification = 0

    for input_file in files:
        file_key = str(input_file.relative_to(in_dir))

        # Skip if already completed
        if not args.revalidate and file_key in state.completed_files and not args.overwrite:
            skipped += 1
            continue

        # Verification gate
        should_process, reason = should_process_video(
            input_file, source_name, verify_root,
            skip_verification=args.skip_verification or args.revalidate,
            allow_flag=args.allow_flag,
        )
        if not should_process:
            print(f"{LOG_PREFIX} BLOCKED: {input_file.name} - {reason}")
            skipped_verification += 1
            continue

        output_file = compute_output_path(input_file, out_dir)

        if not args.revalidate and output_file.exists() and not args.overwrite:
            skipped += 1
            state.completed_files.append(file_key)
            save_state(state_path, state)
            continue

        # Mark as in progress
        state.in_progress = file_key
        save_state(state_path, state)

        try:
            if args.revalidate:
                result = revalidate_video_file(input_file, output_file, dry_run=args.dry_run)
            else:
                result = process_video_file(input_file, output_file, dry_run=args.dry_run)
            total_convs += result["conversations"]
            total_enriched += result["enriched"]
            processed += 1

            # Track validation failures for failure budget
            if not result.get("validation_passed", True):
                validation_failed += 1
                consecutive_failures += 1
            else:
                consecutive_failures = 0

            # Mark as completed
            if not args.dry_run:
                state.completed_files.append(file_key)
                state.in_progress = None
                save_state(state_path, state)

            # Failure budget: halt on consecutive failures
            if consecutive_failures >= MAX_CONSECUTIVE_FAILURES:
                print(f"\n{LOG_PREFIX} HALTING: {consecutive_failures} consecutive validation failures")
                print(f"{LOG_PREFIX} Review .validation.json files for details.")
                break

        except Exception as e:
            print(f"{LOG_PREFIX} Error processing {input_file}: {e}")
            state.failures.append({"file": file_key, "error": str(e)})
            state.in_progress = None
            save_state(state_path, state)
            failed += 1
            consecutive_failures += 1

            if consecutive_failures >= MAX_CONSECUTIVE_FAILURES:
                print(f"\n{LOG_PREFIX} HALTING: {consecutive_failures} consecutive failures")
                break

    # Print summary first
    print(f"\n{LOG_PREFIX} Done.")
    print(f"  Processed:           {processed}")
    print(f"  Skipped (existing):  {skipped}")
    print(f"  Blocked (verify):    {skipped_verification}")
    print(f"  Failed (exception):  {failed}")
    print(f"  Failed (validation): {validation_failed}")
    print(f"  Enriched:            {total_enriched}/{total_convs} conversations")

    # Failure budget: check overall failure rate (after summary so user sees stats)
    total_attempted = processed + failed
    if total_attempted > 0:
        failure_rate = (failed + validation_failed) / total_attempted
        if failure_rate > MAX_FAILURE_RATE and total_attempted >= 5:
            print(f"\n{LOG_PREFIX} HALTING: Failure rate {failure_rate:.0%} exceeds {MAX_FAILURE_RATE:.0%} threshold")
            print(f"{LOG_PREFIX} {failed} exceptions + {validation_failed} validation failures out of {total_attempted} attempted.")
            print(f"{LOG_PREFIX} Review .validation.json files for details.")
            sys.exit(1)


if __name__ == "__main__":
    main()
