#!/usr/bin/env python3
"""
scripts/training-data/08.conversations

Speaker Labeling + Conversation Boundaries using Claude Code CLI

Two-pass architecture:
1. Speaker Labeling - SPEAKER_XX -> coach, target, voiceover, other
2. Conversation Boundaries - segment_type + conversation_id

Reads:
  - Video type files (with full segment data):
      data/07.video-type/<source>/<video>/*.video_type.json

Writes:
  - Conversation files:
      data/08.conversations/<source>/<video>/*.conversations.json

Use:

  A) Test videos:
     ./scripts/training-data/08.conversations --test

  B) Single file:
     ./scripts/training-data/08.conversations --input data/test/07.video-type/video.video_type.json

  C) Batch from sources file:
     ./scripts/training-data/08.conversations --sources

Requirements:
  - Claude Code CLI installed and authenticated (claude command available)
"""

from __future__ import annotations

import argparse
import hashlib
import json
import re
import shlex
import subprocess
import time
from dataclasses import dataclass, asdict
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple


# ---------------------------
# Configuration
# ---------------------------

SCHEMA_VERSION = "2.0.0"
PIPELINE_VERSION = "08.conversations-cli-v1"
PROMPT_VERSION = "2.0.0"

# Global debug flag (set via --debug CLI arg)
DEBUG_MODE = False

# Claude CLI binary path - try common locations
CLAUDE_BINARY_PATHS = [
    "claude",  # If in PATH
    Path.home() / ".vscode-server/extensions/anthropic.claude-code-2.1.17-linux-x64/resources/native-binary/claude",
    Path.home() / ".vscode/extensions/anthropic.claude-code-2.1.17-linux-x64/resources/native-binary/claude",
    "/usr/local/bin/claude",
]


# ---------------------------
# Prompts
# ---------------------------

SPEAKER_LABELING_PROMPT = """You are labeling speakers in a daygame video based on speech patterns.

SPEAKER ROLES:

1. "coach" - The person teaching/demonstrating
   - Opens conversations (excuse me, quick question...)
   - Asks personal questions (name, origin, occupation)
   - Gives compliments
   - Longer, confident statements
   - Commentary to camera between approaches
   - May reference teaching ("guys", "as you can see")

2. "target" - Women being approached
   - Responds to questions (short answers initially)
   - Asked about herself (not asking)
   - Gives name when asked
   - May laugh, show surprise, hesitation
   - Typically shorter turns than coach

3. "voiceover" - Post-production narration
   - Instructional tone disconnected from live action
   - No back-and-forth dialogue
   - Perfect sentences (not fragmented)
   - "Notice how he..." or "Watch what happens..."

4. "other" - Background voices, friends, staff
   - Brief interjections
   - Not involved in approach

5. "unknown" - Cannot determine with confidence
   - Mark as unknown if unsure
   - Flag for manual review

CRITICAL RULES:
1. The person who delivers approach OPENERS ("excuse me", "I just saw you", "you looked really cute") is ALWAYS the coach, NEVER the target
2. The person giving SHORT RESPONSES to questions is typically the target
3. If unsure, mark as "unknown" with low confidence - DO NOT GUESS
4. Consider speech patterns across ALL samples, not just one or two

HANDLING DIARIZATION CONFUSION:
If one speaker ID shows BOTH coach AND target patterns (opens AND gives short responses),
this indicates pyannote merged two speakers. In this case:
- Label as "unknown" with confidence 0.3
- Add reasoning "mixed_diarization_error"

SPEAKERS TO LABEL: {speakers}

FULL TRANSCRIPT BY SPEAKER:
{transcript}

OUTPUT: Return ONLY a JSON object with this exact structure:
{{"speaker_labels": {{"SPEAKER_XX": {{"role": "coach|target|voiceover|other|unknown", "confidence": 0.0-1.0, "reasoning": "brief explanation"}}}}}}
"""

CONVERSATION_BOUNDARY_PROMPT = """You are detecting conversation boundaries in infield daygame footage.

SEGMENT TYPES:

1. "approach" - Part of live interaction with a woman
   - Includes: opener, small talk, flirting, number close
   - Gets non-zero conversation_id

2. "commentary" - Coach talking to camera (not to woman)
   - Pre-approach setup, post-approach breakdown
   - conversation_id: 0

3. "transition" - Brief moment between content
   - Walking, repositioning, audio gaps
   - conversation_id: 0

NEW CONVERSATION STARTS WHEN:
- Direct address to new person (excuse me, sorry, quick question)
- Change from commentary to interpersonal dialogue
- Location/context shift implied
- Previous approach clearly ended (goodbye, number, rejection)

SAME CONVERSATION CONTINUES WHEN:
- Same conversational thread
- Questions followed by relevant answers
- Continuous interaction without camera break

APPROACH ENDS WHEN:
- Number exchange ("text you", "send you a message")
- Explicit goodbye
- Rejection ("I have a boyfriend", walking away)
- Coach pivots to camera commentary

RULES:
- When uncertain: default to commentary (safer)
- conversation_id must be sequential (1, 2, 3...)
- Segments with same conversation_id must be contiguous
- Return EXACTLY {segment_count} segments

SPEAKER ROLES FOR CONTEXT:
{speaker_roles}

SEGMENTS TO CLASSIFY (id: speaker_role: text):
{segments}

OUTPUT: Return ONLY a JSON object with this exact structure:
{{"segments": [{{"id": 0, "segment_type": "approach|commentary|transition", "conversation_id": 0, "is_conversation_start": false}}, ...]}}
"""


# ---------------------------
# State Management
# ---------------------------

@dataclass
class ProcessingState:
    version: int
    completed_files: List[str]
    in_progress: Optional[str]
    failures: List[Dict[str, str]]


def load_state(state_path: Path) -> ProcessingState:
    """Load processing state from file."""
    if state_path.exists():
        try:
            data = json.loads(state_path.read_text())
            return ProcessingState(
                version=data.get("version", 1),
                completed_files=data.get("completed_files", []),
                in_progress=data.get("in_progress"),
                failures=data.get("failures", []),
            )
        except (json.JSONDecodeError, KeyError):
            pass
    return ProcessingState(version=1, completed_files=[], in_progress=None, failures=[])


def save_state(state_path: Path, state: ProcessingState) -> None:
    """Save processing state to file."""
    state_path.parent.mkdir(parents=True, exist_ok=True)
    state_path.write_text(json.dumps(asdict(state), indent=2))


# ---------------------------
# Claude CLI Interface
# ---------------------------

def find_claude_binary() -> Optional[str]:
    """Find the Claude CLI binary."""
    for path in CLAUDE_BINARY_PATHS:
        path = Path(path)
        if path.exists() and path.is_file():
            return str(path)
        # Also check if it's in PATH
        if str(path) == "claude":
            try:
                result = subprocess.run(["which", "claude"], capture_output=True, text=True)
                if result.returncode == 0:
                    return "claude"
            except Exception:
                pass
    return None


def call_claude(prompt: str, retries: int = 3, timeout: int = 300) -> Optional[str]:
    """Call Claude Code CLI with retry logic."""
    claude_bin = find_claude_binary()
    if not claude_bin:
        print("[08.conversations] Error: Claude CLI binary not found")
        return None

    for attempt in range(retries):
        try:
            result = subprocess.run(
                [claude_bin, "-p", prompt, "--output-format", "text"],
                capture_output=True,
                text=True,
                timeout=timeout
            )
            if result.returncode == 0:
                return result.stdout.strip()
            else:
                if attempt < retries - 1:
                    wait = 2 ** attempt
                    print(f"[08.conversations] Claude CLI error, retrying in {wait}s...")
                    print(f"[08.conversations]   stderr: {result.stderr[:200]}")
                    time.sleep(wait)
                    continue
                print(f"[08.conversations] Claude CLI error: {result.stderr[:500]}")
        except subprocess.TimeoutExpired:
            if attempt < retries - 1:
                print(f"[08.conversations] Timeout, retrying...")
                time.sleep(2 ** attempt)
                continue
            print(f"[08.conversations] Claude CLI timeout after {timeout}s")
        except FileNotFoundError:
            print("[08.conversations] Error: 'claude' command not found. Install Claude Code CLI.")
            return None
    return None


def parse_json_response(response: str, debug: bool = False) -> Optional[Dict]:
    """Parse JSON object from LLM response."""
    if not response:
        if debug:
            print("[08.conversations] DEBUG: Response is empty/None")
        return None

    if debug:
        print(f"[08.conversations] DEBUG: Response length: {len(response)} chars")
        print(f"[08.conversations] DEBUG: Response preview:\n{response[:1000]}")
        print(f"[08.conversations] DEBUG: Response end:\n...{response[-500:]}")

    try:
        # Try to find JSON in code block
        code_block_match = re.search(r"```(?:json)?\s*(\{[\s\S]*?\})\s*```", response)
        if code_block_match:
            if debug:
                print("[08.conversations] DEBUG: Found JSON in code block")
            return json.loads(code_block_match.group(1))

        # Try to find raw JSON object
        start = response.find("{")
        if start != -1:
            bracket_count = 0
            for i, char in enumerate(response[start:], start):
                if char == "{":
                    bracket_count += 1
                elif char == "}":
                    bracket_count -= 1
                    if bracket_count == 0:
                        json_str = response[start:i + 1]
                        if debug:
                            print(f"[08.conversations] DEBUG: Extracted JSON ({len(json_str)} chars)")
                        return json.loads(json_str)
            if debug:
                print(f"[08.conversations] DEBUG: Unbalanced brackets, final count: {bracket_count}")
    except (json.JSONDecodeError, ValueError) as e:
        print(f"[08.conversations] JSON parse error: {e}")
        print(f"[08.conversations] Response preview: {response[:500]}...")

    # Save failed response to file for debugging
    debug_path = Path(__file__).parent / "debug_failed_response.txt"
    debug_path.write_text(response)
    print(f"[08.conversations] DEBUG: Saved full response to {debug_path}")

    return None


# ---------------------------
# Pass 1: Speaker Labeling
# ---------------------------

def label_speakers(segments: List[Dict], video_type: str) -> Dict[str, Dict[str, Any]]:
    """Label speakers using Claude CLI."""

    # For talking_head, single speaker is coach
    speakers = list(set(seg.get("pyannote_speaker", "UNKNOWN") for seg in segments))

    if video_type == "talking_head":
        print("[08.conversations] Pass 1: Skipping speaker labeling for talking_head")
        return {
            speaker: {"role": "coach", "confidence": 0.95, "reasoning": "Single speaker in talking_head video"}
            for speaker in speakers
        }

    # Build full transcript by speaker
    speaker_transcripts: Dict[str, List[str]] = {s: [] for s in speakers}
    for i, seg in enumerate(segments):
        speaker = seg.get("pyannote_speaker", "UNKNOWN")
        text = seg.get("text", "").strip()
        if text:
            speaker_transcripts[speaker].append(f"[{i}] \"{text}\"")

    transcript_text = "\n\n".join([
        f"=== {speaker} ({len(lines)} utterances) ===\n" + "\n".join(lines)
        for speaker, lines in speaker_transcripts.items()
    ])

    prompt = SPEAKER_LABELING_PROMPT.format(
        speakers=", ".join(speakers),
        transcript=transcript_text
    )

    print(f"[08.conversations] Pass 1: Labeling {len(speakers)} speakers...")

    # Retry loop for non-deterministic Claude responses
    max_retries = 3
    for attempt in range(max_retries):
        response = call_claude(prompt, timeout=180)

        result = parse_json_response(response, debug=DEBUG_MODE)
        if result and "speaker_labels" in result:
            labels = result["speaker_labels"]

            # Ensure all speakers have labels
            for speaker in speakers:
                if speaker not in labels:
                    labels[speaker] = {"role": "unknown", "confidence": 0.3, "reasoning": "Not labeled by LLM"}

            # Log results
            for speaker, label in labels.items():
                conf = label.get("confidence", 0) * 100
                print(f"[08.conversations]   {speaker}: {label.get('role')} ({conf:.0f}%) - {label.get('reasoning', '')[:50]}")

            return labels

        # JSON parsing failed - retry
        if attempt < max_retries - 1:
            print(f"[08.conversations]   WARNING: JSON parsing failed, retrying ({attempt + 2}/{max_retries})...")
            time.sleep(2)

    # All retries exhausted
    print("[08.conversations]   ERROR: Speaker labeling failed after {max_retries} attempts")
    raise RuntimeError(f"Speaker labeling failed after {max_retries} retries - cannot proceed")


# ---------------------------
# Pass 2: Conversation Boundaries
# ---------------------------

def detect_conversations(
    segments: List[Dict],
    speaker_labels: Dict[str, Dict[str, Any]],
    video_type: str
) -> List[Dict[str, Any]]:
    """Detect conversation boundaries using Claude CLI."""

    # For talking_head/podcast, all is commentary
    if video_type in ("talking_head", "podcast"):
        print("[08.conversations] Pass 2: Skipping boundary detection for non-infield content")
        return [
            {"id": i, "segment_type": "commentary", "conversation_id": 0, "is_conversation_start": False}
            for i in range(len(segments))
        ]

    # Build segment list with speaker roles
    speaker_roles_text = "\n".join([
        f"  {speaker}: {label.get('role', 'unknown')}"
        for speaker, label in speaker_labels.items()
    ])

    segments_text = "\n".join([
        f"[{i}] {speaker_labels.get(seg.get('pyannote_speaker', 'UNKNOWN'), {}).get('role', 'unknown').upper()}: {seg.get('text', '')[:80]}"
        for i, seg in enumerate(segments)
    ])

    prompt = CONVERSATION_BOUNDARY_PROMPT.format(
        segment_count=len(segments),
        speaker_roles=speaker_roles_text,
        segments=segments_text
    )

    print(f"[08.conversations] Pass 2: Detecting boundaries in {len(segments)} segments...")

    # Retry loop for non-deterministic Claude responses
    max_retries = 3
    for attempt in range(max_retries):
        response = call_claude(prompt, timeout=300)

        result = parse_json_response(response, debug=DEBUG_MODE)
        if result and "segments" in result:
            classifications = result["segments"]

            # Validate count
            if len(classifications) != len(segments):
                print(f"[08.conversations]   WARNING: Got {len(classifications)} classifications for {len(segments)} segments")
                # Pad or truncate
                while len(classifications) < len(segments):
                    classifications.append({
                        "id": len(classifications),
                        "segment_type": "commentary",
                        "conversation_id": 0,
                        "is_conversation_start": False
                    })
                classifications = classifications[:len(segments)]

            # Count conversations
            conv_ids = set(c.get("conversation_id", 0) for c in classifications if c.get("conversation_id", 0) > 0)
            print(f"[08.conversations]   Found {len(conv_ids)} conversations")

            return classifications

        # JSON parsing failed - retry
        if attempt < max_retries - 1:
            print(f"[08.conversations]   WARNING: JSON parsing failed, retrying ({attempt + 2}/{max_retries})...")
            time.sleep(2)

    # All retries exhausted
    print(f"[08.conversations]   ERROR: Boundary detection failed after {max_retries} attempts")
    raise RuntimeError(f"Boundary detection failed after {max_retries} retries - cannot proceed")


# ---------------------------
# Validation
# ---------------------------

def validate_results(
    video_type: str,
    speaker_labels: Dict[str, Dict[str, Any]],
    classifications: List[Dict[str, Any]]
) -> List[str]:
    """Validate results and return list of review flags."""
    flags = []

    # Check for unknown speakers
    unknown_speakers = [
        (speaker, label)
        for speaker, label in speaker_labels.items()
        if label.get("role") == "unknown" or label.get("confidence", 0) < 0.5
    ]

    if unknown_speakers:
        unknown_ratio = len(unknown_speakers) / len(speaker_labels)
        if unknown_ratio > 0.5:
            flags.append(f"speakers_unknown_{len(unknown_speakers)}_of_{len(speaker_labels)}")
            print(f"[08.conversations] FLAG: {len(unknown_speakers)}/{len(speaker_labels)} speakers unknown - NEEDS MANUAL REVIEW")

    # Check for 0 conversations in infield/compilation
    conv_ids = set(c.get("conversation_id", 0) for c in classifications if c.get("conversation_id", 0) > 0)

    if video_type in ("infield", "compilation") and len(conv_ids) == 0:
        flags.append("zero_conversations_in_infield")
        print(f"[08.conversations] FLAG: 0 conversations detected in {video_type} video - NEEDS MANUAL REVIEW")

    return flags


# ---------------------------
# Main Processing
# ---------------------------

def extract_video_title(filename: str) -> str:
    """Extract video title from filename."""
    name = Path(filename).stem
    name = re.sub(r"\.(video_type|conversations|audio_features|corrected)$", "", name)
    match = re.match(r"^(.+?)\s*\[", name)
    return match.group(1).strip() if match else name


def extract_video_id(filename: str) -> str:
    """Extract video ID from filename."""
    match = re.search(r"\[([^\]]+)\]", filename)
    return match.group(1) if match else Path(filename).stem


def compute_checksum(data: Any) -> str:
    """Compute checksum of data."""
    return hashlib.sha256(json.dumps(data, sort_keys=True).encode()).hexdigest()[:16]


def process_file(input_path: Path, output_path: Path, dry_run: bool = False) -> Dict[str, Any]:
    """Process a single video_type.json file."""

    print(f"\n[08.conversations] Processing: {input_path.name}")

    # Load input
    with input_path.open("r", encoding="utf-8") as f:
        data = json.load(f)

    segments = data.get("segments", [])
    video_title = extract_video_title(str(input_path))
    video_id = extract_video_id(str(input_path))

    # Get video_type from input (already classified by Stage 07)
    video_type_info = data.get("video_type", {})
    if isinstance(video_type_info, dict):
        video_type = video_type_info.get("type", "compilation")
    else:
        video_type = "compilation"

    print(f"[08.conversations]   Video: \"{video_title}\" [{video_id}]")
    print(f"[08.conversations]   Segments: {len(segments)}")
    print(f"[08.conversations]   Video type: {video_type}")

    if not segments:
        print("[08.conversations]   No segments found")
        return {"video_type": video_type, "conversations": 0, "flags": ["no_segments"]}

    if dry_run:
        print("[08.conversations]   [DRY RUN] Would process this file")
        return {"video_type": video_type, "conversations": 0, "flags": []}

    start_time = time.time()
    llm_calls = 0

    # Pass 1: Speaker Labeling
    speaker_labels = label_speakers(segments, video_type)
    if video_type != "talking_head":
        llm_calls += 1

    # Pass 2: Conversation Boundaries
    classifications = detect_conversations(segments, speaker_labels, video_type)
    if video_type not in ("talking_head", "podcast"):
        llm_calls += 1

    # Validate
    review_flags = validate_results(video_type, speaker_labels, classifications)

    # Build output segments
    output_segments = []
    for i, seg in enumerate(segments):
        classification = classifications[i] if i < len(classifications) else {
            "segment_type": "commentary",
            "conversation_id": 0,
            "is_conversation_start": False
        }

        speaker_id = seg.get("pyannote_speaker", "UNKNOWN")
        speaker_role = speaker_labels.get(speaker_id, {}).get("role", "unknown")

        output_segments.append({
            "id": i,
            "start": seg.get("start", 0),
            "end": seg.get("end", 0),
            "text": seg.get("text", ""),
            "speaker_id": speaker_id,
            "speaker_role": speaker_role,
            "segment_type": classification.get("segment_type", "commentary"),
            "conversation_id": classification.get("conversation_id", 0),
            "is_conversation_start": classification.get("is_conversation_start", False),
        })

    # Build conversation summaries
    conversations = []
    conv_segments: Dict[int, List[Dict]] = {}
    for seg in output_segments:
        conv_id = seg["conversation_id"]
        if conv_id > 0:
            if conv_id not in conv_segments:
                conv_segments[conv_id] = []
            conv_segments[conv_id].append(seg)

    for conv_id, segs in sorted(conv_segments.items()):
        conversations.append({
            "conversation_id": conv_id,
            "segment_ids": [s["id"] for s in segs],
            "start_time": segs[0]["start"],
            "end_time": segs[-1]["end"],
        })

    elapsed = time.time() - start_time

    # Build output
    output = {
        "video_id": video_id,
        "source_file": str(input_path),
        "processed_at": time.strftime("%Y-%m-%dT%H:%M:%SZ"),
        "video_type": {
            "type": video_type,
            "confidence": video_type_info.get("confidence") if isinstance(video_type_info, dict) else None,
            "method": "from_stage_07",
            "reasoning": video_type_info.get("reasoning") if isinstance(video_type_info, dict) else None,
        },
        "speaker_labels": speaker_labels,
        "segments": output_segments,
        "conversations": conversations,
        "review_flags": review_flags if review_flags else None,
        "metadata": {
            "pipeline_version": PIPELINE_VERSION,
            "prompt_version": PROMPT_VERSION,
            "schema_version": SCHEMA_VERSION,
            "input_checksum": compute_checksum(data),
            "llm_calls": llm_calls,
            "processing_time_sec": elapsed,
        },
    }

    # Write output
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with output_path.open("w", encoding="utf-8") as f:
        json.dump(output, f, indent=2, ensure_ascii=False)

    # Summary
    type_counts: Dict[str, int] = {}
    for seg in output_segments:
        st = seg["segment_type"]
        type_counts[st] = type_counts.get(st, 0) + 1

    print(f"[08.conversations] Results:")
    print(f"  Video type: {video_type}")
    print(f"  Conversations: {len(conversations)}")
    print(f"  Segment types: {type_counts}")
    print(f"  LLM calls: {llm_calls}")
    print(f"  Time: {elapsed:.1f}s")
    print(f"  Output: {output_path}")

    return {
        "video_type": video_type,
        "conversations": len(conversations),
        "flags": review_flags,
    }


# ---------------------------
# Path helpers
# ---------------------------

def repo_root() -> Path:
    return Path(__file__).resolve().parents[2]


def input_root() -> Path:
    return repo_root() / "data" / "07.video-type"


def output_root() -> Path:
    return repo_root() / "data" / "08.conversations"


def test_input_root() -> Path:
    return repo_root() / "data" / "test" / "07.video-type"


def test_output_root() -> Path:
    return repo_root() / "data" / "test" / "08.conversations"


def compute_output_path(input_path: Path, output_dir: Path) -> Path:
    """Compute output path from input path."""
    stem = input_path.stem
    if stem.endswith(".video_type"):
        stem = stem[:-len(".video_type")]
    return output_dir / f"{stem}.conversations.json"


def parse_sources_file(path: Path) -> List[Tuple[str, str]]:
    """Parse sources.txt file."""
    sources: List[Tuple[str, str]] = []
    for raw in path.read_text(encoding="utf-8").splitlines():
        line = raw.strip()
        if not line or line.startswith("#"):
            continue
        if "|" in line:
            name, url = line.split("|", 1)
            sources.append((name.strip(), url.strip()))
            continue
        parts = shlex.split(line)
        if len(parts) >= 2:
            sources.append((parts[0], parts[1]))
    return sources


def find_input_files(in_dir: Path) -> List[Path]:
    """Find all video_type JSON files in directory."""
    return sorted(in_dir.rglob("*.video_type.json"))


# ---------------------------
# CLI
# ---------------------------

def main() -> None:
    parser = argparse.ArgumentParser(
        description="Speaker labeling and conversation boundaries using Claude CLI"
    )
    parser.add_argument(
        "--input",
        help="Input .video_type.json file or directory"
    )
    parser.add_argument(
        "--output",
        help="Output directory (defaults to data/08.conversations/)"
    )
    parser.add_argument(
        "--test",
        action="store_true",
        help="Process test videos (data/test/07.video-type/)"
    )
    parser.add_argument(
        "--sources",
        nargs="?",
        const="docs/sources.txt",
        help="Process all sources from sources.txt file"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Preview what would be processed"
    )
    parser.add_argument(
        "--overwrite",
        action="store_true",
        help="Overwrite existing output files"
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="Enable debug logging for LLM responses"
    )

    args = parser.parse_args()

    # Set global debug mode
    global DEBUG_MODE
    DEBUG_MODE = args.debug

    # Test Claude CLI availability
    claude_bin = find_claude_binary()
    if not claude_bin:
        print("[08.conversations] Error: Claude CLI binary not found")
        print("[08.conversations] Searched paths:")
        for p in CLAUDE_BINARY_PATHS:
            print(f"  - {p}")
        print("[08.conversations] Install Claude Code CLI: https://claude.ai/code")
        return

    try:
        result = subprocess.run(
            [claude_bin, "--version"],
            capture_output=True,
            text=True,
            timeout=10
        )
        if result.returncode != 0:
            print("[08.conversations] Warning: Claude CLI not responding properly")
        else:
            print(f"[08.conversations] Using Claude CLI: {claude_bin}")
    except subprocess.TimeoutExpired:
        print("[08.conversations] Warning: Claude CLI slow to respond")

    # Determine input/output paths
    if args.test:
        in_dir = test_input_root()
        out_dir = test_output_root()
    elif args.input:
        input_path = Path(args.input)
        if not input_path.exists():
            input_path = repo_root() / args.input
        if not input_path.exists():
            raise SystemExit(f"Input not found: {args.input}")

        if input_path.is_file():
            # Single file mode
            out_dir = Path(args.output) if args.output else output_root()
            output_path = compute_output_path(input_path, out_dir)

            if output_path.exists() and not args.overwrite:
                print(f"[08.conversations] Output exists, skipping: {output_path}")
                return

            result = process_file(input_path, output_path, dry_run=args.dry_run)
            print(f"\n[08.conversations] Done. Found {result['conversations']} conversations")
            return

        in_dir = input_path
        out_dir = Path(args.output) if args.output else output_root()
    elif args.sources:
        sources_path = repo_root() / args.sources
        if not sources_path.exists():
            raise SystemExit(f"Sources file not found: {sources_path}")

        total_convs = 0
        total_files = 0

        for src_name, _ in parse_sources_file(sources_path):
            src_in_dir = input_root() / src_name
            if not src_in_dir.exists():
                print(f"[08.conversations] Skipping {src_name}: no 07.video-type output")
                continue

            src_out_dir = output_root() / src_name
            files = find_input_files(src_in_dir)

            for input_file in files:
                output_file = compute_output_path(input_file, src_out_dir)
                if output_file.exists() and not args.overwrite:
                    continue
                result = process_file(input_file, output_file, dry_run=args.dry_run)
                total_convs += result["conversations"]
                total_files += 1

        print(f"\n[08.conversations] Done. Processed {total_files} files, found {total_convs} conversations")
        return
    else:
        raise SystemExit("Provide --input, --test, or --sources")

    # Directory mode
    files = find_input_files(in_dir)
    if not files:
        print(f"[08.conversations] No .video_type.json files found in: {in_dir}")
        return

    print(f"[08.conversations] Input : {in_dir}")
    print(f"[08.conversations] Output: {out_dir}")
    print(f"[08.conversations] Files : {len(files)}")

    # Load state for checkpointing
    state_path = out_dir / ".conversations_state.json"
    state = load_state(state_path)

    total_convs = 0
    processed = 0
    skipped = 0
    failed = 0

    for input_file in files:
        file_key = str(input_file.relative_to(in_dir))

        # Skip if already completed
        if file_key in state.completed_files and not args.overwrite:
            skipped += 1
            continue

        output_file = compute_output_path(input_file, out_dir)

        if output_file.exists() and not args.overwrite:
            skipped += 1
            state.completed_files.append(file_key)
            save_state(state_path, state)
            continue

        # Mark as in progress
        state.in_progress = file_key
        save_state(state_path, state)

        try:
            result = process_file(input_file, output_file, dry_run=args.dry_run)
            total_convs += result["conversations"]
            processed += 1

            # Mark as completed
            if not args.dry_run:
                state.completed_files.append(file_key)
                state.in_progress = None
                save_state(state_path, state)
        except Exception as e:
            print(f"[08.conversations] Error processing {input_file}: {e}")
            state.failures.append({"file": file_key, "error": str(e)})
            state.in_progress = None
            save_state(state_path, state)
            failed += 1

    print(f"\n[08.conversations] Done.")
    print(f"  Processed: {processed}")
    print(f"  Skipped  : {skipped}")
    print(f"  Failed   : {failed}")
    print(f"  Conversations found: {total_convs}")


if __name__ == "__main__":
    main()
